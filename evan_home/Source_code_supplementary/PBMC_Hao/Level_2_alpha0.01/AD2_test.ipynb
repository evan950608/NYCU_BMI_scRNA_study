{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/evanlee/PBMC_Hao/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import AD2_w_utils as ad2\n",
    "from AD2_w_utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import scanpy as sc\n",
    "import sklearn\n",
    "import copy\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data contains 129 samples and 6661 features\n",
      "['Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal'] ['Cancer' 'Normal']\n",
      "median of selected prevalence : 0.29457364341085274\n",
      "total selected feature : 483\n",
      "Total cost：0.384000 sec\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "url_1 = 'https://raw.githubusercontent.com/YinchengChen23/ADlasso/main/data/crc_zeller/ASV_vst.txt'\n",
    "url_2 = 'https://raw.githubusercontent.com/YinchengChen23/ADlasso/main/data/crc_zeller/ASV_table.txt'\n",
    "url_3 = 'https://raw.githubusercontent.com/YinchengChen23/ADlasso/main/data/crc_zeller/metadata.txt'\n",
    "Data = pd.read_csv(url_1, sep=\"\\t\")\n",
    "Data = Data.T           # Variance-stabilizing transformation was conducted by DESeq2\n",
    "# we using z-normalization data as input-data\n",
    "Data_std = scipy.stats.zscore(Data, axis=0, ddof=0)\n",
    "RawData = pd.read_csv(url_2, sep=\"\\t\")\n",
    "RawData = RawData.T  # Raw count data, was used as an assessment of prevalence\n",
    "Cohort = pd.read_csv(url_3, sep=\"\\t\")                        # Metadata\n",
    "Label = Cohort['Class'].tolist()\n",
    "\n",
    "print('This data contains',\n",
    "      Data_std.shape[0], 'samples and', Data_std.shape[1], 'features')\n",
    "print(Label[0:10], np.unique(Label))\n",
    "\n",
    "# get_prevalence(data, [0,1,2, ..., 129])\n",
    "pvl0 = get_prevalence(RawData, np.arange(RawData.shape[0]))\n",
    "res0 = ADlasso2(lmbd=1e-5, alpha=0.9, echo=True)\n",
    "start = time.time()\n",
    "res0.fit(Data_std, Label, pvl0)  # .fit(X, y, prevalence)\n",
    "# minimum epoch =  9999 ; minimum lost =  6.27363842795603e-05 ; diff weight =  0.002454951871186495\n",
    "end = time.time()\n",
    "\n",
    "print('median of selected prevalence :', np.median(\n",
    "    [pvl0[i] for i, w in enumerate(res0.feature_set) if w != 0]))\n",
    "print('total selected feature :', np.sum(res0.feature_set))\n",
    "print(\"Total cost：%f sec\" % (end - start))\n",
    "\n",
    "# Export selection result\n",
    "res0.writeList('./demo_selectedList.txt', Data_std.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PBMC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161764, 20568)\n"
     ]
    }
   ],
   "source": [
    "# data_path = '/Users/evanli/Documents/Research_datasets/PBMC_Hao/'\n",
    "os.chdir('/home/evanlee/PBMC_Hao/')\n",
    "data_path = ''\n",
    "adata_raw = sc.read(data_path + 'Hao_PBMC.h5ad')\n",
    "print(adata_raw.shape)  # row is cells, column is gene\n",
    "# (161764, 20568)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': ['B intermediate', 'B memory', 'B naive', 'Plasmablast'],\n",
       " 'CD4 T': ['CD4 CTL',\n",
       "  'CD4 Naive',\n",
       "  'CD4 Proliferating',\n",
       "  'CD4 TCM',\n",
       "  'CD4 TEM',\n",
       "  'Treg'],\n",
       " 'CD8 T': ['CD8 Naive', 'CD8 Proliferating', 'CD8 TCM', 'CD8 TEM'],\n",
       " 'DC': ['ASDC', 'cDC1', 'cDC2', 'pDC'],\n",
       " 'Mono': ['CD14 Mono', 'CD16 Mono'],\n",
       " 'NK': ['NK', 'NK Proliferating', 'NK_CD56bright'],\n",
       " 'other': ['Doublet', 'Eryth', 'HSPC', 'ILC', 'Platelet'],\n",
       " 'other T': ['MAIT', 'dnT', 'gdT']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata\n",
    "types_l1 = adata_raw.obs['celltype.l1'].unique()  # 8\n",
    "types_l2 = adata_raw.obs['celltype.l2'].unique()  # 31\n",
    "types_l3 = adata_raw.obs['celltype.l3'].unique()  # 58\n",
    "\n",
    "celltype_df = adata_raw.obs[['celltype.l1', 'celltype.l2', 'cell_type']]\n",
    "celltype_df = celltype_df.sort_values(['celltype.l1', 'celltype.l2'])\n",
    "\n",
    "celltype_dict = {k: [] for k in sorted(types_l1)}\n",
    "for i in range(len(celltype_df)):\n",
    "    level_1 = celltype_df.iloc[i, 0]\n",
    "    level_2 = celltype_df.iloc[i, 1]\n",
    "    if level_2 not in celltype_dict[level_1]:\n",
    "        celltype_dict[level_1].append(level_2)\n",
    "\n",
    "celltype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary labels for B naive\n",
    "# TODO：create labels without creating adata_raw.obs['is B naive']\n",
    "# adata_raw.obs['is B naive'] = ['B_naive' if x ==\n",
    "#                                'B naive' else \"False\" for x in adata_raw.obs['celltype.l2']]\n",
    "# labels = adata_raw.obs['is B naive'].tolist()\n",
    "labels = [1 if x == 'B naive' else 0 for x in adata_raw.obs['celltype.l2']]\n",
    "\n",
    "# create index for B naive\n",
    "b_naive_indices = [idx for idx, cell_type in enumerate(\n",
    "    adata_raw.obs['celltype.l2']) if cell_type == 'B naive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize expression data\n",
    "adata_std = copy.deepcopy(adata_raw)\n",
    "# Total-count normalize the data matrix X to 10,000 reads per cell\n",
    "sc.pp.normalize_total(adata_std, target_sum=1e4)\n",
    "# Log\n",
    "sc.pp.log1p(adata_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvl = get_prevalence(adata_raw.X, b_naive_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median of selected prevalence : 0.06309924850997668\n",
      "total selected feature : 13059\n",
      "Total cost：3420.610412 sec\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "columns not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtotal selected feature :\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39msum(res\u001b[39m.\u001b[39mfeature_set))\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal cost：\u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (et \u001b[39m-\u001b[39m st))\n\u001b[0;32m---> 14\u001b[0m res\u001b[39m.\u001b[39mwriteList(\u001b[39m'\u001b[39m\u001b[39m./Bnaive_selectedList.txt\u001b[39m\u001b[39m'\u001b[39m, adata_std\u001b[39m.\u001b[39;49mX\u001b[39m.\u001b[39;49mcolumns)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetnnz()\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: columns not found"
     ]
    }
   ],
   "source": [
    "# pvl = get_prevalence(adata_raw.X, np.arange(adata_raw.shape[0]))\n",
    "pvl = get_prevalence(adata_raw.X, b_naive_indices)\n",
    "res = ADlasso2(lmbd=1e-5, echo=True, device='cpu')\n",
    "\n",
    "st = time.time()\n",
    "res.fit(adata_std.X, labels, pvl)  # .fit(X, y, prevalence)\n",
    "et = time.time()\n",
    "\n",
    "print('median of selected prevalence :', np.median(\n",
    "    [pvl[i] for i, w in enumerate(res.feature_set) if w != 0]))\n",
    "print('total selected feature :', np.sum(res.feature_set))\n",
    "print(\"Total cost：%f sec\" % (et - st))\n",
    "\n",
    "res.writeList('./Bnaive_selectedList.txt', adata_std.X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median of selected prevalence : 0.06309924850997668\n",
      "total selected feature : 13059\n",
      "Total cost：3420.610412 sec\n"
     ]
    }
   ],
   "source": [
    "print('median of selected prevalence :', np.median(\n",
    "    [pvl[i] for i, w in enumerate(res.feature_set) if w != 0]))\n",
    "print('total selected feature :', np.sum(res.feature_set))\n",
    "print(\"Total cost：%f sec\" % (et - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.int64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res\u001b[39m.\u001b[39;49mwriteList(\u001b[39m'\u001b[39;49m\u001b[39m./Bnaive_selectedList.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, adata_raw\u001b[39m.\u001b[39;49mvar_names)\n",
      "File \u001b[0;32m~/PBMC_Hao/AD2_w_utils.py:346\u001b[0m, in \u001b[0;36mADlasso2.writeList\u001b[0;34m(self, outpath, featureNameList)\u001b[0m\n\u001b[1;32m    344\u001b[0m         featureID \u001b[39m=\u001b[39m featureNameList[ix] \u001b[39mif\u001b[39;00m featureNameList \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ix\n\u001b[1;32m    345\u001b[0m         tendency \u001b[39m=\u001b[39m classes[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m wi \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m classes[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 346\u001b[0m         w\u001b[39m.\u001b[39mwritelines(featureID \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(wi) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m tendency \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    347\u001b[0m w\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.int64\") to str"
     ]
    }
   ],
   "source": [
    "res.writeList('./Bnaive_selectedList.txt', adata_raw.var_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000237491', 'ENSG00000225880', 'ENSG00000230368',\n",
       "       'ENSG00000188976', 'ENSG00000187961', 'ENSG00000188290',\n",
       "       'ENSG00000187608', 'ENSG00000188157', 'ENSG00000131591',\n",
       "       'ENSG00000186891',\n",
       "       ...\n",
       "       'ENSG00000223653', 'ENSG00000115008', 'ENSG00000117525',\n",
       "       'ENSG00000237541', 'ENSG00000255823', 'ENSG00000176979',\n",
       "       'ENSG00000221933', 'ENSG00000229807', 'ENSG00000268400',\n",
       "       'ENSG00000276345'],\n",
       "      dtype='object', name='gene_ids', length=13059)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_raw.var_names[res.feature_set != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8560, 11469,  6476, ..., 13023, 13069, 20567])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.feature_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace \"selected_features.txt\" with the desired file name\n",
    "filename = \"bnaive_feature_set.txt\"\n",
    "\n",
    "# extract the selected feature names\n",
    "selected_features = adata_raw.var_names[res.feature_set != 0]\n",
    "\n",
    "# save the selected feature names to a text file\n",
    "np.savetxt(filename, selected_features, fmt=\"%s\")\n",
    "\n",
    "\n",
    "# replace \"feature_sort.txt\" with the desired file name\n",
    "filename = \"bnaive_feature_sort.txt\"\n",
    "\n",
    "# save the feature sort to a text file\n",
    "np.savetxt(filename, res.feature_sort, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda tuning\n",
    "# auto_scale(X_input, X_raw, y, step=50)\n",
    "log_lmbd_range = auto_scale(adata_std.X, adata_raw.X, labels, step=50)\n",
    "\n",
    "lmbd_range = np.exp(log_lmbd_range)\n",
    "print(lmbd_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

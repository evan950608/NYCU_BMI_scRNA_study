nohup: ignoring input
Z-transformed rep_cells adata: (57515, 27504) <class 'numpy.ndarray'>
all cell types: ['ASDC', 'B_intermediate', 'B_memory', 'B_naive', 'CD14_Mono', 'CD16_Mono', 'CD4_CTL', 'CD4_Naive', 'CD4_Proliferating', 'CD4_TCM', 'CD4_TEM', 'CD8_Naive', 'CD8_Proliferating', 'CD8_TCM', 'CD8_TEM', 'Doublet', 'Eryth', 'HSPC', 'ILC', 'MAIT', 'NK', 'NK_CD56bright', 'NK_Proliferating', 'Plasmablast', 'Platelet', 'Treg', 'cDC1', 'cDC2', 'dnT', 'gdT', 'pDC']
====================
Queue ['ASDC', 'B_intermediate', 'B_memory', 'B_naive', 'CD14_Mono', 'CD16_Mono', 'CD4_CTL', 'CD4_Naive', 'CD4_Proliferating', 'CD4_TCM', 'CD4_TEM', 'CD8_Naive', 'CD8_Proliferating', 'CD8_TCM', 'CD8_TEM', 'Doublet', 'Eryth', 'HSPC', 'ILC', 'MAIT', 'NK', 'NK_CD56bright', 'NK_Proliferating', 'Plasmablast', 'Platelet', 'Treg', 'cDC1', 'cDC2', 'dnT', 'gdT', 'pDC']
====================
Subsetted raw count adata: (57515, 27504) <class 'anndata._core.views.SparseCSCView'>
***** Starting tuning
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for ASDC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 16:22:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 899, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.725 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 16:23:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 835, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.668 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 16:24:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 941, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.695 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 16:24:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 498, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.573 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 16:25:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 475, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.529 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 16:26:00 Max_iter: 1000
At iteration 462, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.492 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 16:26:29 Max_iter: 1000
At iteration 479, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.479 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 16:26:58 Max_iter: 1000
At iteration 484, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.452 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 16:27:25 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.402 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 16:27:49 Max_iter: 1000
At iteration 409, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.361 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 16:28:11 Max_iter: 1000
At iteration 399, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.343 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 16:28:32 Max_iter: 1000
At iteration 367, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.298 min
==========
Testing lambda: 0.001 starting at 2024-09-19 16:28:50 Max_iter: 1000
At iteration 353, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.27 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 16:29:06 Max_iter: 1000
At iteration 338, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.246 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 16:29:21 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.229 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 16:29:34 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.213 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 16:29:47 Max_iter: 1000
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.205 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 16:29:59 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.202 min
==========
Testing lambda: 0.01 starting at 2024-09-19 16:30:11 Max_iter: 1000
At iteration 343, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.219 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 16:30:25 Max_iter: 1000
At iteration 296, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220683, cost : 0.198 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 16:30:36 Max_iter: 1000
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.204 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 16:30:49 Max_iter: 1000
At iteration 291, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.188 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 16:31:00 Max_iter: 1000
At iteration 241, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.159 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 16:31:09 Max_iter: 1000
At iteration 192, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.13 min
==========
Testing lambda: 0.1 starting at 2024-09-19 16:31:17 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 16:31:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 16:31:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 16:31:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 16:31:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 16:31:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 16:31:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.205497    0.447368          0.444444            5652  0.990219  ...  0.725910   0.571429  0.705882      0.065721       0.001285
0.000015    0.238184    0.407895          0.412698            6551  0.997556  ...  0.725910   0.571429  0.705882      0.089214       0.000253
0.000022    0.190191    0.460526          0.460317            5231  0.971815  ...  0.678923   0.500000  0.648649      0.120163       0.017887
0.000032    0.359802    0.263158          0.253968            9896  0.981067  ...  0.388311   0.164384  0.279070      0.470312       0.000104
0.000046    0.333115    0.289474          0.285714            9162  0.973027  ...  0.474543   0.244898  0.387097      0.481546       0.000002

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
ASDC Time elapsed: 8.718805674711863 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for B_intermediate
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 16:31:56 Max_iter: 1000
At iteration 433, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.579 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 16:32:30 Max_iter: 1000
At iteration 505, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.589 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 16:33:06 Max_iter: 1000
At iteration 505, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.556 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 16:33:39 Max_iter: 1000
At iteration 482, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.531 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 16:34:11 Max_iter: 1000
At iteration 468, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.497 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 16:34:41 Max_iter: 1000
At iteration 458, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.472 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 16:35:09 Max_iter: 1000
At iteration 440, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.422 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 16:35:34 Max_iter: 1000
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.393 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 16:35:58 Max_iter: 1000
At iteration 394, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.36 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 16:36:19 Max_iter: 1000
At iteration 400, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.346 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 16:36:40 Max_iter: 1000
At iteration 376, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.306 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 16:36:59 Max_iter: 1000
At iteration 361, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.284 min
==========
Testing lambda: 0.001 starting at 2024-09-19 16:37:16 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.274 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 16:37:32 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.258 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 16:37:48 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.255 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 16:38:03 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.226 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 16:38:16 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.206 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 16:38:29 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.215 min
==========
Testing lambda: 0.01 starting at 2024-09-19 16:38:42 Max_iter: 1000
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.204 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 16:38:54 Max_iter: 1000
At iteration 307, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.199 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 16:39:06 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.214 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 16:39:19 Max_iter: 1000
At iteration 284, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.183 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 16:39:30 Max_iter: 1000
At iteration 216, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.144 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 16:39:38 Max_iter: 1000
At iteration 90, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.072 min
==========
Testing lambda: 0.1 starting at 2024-09-19 16:39:43 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 16:39:44 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 16:39:45 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 16:39:46 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 16:39:47 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 16:39:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 16:39:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.412631    0.117776          0.119485           11349  0.966103  ...  0.685976   0.573171  0.682148      0.442063       0.001565
0.000015    0.381508    0.131675          0.132353           10493  0.968739  ...  0.698629   0.601036  0.697744      0.452981       0.000682
0.000022    0.350494    0.144111          0.145680            9640  0.966473  ...  0.712675   0.635097  0.714734      0.464511       0.001054
0.000032    0.323044    0.158742          0.159926            8885  0.969077  ...  0.729868   0.661850  0.732800      0.476543       0.000673
0.000046    0.291049    0.176298          0.178309            8005  0.969201  ...  0.748301   0.697248  0.752475      0.489038       0.000760

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
B_intermediate Time elapsed: 8.032880616188049 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for B_memory
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 16:40:20 Max_iter: 1000
At iteration 450, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.558 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 16:40:54 Max_iter: 1000
At iteration 478, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.553 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 16:41:27 Max_iter: 1000
At iteration 468, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.52 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 16:41:58 Max_iter: 1000
At iteration 454, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.499 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 16:42:28 Max_iter: 1000
At iteration 457, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.482 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 16:42:57 Max_iter: 1000
At iteration 465, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.469 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 16:43:25 Max_iter: 1000
At iteration 450, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.428 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 16:43:51 Max_iter: 1000
At iteration 412, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.384 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 16:44:14 Max_iter: 1000
At iteration 428, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.375 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 16:44:37 Max_iter: 1000
At iteration 407, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.343 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 16:44:57 Max_iter: 1000
At iteration 387, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.302 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 16:45:15 Max_iter: 1000
At iteration 373, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.278 min
==========
Testing lambda: 0.001 starting at 2024-09-19 16:45:32 Max_iter: 1000
At iteration 359, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.259 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 16:45:48 Max_iter: 1000
At iteration 349, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.242 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 16:46:02 Max_iter: 1000
At iteration 345, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.242 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 16:46:17 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.222 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 16:46:30 Max_iter: 1000
At iteration 333, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.218 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 16:46:43 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.217 min
==========
Testing lambda: 0.01 starting at 2024-09-19 16:46:56 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.221 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 16:47:09 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.215 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 16:47:22 Max_iter: 1000
At iteration 348, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.223 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 16:47:36 Max_iter: 1000
At iteration 239, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.157 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 16:47:45 Max_iter: 1000
At iteration 210, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.14 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 16:47:53 Max_iter: 1000
At iteration 92, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.072 min
==========
Testing lambda: 0.1 starting at 2024-09-19 16:47:58 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 16:47:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 16:48:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 16:48:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 16:48:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 16:48:03 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 16:48:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.403978    0.112660          0.112564           11111  0.991509  ...  0.824520   0.738532  0.824584      0.415625       0.002239
0.000015    0.371619    0.124855          0.125635           10221  0.992756  ...  0.861293   0.798030  0.862850      0.426917       0.002249
0.000022    0.343441    0.137050          0.137255            9446  0.992643  ...  0.855245   0.789731  0.856764      0.438784       0.001281
0.000032    0.312464    0.152729          0.152505            8594  0.994041  ...  0.882034   0.848404  0.884882      0.451021       0.001626
0.000046    0.279305    0.168990          0.169208            7682  0.996196  ...  0.877857   0.830334  0.880109      0.463700       0.001256

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:947: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax1 = plt.subplots(figsize = (fig_width,fig_height))
B_memory Time elapsed: 7.864387162526449 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for B_naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 16:48:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 573, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.496 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 16:50:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 805, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.889 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 16:52:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 799, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.974 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 16:53:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 791, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.972 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 16:55:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 936, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.029 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 16:57:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 952, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.036 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 17:00:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 934, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.018 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 17:02:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 915, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.936 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 17:03:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 876, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.812 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 17:05:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 963, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.867 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 17:07:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 820, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.776 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 17:09:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 812, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.865 min
==========
Testing lambda: 0.001 starting at 2024-09-19 17:11:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 890, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 1.821 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 17:13:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 295, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.671 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 17:13:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 903, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 1.744 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 17:15:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 643, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 1.477 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 17:17:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.531 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 17:17:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.487 min
==========
Testing lambda: 0.01 starting at 2024-09-19 17:18:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.393 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 17:18:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 310, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.254 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 17:18:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.217 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 17:18:52 Max_iter: 1000
At iteration 379, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.239 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 17:19:07 Max_iter: 1000
At iteration 245, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.161 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 17:19:16 Max_iter: 1000
At iteration 221, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.147 min
==========
Testing lambda: 0.1 starting at 2024-09-19 17:19:25 Max_iter: 1000
At iteration 205, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.138 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 17:19:34 Max_iter: 1000
At iteration 206, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.139 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 17:19:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 17:19:43 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 17:19:44 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 17:19:45 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 17:19:46 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.368092    0.110212          0.110557           10124  0.997565  ...  0.899231   0.829640  0.901430      0.260974       0.000205
0.000015    0.300756    0.136986          0.137428            8272  0.996107  ...  0.916116   0.864826  0.918919      0.266851       0.000175
0.000022    0.260326    0.155666          0.155470            7160  0.996847  ...  0.939641   0.907012  0.942201      0.264872       0.000019
0.000032    0.220986    0.179639          0.179655            6078  0.997059  ...  0.939953   0.904545  0.942384      0.267259       0.000041
0.000046    0.168230    0.215753          0.216123            4627  0.997435  ...  0.944875   0.918083  0.947368      0.237282       0.007162

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
B_naive Time elapsed: 31.30940550963084 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD14_Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 17:20:19 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 734, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.581 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 17:20:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 745, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.594 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 17:21:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 704, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.561 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 17:22:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 358, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.436 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 17:22:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 622, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.538 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 17:23:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 588, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.517 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 17:23:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.38 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 17:23:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 350, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.429 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 17:24:22 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 440, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.502 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 17:24:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 447, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.526 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 17:25:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.429 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 17:25:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 309, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.366 min
==========
Testing lambda: 0.001 starting at 2024-09-19 17:26:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 321, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.377 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 17:26:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 302, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.322 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 17:26:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 359, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.295 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 17:27:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 380, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.281 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 17:27:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.248 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 17:27:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 398, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.267 min
==========
Testing lambda: 0.01 starting at 2024-09-19 17:27:59 Max_iter: 1000
At iteration 421, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.272 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 17:28:15 Max_iter: 1000
At iteration 444, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.278 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 17:28:32 Max_iter: 1000
At iteration 416, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.262 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 17:28:47 Max_iter: 1000
At iteration 412, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.26 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 17:29:03 Max_iter: 1000
At iteration 278, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.183 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 17:29:14 Max_iter: 1000
At iteration 532, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.33 min
==========
Testing lambda: 0.1 starting at 2024-09-19 17:29:34 Max_iter: 1000
At iteration 374, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.238 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 17:29:48 Max_iter: 1000
At iteration 285, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.187 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 17:29:59 Max_iter: 1000
At iteration 302, Convergence with loss difference, Device: cuda
lambda is : 0.21544346900318834, cost : 0.197 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 17:30:11 Max_iter: 1000
At iteration 139, Convergence with loss difference, Device: cuda
lambda is : 0.3162277660168378, cost : 0.102 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 17:30:17 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.021 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 17:30:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.018 min
==========
Testing lambda: 1.0 starting at 2024-09-19 17:30:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.02 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.163831    0.398337          0.398106            4506  0.993949  ...  0.937249   0.928654  0.946350      0.011073       0.005389
0.000015    0.158631    0.412743          0.412090            4363  0.994154  ...  0.939874   0.932448  0.948605      0.014504       0.000852
0.000022    0.144415    0.414149          0.413547            3972  0.994228  ...  0.937661   0.928202  0.946690      0.019051       0.006834
0.000032    0.210042    0.341532          0.341151            5777  0.994178  ...  0.938776   0.932331  0.947678      0.038742       0.000088
0.000046    0.119255    0.456137          0.455353            3280  0.994495  ...  0.936973   0.927628  0.946104      0.032626       0.004776

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD14_Mono Time elapsed: 10.156358528137208 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD16_Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 17:30:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 502, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.136 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 17:32:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 492, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.119 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 17:33:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 433, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.046 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 17:34:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 362, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.918 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 17:35:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.85 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 17:35:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 380, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.971 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 17:36:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 228, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.413 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 17:37:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 453, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.148 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 17:38:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 254, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.491 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 17:38:59 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 277, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.588 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 17:39:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 351, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.86 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 17:40:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 211, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.272 min
==========
Testing lambda: 0.001 starting at 2024-09-19 17:40:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 308, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.587 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 17:41:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 260, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.308 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 17:41:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 279, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.26 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 17:41:51 Max_iter: 1000
At iteration 298, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.223 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 17:42:05 Max_iter: 1000
At iteration 310, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.212 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 17:42:17 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.222 min
==========
Testing lambda: 0.01 starting at 2024-09-19 17:42:31 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.219 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 17:42:44 Max_iter: 1000
At iteration 346, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.222 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 17:42:57 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.216 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 17:43:10 Max_iter: 1000
At iteration 308, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.198 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 17:43:22 Max_iter: 1000
At iteration 263, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.174 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 17:43:32 Max_iter: 1000
At iteration 226, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.152 min
==========
Testing lambda: 0.1 starting at 2024-09-19 17:43:42 Max_iter: 1000
At iteration 215, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.145 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 17:43:50 Max_iter: 1000
At iteration 161, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.113 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 17:43:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 17:43:58 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 17:43:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 17:44:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 17:44:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.418048    0.177599          0.177507           11498  0.994606  ...  0.841779   0.766949  0.845794      0.366604       0.000055
0.000015    0.392925    0.197849          0.198284           10807  0.994704  ...  0.843223   0.773639  0.847724      0.375716       0.000059
0.000022    0.371001    0.217563          0.217706           10204  0.994184  ...  0.849383   0.788546  0.854415      0.385590       0.000058
0.000032    0.345659    0.238710          0.238031            9507  0.995207  ...  0.860967   0.808735  0.866129      0.394833       0.000069
0.000046    0.317299    0.260932          0.261066            8727  0.994800  ...  0.866570   0.818598  0.871753      0.404708       0.000049

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD16_Mono Time elapsed: 13.282926793893179 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_CTL
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 17:44:34 Max_iter: 1000
At iteration 488, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.576 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 17:45:08 Max_iter: 1000
At iteration 479, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.52 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 17:45:40 Max_iter: 1000
At iteration 491, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.507 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 17:46:10 Max_iter: 1000
At iteration 473, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.485 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 17:46:39 Max_iter: 1000
At iteration 461, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.452 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 17:47:06 Max_iter: 1000
At iteration 444, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.431 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 17:47:32 Max_iter: 1000
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.395 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 17:47:56 Max_iter: 1000
At iteration 412, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.377 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 17:48:18 Max_iter: 1000
At iteration 396, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.341 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 17:48:39 Max_iter: 1000
At iteration 380, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.308 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 17:48:57 Max_iter: 1000
At iteration 374, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.29 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 17:49:15 Max_iter: 1000
At iteration 359, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.269 min
==========
Testing lambda: 0.001 starting at 2024-09-19 17:49:31 Max_iter: 1000
At iteration 352, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.25 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 17:49:46 Max_iter: 1000
At iteration 345, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.251 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 17:50:01 Max_iter: 1000
At iteration 333, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.237 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 17:50:15 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.22 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 17:50:28 Max_iter: 1000
At iteration 341, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.22 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 17:50:41 Max_iter: 1000
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.209 min
==========
Testing lambda: 0.01 starting at 2024-09-19 17:50:54 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.216 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 17:51:07 Max_iter: 1000
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.208 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 17:51:19 Max_iter: 1000
At iteration 424, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.266 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 17:51:35 Max_iter: 1000
At iteration 295, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.19 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 17:51:47 Max_iter: 1000
At iteration 212, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.141 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 17:51:55 Max_iter: 1000
At iteration 176, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.12 min
==========
Testing lambda: 0.1 starting at 2024-09-19 17:52:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 17:52:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 17:52:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 17:52:05 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 17:52:06 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 17:52:07 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 17:52:08 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.369474    0.094286          0.094479           10162  0.982623  ...  0.671465   0.570571  0.669014      0.456073       0.000753
0.000015    0.344641    0.103810          0.103067            9479  0.983510  ...  0.681044   0.595541  0.681239      0.467288       0.000237
0.000022    0.314645    0.114286          0.114110            8654  0.985781  ...  0.690666   0.621622  0.693032      0.478817       0.000704
0.000032    0.283122    0.126667          0.125153            7787  0.988104  ...  0.724288   0.673913  0.727984      0.490717       0.000706
0.000046    0.251127    0.140952          0.139877            6907  0.989536  ...  0.737722   0.687273  0.741176      0.502892       0.000667

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_CTL Time elapsed: 7.726646502812703 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_Naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 17:52:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 900, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.832 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 17:53:31 Max_iter: 1000
At iteration 525, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.548 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 17:54:04 Max_iter: 1000
At iteration 482, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.52 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 17:54:35 Max_iter: 1000
At iteration 529, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.512 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 17:55:06 Max_iter: 1000
At iteration 500, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.47 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 17:55:34 Max_iter: 1000
At iteration 481, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.442 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 17:56:01 Max_iter: 1000
At iteration 475, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.418 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 17:56:26 Max_iter: 1000
At iteration 435, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.377 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 17:56:48 Max_iter: 1000
At iteration 419, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.348 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 17:57:09 Max_iter: 1000
At iteration 403, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.315 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 17:57:28 Max_iter: 1000
At iteration 387, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.304 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 17:57:46 Max_iter: 1000
At iteration 376, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.308 min
==========
Testing lambda: 0.001 starting at 2024-09-19 17:58:05 Max_iter: 1000
At iteration 366, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.284 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 17:58:22 Max_iter: 1000
At iteration 359, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.257 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 17:58:37 Max_iter: 1000
At iteration 354, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.255 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 17:58:53 Max_iter: 1000
At iteration 346, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.235 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 17:59:07 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.23 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 17:59:21 Max_iter: 1000
At iteration 357, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.23 min
==========
Testing lambda: 0.01 starting at 2024-09-19 17:59:34 Max_iter: 1000
At iteration 360, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.229 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 17:59:48 Max_iter: 1000
At iteration 301, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.195 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:00:00 Max_iter: 1000
At iteration 309, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.198 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:00:12 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.203 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:00:24 Max_iter: 1000
At iteration 294, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.189 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:00:35 Max_iter: 1000
At iteration 245, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.161 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:00:45 Max_iter: 1000
At iteration 158, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.111 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:00:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:00:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:00:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:00:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:00:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:00:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.331443    0.096910          0.096876            9116  0.992432  ...  0.857970   0.800321  0.868581      0.235531       0.000848
0.000015    0.327225    0.097641          0.097782            9000  0.992197  ...  0.845982   0.785432  0.857390      0.311517       0.002079
0.000022    0.298466    0.109709          0.110005            8209  0.992416  ...  0.850983   0.795181  0.862369      0.327072       0.001555
0.000032    0.265925    0.122874          0.122454            7314  0.991988  ...  0.859691   0.811166  0.870868      0.342750       0.000761
0.000046    0.231712    0.139148          0.138298            6373  0.992267  ...  0.870361   0.830666  0.881144      0.358656       0.000822

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_Naive Time elapsed: 8.412096242109934 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:01:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 958, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.892 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:02:23 Max_iter: 1000
At iteration 492, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.624 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:03:01 Max_iter: 1000
At iteration 455, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.582 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:03:35 Max_iter: 1000
At iteration 520, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.611 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:04:12 Max_iter: 1000
At iteration 498, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.56 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 18:04:46 Max_iter: 1000
At iteration 480, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.543 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 18:05:18 Max_iter: 1000
At iteration 470, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.515 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 18:05:49 Max_iter: 1000
At iteration 455, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.48 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 18:06:18 Max_iter: 1000
At iteration 435, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.443 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 18:06:45 Max_iter: 1000
At iteration 401, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.399 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 18:07:08 Max_iter: 1000
At iteration 382, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.363 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 18:07:30 Max_iter: 1000
At iteration 366, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.334 min
==========
Testing lambda: 0.001 starting at 2024-09-19 18:07:50 Max_iter: 1000
At iteration 351, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.293 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 18:08:08 Max_iter: 1000
At iteration 328, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.253 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 18:08:23 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.241 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 18:08:38 Max_iter: 1000
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.224 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 18:08:51 Max_iter: 1000
At iteration 322, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.213 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 18:09:04 Max_iter: 1000
At iteration 316, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.206 min
==========
Testing lambda: 0.01 starting at 2024-09-19 18:09:16 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.009999999999999995, cost : 0.21 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 18:09:29 Max_iter: 1000
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.209 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:09:41 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.201 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:09:53 Max_iter: 1000
At iteration 245, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.16 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:10:03 Max_iter: 1000
At iteration 203, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.135 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:10:11 Max_iter: 1000
At iteration 194, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.131 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:10:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:10:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:10:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:10:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:10:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:10:24 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:10:24 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.372528    0.365385          0.360465           10246  0.971441  ...  0.284977   0.123711  0.208696      0.220240       0.033600
0.000015    0.437573    0.288462          0.290698           12035  0.948377  ...  0.177452   0.065217  0.115385      0.446950       0.000464
0.000022    0.412994    0.317308          0.313953           11359  0.955502  ...  0.229711   0.097087  0.165289      0.457774       0.001406
0.000032    0.383217    0.346154          0.348837           10540  0.964799  ...  0.236872   0.103093  0.173913      0.468414       0.000826
0.000046    0.355330    0.375000          0.372093            9773  0.965143  ...  0.310238   0.159420  0.252874      0.479297       0.000688

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_Proliferating Time elapsed: 9.062022217114766 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_TCM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:10:56 Max_iter: 1000
At iteration 493, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.57 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:11:30 Max_iter: 1000
At iteration 473, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.556 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:12:04 Max_iter: 1000
At iteration 512, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.553 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:12:37 Max_iter: 1000
At iteration 503, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.525 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:13:08 Max_iter: 1000
At iteration 478, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.487 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 18:13:38 Max_iter: 1000
At iteration 465, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.451 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 18:14:05 Max_iter: 1000
At iteration 445, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.425 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 18:14:30 Max_iter: 1000
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.394 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 18:14:54 Max_iter: 1000
At iteration 412, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.379 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 18:15:17 Max_iter: 1000
At iteration 381, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.359 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 18:15:38 Max_iter: 1000
At iteration 367, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.358 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 18:16:00 Max_iter: 1000
At iteration 359, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.319 min
==========
Testing lambda: 0.001 starting at 2024-09-19 18:16:19 Max_iter: 1000
At iteration 346, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.281 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 18:16:36 Max_iter: 1000
At iteration 333, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.254 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 18:16:51 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.234 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 18:17:05 Max_iter: 1000
At iteration 309, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.212 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 18:17:18 Max_iter: 1000
At iteration 310, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.204 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 18:17:30 Max_iter: 1000
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.202 min
==========
Testing lambda: 0.01 starting at 2024-09-19 18:17:42 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.209 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 18:17:55 Max_iter: 1000
At iteration 316, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.204 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:18:07 Max_iter: 1000
At iteration 328, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.209 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:18:19 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.201 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:18:31 Max_iter: 1000
At iteration 235, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.155 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:18:41 Max_iter: 1000
At iteration 140, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.101 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:18:47 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.019 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:18:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:18:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:18:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.019 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:18:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:18:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:18:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.378272    0.103427          0.103103           10404  0.964193  ...  0.689500   0.641556  0.713628      0.379439       0.002619
0.000015    0.353367    0.112903          0.112613            9719  0.964030  ...  0.691556   0.653550  0.716362      0.392429       0.001868
0.000022    0.325153    0.125403          0.125125            8943  0.964356  ...  0.694996   0.655026  0.719364      0.405761       0.000816
0.000032    0.295048    0.137500          0.137638            8115  0.964674  ...  0.685461   0.658429  0.711493      0.419844       0.001358
0.000046    0.263453    0.153226          0.153028            7246  0.964980  ...  0.690843   0.666369  0.716547      0.434340       0.000700

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_TCM Time elapsed: 8.104570094744364 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_TEM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:19:26 Max_iter: 1000
At iteration 435, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.55 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:19:59 Max_iter: 1000
At iteration 503, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.562 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:20:33 Max_iter: 1000
At iteration 493, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.537 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:21:05 Max_iter: 1000
At iteration 482, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.511 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:21:36 Max_iter: 1000
At iteration 474, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.479 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 18:22:04 Max_iter: 1000
At iteration 459, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.444 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 18:22:31 Max_iter: 1000
At iteration 439, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.42 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 18:22:56 Max_iter: 1000
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.386 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 18:23:19 Max_iter: 1000
At iteration 402, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.352 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 18:23:40 Max_iter: 1000
At iteration 405, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.349 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 18:24:01 Max_iter: 1000
At iteration 384, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.347 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 18:24:22 Max_iter: 1000
At iteration 371, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.314 min
==========
Testing lambda: 0.001 starting at 2024-09-19 18:24:41 Max_iter: 1000
At iteration 362, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.286 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 18:24:58 Max_iter: 1000
At iteration 367, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.27 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 18:25:14 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.238 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 18:25:29 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.222 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 18:25:42 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.217 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 18:25:55 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.21 min
==========
Testing lambda: 0.01 starting at 2024-09-19 18:26:08 Max_iter: 1000
At iteration 351, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.224 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 18:26:21 Max_iter: 1000
At iteration 385, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.242 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:26:36 Max_iter: 1000
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.187 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:26:47 Max_iter: 1000
At iteration 266, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.173 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:26:57 Max_iter: 1000
At iteration 228, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.151 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:27:06 Max_iter: 1000
At iteration 86, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.069 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:27:10 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:27:11 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:27:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:27:13 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:27:14 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:27:15 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:27:16 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.380708    0.093765          0.094395           10471  0.933547  ...  0.505341   0.457090  0.520170      0.460832       0.000284
0.000015    0.350313    0.103284          0.103835            9635  0.936013  ...  0.500373   0.470707  0.517203      0.471844       0.000687
0.000022    0.320572    0.114707          0.115634            8817  0.940631  ...  0.522402   0.485149  0.537870      0.483580       0.001239
0.000032    0.291521    0.128034          0.128614            8018  0.940749  ...  0.511982   0.488518  0.528814      0.495851       0.000803
0.000046    0.258617    0.143265          0.143953            7113  0.941709  ...  0.529366   0.518847  0.546091      0.508502       0.000789

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_TEM Time elapsed: 7.979091739654541 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_Naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:27:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 395, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.538 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:28:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 381, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.51 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:28:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 365, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.469 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:29:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 357, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.442 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:29:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 407, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.501 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 18:30:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.396 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 18:30:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.359 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 18:31:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 824, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.922 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 18:32:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 816, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.926 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 18:34:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 301, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.307 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 18:35:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 302, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.289 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 18:35:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 832, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.87 min
==========
Testing lambda: 0.001 starting at 2024-09-19 18:37:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 348, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.283 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 18:37:37 Max_iter: 1000
At iteration 361, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.261 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 18:37:53 Max_iter: 1000
At iteration 333, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.242 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 18:38:08 Max_iter: 1000
At iteration 322, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.215 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 18:38:21 Max_iter: 1000
At iteration 319, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.212 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 18:38:33 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.213 min
==========
Testing lambda: 0.01 starting at 2024-09-19 18:38:46 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.215 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 18:38:59 Max_iter: 1000
At iteration 353, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.225 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:39:12 Max_iter: 1000
At iteration 278, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.181 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:39:23 Max_iter: 1000
At iteration 302, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.196 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:39:35 Max_iter: 1000
At iteration 242, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.159 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:39:45 Max_iter: 1000
At iteration 186, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.127 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:39:52 Max_iter: 1000
At iteration 101, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.077 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:39:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:39:58 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:39:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:40:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:40:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:40:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.378090    0.095084          0.095414           10399  0.989878  ...  0.845009   0.774974  0.852023      0.345498       0.000024
0.000015    0.353185    0.104767          0.104648            9714  0.990475  ...  0.852170   0.788009  0.859311      0.358843       0.000023
0.000022    0.320499    0.116931          0.117575            8815  0.990437  ...  0.857760   0.801752  0.865248      0.372677       0.000024
0.000032    0.288431    0.130834          0.131117            7933  0.990692  ...  0.860318   0.816027  0.868468      0.386690       0.000045
0.000046    0.256035    0.148213          0.148353            7042  0.991534  ...  0.874610   0.834096  0.882033      0.401295       0.000027

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD8_Naive Time elapsed: 12.3762313524882 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:40:34 Max_iter: 1000
At iteration 480, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.583 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:41:09 Max_iter: 1000
At iteration 422, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.544 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:41:42 Max_iter: 1000
At iteration 514, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.608 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:42:18 Max_iter: 1000
At iteration 484, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.564 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:42:52 Max_iter: 1000
At iteration 487, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.537 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 18:43:24 Max_iter: 1000
At iteration 476, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.506 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 18:43:55 Max_iter: 1000
At iteration 460, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.478 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 18:44:23 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.446 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 18:44:50 Max_iter: 1000
At iteration 409, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.402 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 18:45:14 Max_iter: 1000
At iteration 403, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.382 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 18:45:37 Max_iter: 1000
At iteration 386, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.345 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 18:45:58 Max_iter: 1000
At iteration 357, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.3 min
==========
Testing lambda: 0.001 starting at 2024-09-19 18:46:16 Max_iter: 1000
At iteration 352, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.277 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 18:46:33 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.249 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 18:46:48 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.228 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 18:47:01 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.22 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 18:47:14 Max_iter: 1000
At iteration 328, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.213 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 18:47:27 Max_iter: 1000
At iteration 328, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.213 min
==========
Testing lambda: 0.01 starting at 2024-09-19 18:47:40 Max_iter: 1000
At iteration 348, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.223 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 18:47:53 Max_iter: 1000
At iteration 355, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.226 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:48:07 Max_iter: 1000
At iteration 312, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.199 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:48:19 Max_iter: 1000
At iteration 294, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0316227766016838, cost : 0.19 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:48:30 Max_iter: 1000
At iteration 261, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.046415888336127774, cost : 0.169 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:48:40 Max_iter: 1000
At iteration 199, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.133 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:48:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:48:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.014 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:48:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.014 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:48:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.014 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:48:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.014 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:48:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.014 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:48:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.435573    0.213483          0.216216           11980  0.725186  ...  0.067112   0.024793  0.044118      0.447613       0.001047
0.000015    0.420084    0.224719          0.229730           11554  0.731151  ...  0.077439   0.032258  0.055556      0.457041       0.000292
0.000022    0.393179    0.235955          0.243243           10814  0.733037  ...  0.076994   0.031915  0.055046      0.466929       0.001221
0.000032    0.367001    0.269663          0.270270           10094  0.765825  ...  0.082307   0.036145  0.061224      0.477762       0.000751
0.000046    0.336896    0.292135          0.297297            9266  0.806035  ...  0.128946   0.064516  0.103896      0.488773       0.000670

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD8_Proliferating Time elapsed: 8.470166448752085 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_TCM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:49:27 Max_iter: 1000
At iteration 460, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.556 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:50:00 Max_iter: 1000
At iteration 484, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.556 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:50:34 Max_iter: 1000
At iteration 457, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.519 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:51:05 Max_iter: 1000
At iteration 485, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.5 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:51:35 Max_iter: 1000
At iteration 457, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.471 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 18:52:03 Max_iter: 1000
At iteration 443, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.437 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 18:52:29 Max_iter: 1000
At iteration 433, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.408 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 18:52:54 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.369 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 18:53:16 Max_iter: 1000
At iteration 383, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.339 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 18:53:36 Max_iter: 1000
At iteration 373, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.308 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 18:53:55 Max_iter: 1000
At iteration 366, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.286 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 18:54:12 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.275 min
==========
Testing lambda: 0.001 starting at 2024-09-19 18:54:28 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.271 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 18:54:45 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.24 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 18:54:59 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.232 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 18:55:13 Max_iter: 1000
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.215 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 18:55:26 Max_iter: 1000
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.21 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 18:55:38 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.209 min
==========
Testing lambda: 0.01 starting at 2024-09-19 18:55:51 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.214 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 18:56:04 Max_iter: 1000
At iteration 318, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.206 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 18:56:16 Max_iter: 1000
At iteration 309, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.197 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 18:56:28 Max_iter: 1000
At iteration 250, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.164 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 18:56:38 Max_iter: 1000
At iteration 197, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.133 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 18:56:46 Max_iter: 1000
At iteration 91, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.073 min
==========
Testing lambda: 0.1 starting at 2024-09-19 18:56:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 18:56:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 18:56:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 18:56:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 18:56:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 18:56:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 18:56:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.385035    0.096216          0.096077           10590  0.952289  ...  0.538079   0.447257  0.540816      0.459416       0.001027
0.000015    0.356530    0.105196          0.104884            9806  0.955263  ...  0.557198   0.468547  0.560311      0.470859       0.000750
0.000022    0.328352    0.117383          0.116894            9031  0.960434  ...  0.568996   0.509901  0.577031      0.482855       0.000318
0.000032    0.297484    0.129570          0.128903            8182  0.964879  ...  0.621566   0.587744  0.630792      0.495109       0.000647
0.000046    0.265343    0.146248          0.144916            7298  0.964507  ...  0.611657   0.570270  0.620588      0.507810       0.000981

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD8_TCM Time elapsed: 7.646287337938944 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_TEM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 18:57:30 Max_iter: 1000
At iteration 464, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.567 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 18:58:04 Max_iter: 1000
At iteration 445, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.558 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 18:58:37 Max_iter: 1000
At iteration 459, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.53 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 18:59:09 Max_iter: 1000
At iteration 464, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.511 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 18:59:40 Max_iter: 1000
At iteration 489, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.505 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 19:00:10 Max_iter: 1000
At iteration 470, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.447 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 19:00:37 Max_iter: 1000
At iteration 459, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.422 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 19:01:02 Max_iter: 1000
At iteration 424, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.383 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 19:01:25 Max_iter: 1000
At iteration 421, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.369 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 19:01:47 Max_iter: 1000
At iteration 400, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.335 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 19:02:08 Max_iter: 1000
At iteration 385, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.336 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 19:02:28 Max_iter: 1000
At iteration 372, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.311 min
==========
Testing lambda: 0.001 starting at 2024-09-19 19:02:46 Max_iter: 1000
At iteration 359, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.275 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 19:03:03 Max_iter: 1000
At iteration 344, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.253 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 19:03:18 Max_iter: 1000
At iteration 345, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.242 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 19:03:33 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.228 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 19:03:46 Max_iter: 1000
At iteration 346, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.222 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 19:04:00 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.213 min
==========
Testing lambda: 0.01 starting at 2024-09-19 19:04:12 Max_iter: 1000
At iteration 348, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.222 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 19:04:26 Max_iter: 1000
At iteration 407, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.256 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 19:04:41 Max_iter: 1000
At iteration 370, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.233 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 19:04:55 Max_iter: 1000
At iteration 287, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.185 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 19:05:06 Max_iter: 1000
At iteration 207, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.139 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 19:05:15 Max_iter: 1000
At iteration 190, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.13 min
==========
Testing lambda: 0.1 starting at 2024-09-19 19:05:22 Max_iter: 1000
At iteration 90, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.07 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 19:05:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 19:05:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 19:05:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 19:05:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 19:05:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 19:05:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.379181    0.095987          0.094946           10429  0.976692  ...  0.746274   0.677540  0.760858      0.377950       0.000510
0.000015    0.350931    0.105609          0.104879            9652  0.975529  ...  0.746391   0.687800  0.762108      0.391250       0.001274
0.000022    0.321880    0.116405          0.115396            8853  0.977732  ...  0.765810   0.708171  0.780279      0.404958       0.001508
0.000032    0.291449    0.129899          0.128834            8016  0.978411  ...  0.773470   0.727548  0.788409      0.419050       0.001032
0.000046    0.257926    0.145036          0.144318            7094  0.978129  ...  0.791520   0.760042  0.806054      0.433397       0.001093

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD8_TEM Time elapsed: 8.172602172692617 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Doublet
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 19:06:05 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.594 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 19:06:40 Max_iter: 1000
At iteration 469, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.585 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 19:07:15 Max_iter: 1000
At iteration 450, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.58 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 19:07:50 Max_iter: 1000
At iteration 407, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.509 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 19:08:21 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.53 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 19:08:53 Max_iter: 1000
At iteration 458, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.5 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 19:09:23 Max_iter: 1000
At iteration 466, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.482 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 19:09:51 Max_iter: 1000
At iteration 471, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.458 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 19:10:19 Max_iter: 1000
At iteration 447, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.419 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 19:10:44 Max_iter: 1000
At iteration 424, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.384 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 19:11:07 Max_iter: 1000
At iteration 402, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.348 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 19:11:28 Max_iter: 1000
At iteration 374, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.316 min
==========
Testing lambda: 0.001 starting at 2024-09-19 19:11:47 Max_iter: 1000
At iteration 358, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.284 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 19:12:04 Max_iter: 1000
At iteration 345, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.283 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 19:12:21 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.247 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 19:12:36 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.232 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 19:12:50 Max_iter: 1000
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.216 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 19:13:03 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.217 min
==========
Testing lambda: 0.01 starting at 2024-09-19 19:13:16 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.222 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 19:13:29 Max_iter: 1000
At iteration 338, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.014677992676220683, cost : 0.216 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 19:13:42 Max_iter: 1000
At iteration 279, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.02154434690031883, cost : 0.182 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 19:13:53 Max_iter: 1000
At iteration 282, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0316227766016838, cost : 0.183 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 19:14:04 Max_iter: 1000
At iteration 243, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.046415888336127774, cost : 0.162 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 19:14:14 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.148 min
==========
Testing lambda: 0.1 starting at 2024-09-19 19:14:22 Max_iter: 1000
At iteration 168, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0999999999999999, cost : 0.117 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 19:14:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.019 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 19:14:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 19:14:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 19:14:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 19:14:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-19 19:14:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.436082    0.167785          0.165266           11994  0.872904  ...  0.232924   0.164103  0.224561      0.432037       0.000168
0.000015    0.410595    0.185682          0.182073           11293  0.869893  ...  0.224125   0.167630  0.220532      0.442603       0.000229
0.000022    0.385835    0.203579          0.200280           10612  0.863743  ...  0.211387   0.166667  0.211382      0.453634       0.000206
0.000032    0.358348    0.223714          0.221289            9856  0.891772  ...  0.274085   0.209877  0.269841      0.465023       0.000628
0.000046    0.326752    0.246085          0.243697            8987  0.881671  ...  0.245568   0.212598  0.248848      0.476256       0.000712

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
Doublet Time elapsed: 8.673364833990734 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Eryth
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 19:15:08 Max_iter: 1000
At iteration 509, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.584 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 19:15:43 Max_iter: 1000
At iteration 440, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.52 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 19:16:15 Max_iter: 1000
At iteration 410, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.47 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 19:16:43 Max_iter: 1000
At iteration 486, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.497 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 19:17:13 Max_iter: 1000
At iteration 466, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.464 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 19:17:41 Max_iter: 1000
At iteration 449, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.428 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 19:18:06 Max_iter: 1000
At iteration 435, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.402 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 19:18:30 Max_iter: 1000
At iteration 411, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.362 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 19:18:52 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.337 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 19:19:12 Max_iter: 1000
At iteration 371, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.298 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 19:19:30 Max_iter: 1000
At iteration 360, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.27 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 19:19:46 Max_iter: 1000
At iteration 345, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.25 min
==========
Testing lambda: 0.001 starting at 2024-09-19 19:20:01 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.238 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 19:20:16 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.226 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 19:20:29 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.213 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 19:20:42 Max_iter: 1000
At iteration 350, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.226 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 19:20:56 Max_iter: 1000
At iteration 355, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.229 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 19:21:09 Max_iter: 1000
At iteration 288, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.192 min
==========
Testing lambda: 0.01 starting at 2024-09-19 19:21:21 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.009999999999999995, cost : 0.216 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 19:21:34 Max_iter: 1000
At iteration 380, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220683, cost : 0.242 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 19:21:48 Max_iter: 1000
At iteration 292, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.02154434690031883, cost : 0.189 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 19:22:00 Max_iter: 1000
At iteration 208, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.139 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 19:22:08 Max_iter: 1000
At iteration 262, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.17 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 19:22:18 Max_iter: 1000
At iteration 161, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.112 min
==========
Testing lambda: 0.1 starting at 2024-09-19 19:22:25 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 19:22:26 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 19:22:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 19:22:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 19:22:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 19:22:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 19:22:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.364165    0.084337          0.089552           10016  0.882122  ...  0.457281   0.305556  0.423077      0.461487       0.000085
0.000015    0.343041    0.096386          0.089552            9435  0.944921  ...  0.485661   0.315789  0.444444      0.471555       0.000147
0.000022    0.317336    0.096386          0.104478            8728  0.978106  ...  0.479359   0.307692  0.436364      0.482990       0.000302
0.000032    0.277887    0.108434          0.119403            7643  0.967662  ...  0.501177   0.366667  0.478261      0.494804       0.001059
0.000046    0.240474    0.132530          0.134328            6614  0.989417  ...  0.529468   0.375000  0.500000      0.507207       0.000653

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
Eryth Time elapsed: 7.517399009068807 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for HSPC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 19:23:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 404, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.0 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 19:24:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 704, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.601 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 19:25:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 782, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.324 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 19:27:59 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 3.16227766016838e-05, cost : 4.0 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 19:31:59 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 3.989 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 19:35:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 828, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.553 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 19:37:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 835, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 1.495 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 19:39:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 341, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.717 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 19:39:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 283, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.395 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 19:40:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 568, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.305 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 19:41:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 737, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.314 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 19:42:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 542, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.176 min
==========
Testing lambda: 0.001 starting at 2024-09-19 19:43:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 575, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 1.202 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 19:45:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 517, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 1.172 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 19:46:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 640, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 1.259 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 19:47:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 650, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 1.115 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 19:48:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 380, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.273 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 19:48:57 Max_iter: 1000
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.201 min
==========
Testing lambda: 0.01 starting at 2024-09-19 19:49:09 Max_iter: 1000
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.206 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 19:49:21 Max_iter: 1000
At iteration 300, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.194 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 19:49:33 Max_iter: 1000
At iteration 354, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.02154434690031883, cost : 0.227 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 19:49:46 Max_iter: 1000
At iteration 273, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.179 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 19:49:57 Max_iter: 1000
At iteration 255, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.167 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 19:50:07 Max_iter: 1000
At iteration 266, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.172 min
==========
Testing lambda: 0.1 starting at 2024-09-19 19:50:17 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 19:50:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 19:50:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 19:50:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 19:50:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 19:50:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 19:50:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.475785    0.163569          0.167464           13086  0.999825  ...  0.572701   0.331492  0.497925      0.398766       0.000259
0.000015    0.366092    0.234201          0.239234           10069  0.999738  ...  0.580907   0.340909  0.508475      0.159304       0.487881
0.000022    0.325007    0.263941          0.267943            8939  0.999825  ...  0.654732   0.431655  0.603015      0.148768       0.005930
0.000032    0.269524    0.304833          0.306220            7413  0.999825  ...  0.747291   0.560748  0.718563      0.140083       0.001373
0.000046    0.230912    0.338290          0.344498            6351  0.999913  ...  0.806443   0.652174  0.789474      0.139272       0.004359

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
HSPC Time elapsed: 27.474173839886983 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for ILC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 19:50:56 Max_iter: 1000
At iteration 488, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.581 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 19:51:30 Max_iter: 1000
At iteration 463, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.534 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 19:52:02 Max_iter: 1000
At iteration 490, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.531 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 19:52:34 Max_iter: 1000
At iteration 477, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.505 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 19:53:05 Max_iter: 1000
At iteration 468, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.476 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 19:53:33 Max_iter: 1000
At iteration 446, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.442 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 19:54:00 Max_iter: 1000
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.403 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 19:54:24 Max_iter: 1000
At iteration 415, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.377 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 19:54:46 Max_iter: 1000
At iteration 394, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.347 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 19:55:07 Max_iter: 1000
At iteration 373, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.31 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 19:55:26 Max_iter: 1000
At iteration 373, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.287 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 19:55:43 Max_iter: 1000
At iteration 348, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.26 min
==========
Testing lambda: 0.001 starting at 2024-09-19 19:55:59 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.236 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 19:56:13 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.224 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 19:56:26 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.22 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 19:56:40 Max_iter: 1000
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.211 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 19:56:52 Max_iter: 1000
At iteration 322, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.211 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 19:57:05 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.209 min
==========
Testing lambda: 0.01 starting at 2024-09-19 19:57:17 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.209 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 19:57:30 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.209 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 19:57:43 Max_iter: 1000
At iteration 328, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.208 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 19:57:55 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.208 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 19:58:08 Max_iter: 1000
At iteration 276, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.178 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 19:58:18 Max_iter: 1000
At iteration 215, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.142 min
==========
Testing lambda: 0.1 starting at 2024-09-19 19:58:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 19:58:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 19:58:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 19:58:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 19:58:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 19:58:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 19:58:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.385180    0.097561              0.10           10594  0.922409  ...  0.161670   0.103448  0.148148      0.463274       0.000916
0.000015    0.359839    0.105691              0.11            9897  0.925739  ...  0.233701   0.160000  0.219178      0.474316       0.001118
0.000022    0.328243    0.113821              0.12            9028  0.928802  ...  0.255416   0.190476  0.246154      0.486021       0.000719
0.000032    0.294175    0.130081              0.13            8091  0.938388  ...  0.276469   0.178571  0.253165      0.498068       0.000729
0.000046    0.261816    0.146341              0.15            7201  0.943217  ...  0.457602   0.440000  0.458333      0.510262       0.000654

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
ILC Time elapsed: 7.757493531703949 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for MAIT
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 19:59:06 Max_iter: 1000
At iteration 482, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.57 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 19:59:40 Max_iter: 1000
At iteration 473, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.572 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 20:00:14 Max_iter: 1000
At iteration 463, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.563 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 20:00:48 Max_iter: 1000
At iteration 457, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.464 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 20:01:16 Max_iter: 1000
At iteration 428, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.417 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 20:01:41 Max_iter: 1000
At iteration 419, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.399 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 20:02:05 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.371 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 20:02:27 Max_iter: 1000
At iteration 383, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.349 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 20:02:48 Max_iter: 1000
At iteration 372, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.312 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 20:03:07 Max_iter: 1000
At iteration 368, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.299 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 20:03:25 Max_iter: 1000
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.283 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 20:03:42 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.256 min
==========
Testing lambda: 0.001 starting at 2024-09-19 20:03:57 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.236 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 20:04:11 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.235 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 20:04:25 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.229 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 20:04:39 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.221 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 20:04:52 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.213 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 20:05:05 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.211 min
==========
Testing lambda: 0.01 starting at 2024-09-19 20:05:18 Max_iter: 1000
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.203 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 20:05:30 Max_iter: 1000
At iteration 362, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.23 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 20:05:44 Max_iter: 1000
At iteration 239, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.158 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 20:05:53 Max_iter: 1000
At iteration 235, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.154 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 20:06:03 Max_iter: 1000
At iteration 241, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.158 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 20:06:12 Max_iter: 1000
At iteration 167, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.115 min
==========
Testing lambda: 0.1 starting at 2024-09-19 20:06:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 20:06:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 20:06:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 20:06:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 20:06:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 20:06:24 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 20:06:25 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.365401    0.088933          0.089141           10050  0.986404  ...  0.739429   0.628429  0.735766      0.450259       0.001570
0.000015    0.340023    0.098155          0.098055            9352  0.986995  ...  0.757458   0.652956  0.754829      0.461720       0.000909
0.000022    0.312391    0.108696          0.108590            8592  0.989636  ...  0.776306   0.681818  0.775076      0.473799       0.000952
0.000032    0.280577    0.120553          0.121556            7717  0.989743  ...  0.817429   0.755952  0.819355      0.486241       0.000974
0.000046    0.249236    0.134387          0.134522            6855  0.990768  ...  0.850054   0.812102  0.852843      0.498966       0.001035

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
MAIT Time elapsed: 7.470856050650279 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 20:06:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 624, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.775 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 20:07:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 441, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.694 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 20:08:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 390, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.591 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 20:09:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 541, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.816 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 20:09:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 441, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.696 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 20:10:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.527 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 20:11:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 394, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.633 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 20:11:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 357, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.538 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 20:12:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 367, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.548 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 20:12:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 354, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.557 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 20:13:19 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.482 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 20:13:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 362, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.426 min
==========
Testing lambda: 0.001 starting at 2024-09-19 20:14:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.271 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 20:14:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 332, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.253 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 20:14:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 329, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.264 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 20:15:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 351, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.253 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 20:15:16 Max_iter: 1000
At iteration 350, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.229 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 20:15:29 Max_iter: 1000
At iteration 370, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.236 min
==========
Testing lambda: 0.01 starting at 2024-09-19 20:15:44 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.252 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 20:15:59 Max_iter: 1000
At iteration 394, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.248 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 20:16:14 Max_iter: 1000
At iteration 365, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.23 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 20:16:27 Max_iter: 1000
At iteration 399, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.25 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 20:16:42 Max_iter: 1000
At iteration 464, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.288 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 20:17:00 Max_iter: 1000
At iteration 379, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.239 min
==========
Testing lambda: 0.1 starting at 2024-09-19 20:17:14 Max_iter: 1000
At iteration 250, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.164 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 20:17:24 Max_iter: 1000
At iteration 225, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.15 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 20:17:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 20:17:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 20:17:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 20:17:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 20:17:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.321008    0.131584          0.131276            8829  0.994871  ...  0.908554   0.868399  0.916004      0.116025       0.000059
0.000015    0.304392    0.138607          0.138415            8372  0.994754  ...  0.911010   0.873418  0.918367      0.145130       0.000124
0.000022    0.277850    0.152467          0.152234            7642  0.994721  ...  0.915584   0.879559  0.922598      0.162284       0.000096
0.000032    0.257563    0.166235          0.165477            7084  0.995700  ...  0.917354   0.879223  0.924101      0.180461       0.000087
0.000046    0.219786    0.188505          0.188623            6045  0.995408  ...  0.929282   0.899741  0.935310      0.195610       0.000100

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
NK Time elapsed: 10.825429304440815 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK_CD56bright
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 20:18:10 Max_iter: 1000
At iteration 493, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.598 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 20:18:46 Max_iter: 1000
At iteration 523, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.568 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 20:19:20 Max_iter: 1000
At iteration 505, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.556 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 20:19:53 Max_iter: 1000
At iteration 435, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.497 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 20:20:23 Max_iter: 1000
At iteration 474, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.49 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 20:20:53 Max_iter: 1000
At iteration 449, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.449 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 20:21:20 Max_iter: 1000
At iteration 426, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.413 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 20:21:44 Max_iter: 1000
At iteration 406, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.379 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 20:22:07 Max_iter: 1000
At iteration 405, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.357 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 20:22:29 Max_iter: 1000
At iteration 372, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.317 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 20:22:48 Max_iter: 1000
At iteration 360, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.288 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 20:23:05 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.258 min
==========
Testing lambda: 0.001 starting at 2024-09-19 20:23:20 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.244 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 20:23:35 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.228 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 20:23:49 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.224 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 20:24:02 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.217 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 20:24:15 Max_iter: 1000
At iteration 328, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.219 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 20:24:28 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.213 min
==========
Testing lambda: 0.01 starting at 2024-09-19 20:24:41 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.217 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 20:24:54 Max_iter: 1000
At iteration 354, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.226 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 20:25:08 Max_iter: 1000
At iteration 318, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.203 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 20:25:20 Max_iter: 1000
At iteration 275, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.18 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 20:25:31 Max_iter: 1000
At iteration 234, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.154 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 20:25:40 Max_iter: 1000
At iteration 255, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.166 min
==========
Testing lambda: 0.1 starting at 2024-09-19 20:25:50 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 20:25:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 20:25:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 20:25:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 20:25:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 20:25:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 20:25:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.394161    0.105754          0.106061           10841  0.985767  ...  0.583406   0.428571  0.560241      0.456057       0.000867
0.000015    0.362929    0.118196          0.115530            9982  0.988246  ...  0.697709   0.588957  0.690647      0.467136       0.000742
0.000022    0.335987    0.129082          0.126894            9241  0.989781  ...  0.677327   0.544444  0.664407      0.478788       0.000722
0.000032    0.309519    0.141524          0.140152            8513  0.993858  ...  0.711048   0.592814  0.702128      0.491133       0.000495
0.000046    0.275960    0.155521          0.153409            7590  0.994324  ...  0.726734   0.618750  0.720000      0.503794       0.000642

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
NK_CD56bright Time elapsed: 7.908052543799083 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 20:26:29 Max_iter: 1000
At iteration 527, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.634 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 20:27:07 Max_iter: 1000
At iteration 483, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.594 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 20:27:42 Max_iter: 1000
At iteration 495, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.585 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 20:28:18 Max_iter: 1000
At iteration 465, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.528 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 20:28:49 Max_iter: 1000
At iteration 478, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.526 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 20:29:21 Max_iter: 1000
At iteration 471, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.499 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 20:29:51 Max_iter: 1000
At iteration 450, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.471 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 20:30:19 Max_iter: 1000
At iteration 440, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.44 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 20:30:45 Max_iter: 1000
At iteration 409, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.395 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 20:31:09 Max_iter: 1000
At iteration 410, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.377 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 20:31:32 Max_iter: 1000
At iteration 375, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.328 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 20:31:51 Max_iter: 1000
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.305 min
==========
Testing lambda: 0.001 starting at 2024-09-19 20:32:10 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.271 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 20:32:26 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.246 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 20:32:41 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.227 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 20:32:54 Max_iter: 1000
At iteration 333, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.226 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 20:33:08 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.216 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 20:33:21 Max_iter: 1000
At iteration 344, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.224 min
==========
Testing lambda: 0.01 starting at 2024-09-19 20:33:34 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.009999999999999995, cost : 0.217 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 20:33:47 Max_iter: 1000
At iteration 282, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220683, cost : 0.189 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 20:33:59 Max_iter: 1000
At iteration 316, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.203 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 20:34:11 Max_iter: 1000
At iteration 242, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.16 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 20:34:21 Max_iter: 1000
At iteration 204, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.139 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 20:34:29 Max_iter: 1000
At iteration 148, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.105 min
==========
Testing lambda: 0.1 starting at 2024-09-19 20:34:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 20:34:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 20:34:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 20:34:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 20:34:39 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 20:34:40 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 20:34:41 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.429065    0.169903          0.171254           11801  0.962291  ...  0.500095   0.380000  0.485106      0.442369       0.000823
0.000015    0.404705    0.189320          0.186544           11131  0.974200  ...  0.533241   0.423358  0.522523      0.453099       0.000332
0.000022    0.377000    0.206311          0.204893           10369  0.958751  ...  0.519807   0.402778  0.506550      0.463885       0.000726
0.000032    0.351113    0.223301          0.223242            9657  0.971651  ...  0.613750   0.557692  0.613757      0.475124       0.000328
0.000046    0.322353    0.245146          0.244648            8866  0.966532  ...  0.610769   0.552381  0.610526      0.486861       0.000693

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
NK_Proliferating Time elapsed: 8.375434688727061 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Plasmablast
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 20:35:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 850, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.801 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 20:36:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 427, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.597 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 20:36:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 420, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.568 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 20:37:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 450, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.564 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 20:37:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 455, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.551 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 20:38:20 Max_iter: 1000
At iteration 471, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.524 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 20:38:52 Max_iter: 1000
At iteration 467, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.491 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 20:39:21 Max_iter: 1000
At iteration 484, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.469 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 20:39:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 485, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.463 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 20:40:17 Max_iter: 1000
At iteration 422, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.385 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 20:40:40 Max_iter: 1000
At iteration 377, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.337 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 20:41:00 Max_iter: 1000
At iteration 357, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.295 min
==========
Testing lambda: 0.001 starting at 2024-09-19 20:41:18 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.272 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 20:41:34 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.247 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 20:41:49 Max_iter: 1000
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.227 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 20:42:03 Max_iter: 1000
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.213 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 20:42:16 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.21 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 20:42:28 Max_iter: 1000
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.209 min
==========
Testing lambda: 0.01 starting at 2024-09-19 20:42:41 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.211 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 20:42:54 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220683, cost : 0.224 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 20:43:07 Max_iter: 1000
At iteration 317, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.02154434690031883, cost : 0.207 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 20:43:19 Max_iter: 1000
At iteration 346, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.221 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 20:43:33 Max_iter: 1000
At iteration 279, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.18 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 20:43:44 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.146 min
==========
Testing lambda: 0.1 starting at 2024-09-19 20:43:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 20:43:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 20:43:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 20:43:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 20:43:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 20:43:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 20:43:58 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number  AUC  AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.282577    0.329932          0.327801            7772  1.0   1.0  0.788535   0.623529  0.768116      0.129799       0.004775
0.000015    0.429138    0.207483          0.207469           11803  1.0   1.0  0.602146   0.365517  0.535354      0.443369       0.000055
0.000022    0.405141    0.227891          0.224066           11143  1.0   1.0  0.621998   0.389706  0.560847      0.455022       0.000033
0.000032    0.372055    0.255102          0.248963           10233  1.0   1.0  0.677033   0.460870  0.630952      0.467009       0.000128
0.000046    0.340132    0.282313          0.278008            9355  1.0   1.0  0.715763   0.514563  0.679487      0.479248       0.000094
Exporting resultDF
Exporting result Dict
Plasmablast Time elapsed: 8.860530571142833 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Platelet
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 20:44:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.849 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 20:47:22 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 699, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 2.426 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 20:49:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 687, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.434 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 20:52:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 277, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.207 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 20:53:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 607, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.287 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 20:55:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 568, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.071 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 20:57:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 612, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.284 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 21:00:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 148, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.371 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 21:00:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 612, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 2.22 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 21:02:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 508, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 2.033 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 21:04:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 564, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 2.199 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 21:06:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 594, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 2.262 min
==========
Testing lambda: 0.001 starting at 2024-09-19 21:09:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 586, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 2.47 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 21:11:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 553, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 2.402 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 21:14:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 484, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.257 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 21:16:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 598, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 2.516 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 21:18:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 237, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.688 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 21:19:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 195, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.28 min
==========
Testing lambda: 0.01 starting at 2024-09-19 21:19:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 429, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.009999999999999995, cost : 1.173 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 21:20:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.265 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 21:21:13 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.213 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 21:21:26 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.215 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 21:21:38 Max_iter: 1000
At iteration 300, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.192 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 21:21:50 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.171 min
==========
Testing lambda: 0.1 starting at 2024-09-19 21:22:00 Max_iter: 1000
At iteration 176, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.12 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 21:22:07 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 21:22:09 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 21:22:09 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 21:22:10 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 21:22:11 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 21:22:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.215241    0.065084          0.064202            5920  0.988198  ...  0.903561   0.880952  0.905594      0.302248       0.104931
0.000015    0.220695    0.065084          0.063230            6070  0.987464  ...  0.894820   0.871186  0.897033      0.434879       0.000276
0.000022    0.187027    0.075804          0.074903            5144  0.988582  ...  0.926023   0.931159  0.927798      0.454927       0.000184
0.000032    0.225022    0.065084          0.063230            6189  0.988247  ...  0.906347   0.889655  0.908451      0.475871       0.000056
0.000046    0.197571    0.074273          0.072957            5434  0.990519  ...  0.931322   0.916667  0.932862      0.482765       0.000059

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
Platelet Time elapsed: 37.83588929573695 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Treg
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 21:22:44 Max_iter: 1000
At iteration 401, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.518 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 21:23:15 Max_iter: 1000
At iteration 444, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.512 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 21:23:46 Max_iter: 1000
At iteration 488, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.527 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 21:24:18 Max_iter: 1000
At iteration 431, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.466 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 21:24:45 Max_iter: 1000
At iteration 458, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.454 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 21:25:13 Max_iter: 1000
At iteration 438, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.419 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 21:25:38 Max_iter: 1000
At iteration 418, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.394 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 21:26:01 Max_iter: 1000
At iteration 395, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.357 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 21:26:23 Max_iter: 1000
At iteration 377, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.318 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 21:26:42 Max_iter: 1000
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.291 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 21:27:00 Max_iter: 1000
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.272 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 21:27:16 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.249 min
==========
Testing lambda: 0.001 starting at 2024-09-19 21:27:31 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.263 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 21:27:47 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.248 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 21:28:01 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.23 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 21:28:15 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.221 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 21:28:29 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.216 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 21:28:41 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.218 min
==========
Testing lambda: 0.01 starting at 2024-09-19 21:28:55 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.212 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 21:29:07 Max_iter: 1000
At iteration 289, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.189 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 21:29:19 Max_iter: 1000
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.201 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 21:29:31 Max_iter: 1000
At iteration 274, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0316227766016838, cost : 0.178 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 21:29:41 Max_iter: 1000
At iteration 179, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.046415888336127774, cost : 0.123 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 21:29:49 Max_iter: 1000
At iteration 124, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.092 min
==========
Testing lambda: 0.1 starting at 2024-09-19 21:29:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.02 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 21:29:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 21:29:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 21:29:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.027 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 21:29:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 21:30:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.027 min
==========
Testing lambda: 1.0 starting at 2024-09-19 21:30:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.365583    0.077857          0.076923           10055  0.979849  ...  0.701121   0.568182  0.692521      0.456921       0.000318
0.000015    0.333988    0.087143          0.085868            9186  0.981747  ...  0.731872   0.636842  0.731118      0.468530       0.001971
0.000022    0.301956    0.095714          0.094812            8305  0.982925  ...  0.758997   0.697059  0.762058      0.480663       0.001131
0.000032    0.271415    0.107143          0.106440            7465  0.984131  ...  0.757016   0.699405  0.760518      0.493278       0.001794
0.000046    0.234729    0.124643          0.123435            6456  0.987236  ...  0.797473   0.773026  0.802048      0.505817       0.000658

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
Treg Time elapsed: 7.4416958014170325 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for cDC1
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 21:30:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 676, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.835 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 21:31:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 410, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.617 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 21:32:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 427, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.605 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 21:32:38 Max_iter: 1000
At iteration 412, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.556 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 21:33:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 911, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.8 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 21:33:59 Max_iter: 1000
At iteration 396, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.471 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 21:34:28 Max_iter: 1000
At iteration 393, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.455 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 21:34:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 395, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.435 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 21:35:21 Max_iter: 1000
At iteration 382, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.415 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 21:35:46 Max_iter: 1000
At iteration 389, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.394 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 21:36:10 Max_iter: 1000
At iteration 400, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.366 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 21:36:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 429, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.385 min
==========
Testing lambda: 0.001 starting at 2024-09-19 21:36:55 Max_iter: 1000
At iteration 399, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.317 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 21:37:14 Max_iter: 1000
At iteration 360, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.269 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 21:37:30 Max_iter: 1000
At iteration 341, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.238 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 21:37:44 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.223 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 21:37:57 Max_iter: 1000
At iteration 320, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.23 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 21:38:11 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.204 min
==========
Testing lambda: 0.01 starting at 2024-09-19 21:38:24 Max_iter: 1000
At iteration 329, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.221 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 21:38:37 Max_iter: 1000
At iteration 310, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.199 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 21:38:49 Max_iter: 1000
At iteration 301, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.195 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 21:39:00 Max_iter: 1000
At iteration 281, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0316227766016838, cost : 0.205 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 21:39:13 Max_iter: 1000
At iteration 287, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.185 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 21:39:24 Max_iter: 1000
At iteration 245, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.183 min
==========
Testing lambda: 0.1 starting at 2024-09-19 21:39:35 Max_iter: 1000
At iteration 37, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.062 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 21:39:39 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.021 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 21:39:40 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 21:39:41 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 21:39:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 21:39:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-19 21:39:43 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.427029    0.239130          0.243243           11745  0.999384  ...  0.386972   0.157576  0.270833      0.283328       0.732077
0.000015    0.429465    0.239130          0.243243           11812  0.999532  ...  0.421984   0.180000  0.305085      0.439020       0.000024
0.000022    0.402487    0.260870          0.270270           11070  0.999413  ...  0.445441   0.208000  0.342105      0.449595       0.000017
0.000032    0.378018    0.289855          0.288288           10397  0.999684  ...  0.491223   0.252427  0.400000      0.460462       0.002074
0.000046    0.299229    0.362319          0.369369            8230  0.999858  ...  0.615487   0.380282  0.551020      0.222642       0.000794

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
cDC1 Time elapsed: 9.328793899218242 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for cDC2
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 21:40:19 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.672 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 21:41:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 349, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.618 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 21:41:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.569 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 21:42:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.578 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 21:42:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 396, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.623 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 21:43:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 263, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.44 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 21:43:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 377, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.524 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 21:44:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.437 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 21:44:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 344, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.427 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 21:45:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.37 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 21:45:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 307, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.338 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 21:45:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 354, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.347 min
==========
Testing lambda: 0.001 starting at 2024-09-19 21:46:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 353, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.315 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 21:46:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 270, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.23 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 21:46:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 288, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.228 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 21:47:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 303, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.223 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 21:47:16 Max_iter: 1000
At iteration 341, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.231 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 21:47:30 Max_iter: 1000
At iteration 354, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.231 min
==========
Testing lambda: 0.01 starting at 2024-09-19 21:47:43 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.224 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 21:47:57 Max_iter: 1000
At iteration 310, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.201 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 21:48:09 Max_iter: 1000
At iteration 309, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.202 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 21:48:21 Max_iter: 1000
At iteration 298, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.192 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 21:48:33 Max_iter: 1000
At iteration 258, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.168 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 21:48:43 Max_iter: 1000
At iteration 240, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.159 min
==========
Testing lambda: 0.1 starting at 2024-09-19 21:48:52 Max_iter: 1000
At iteration 197, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.134 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 21:49:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 21:49:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 21:49:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.018 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 21:49:03 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 21:49:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 21:49:05 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.450989    0.204724          0.206836           12404  0.994006  ...  0.790822   0.664850  0.783307      0.388206       0.000044
0.000015    0.426229    0.229062          0.229623           11723  0.996122  ...  0.796461   0.674033  0.789644      0.399002       0.000045
0.000022    0.397433    0.254116          0.255916           10931  0.997146  ...  0.807206   0.697406  0.802653      0.409219       0.000069
0.000032    0.375909    0.275591          0.276950           10339  0.997771  ...  0.839451   0.746177  0.837050      0.420237       0.000037
0.000046    0.348713    0.298497          0.300613            9591  0.997994  ...  0.853584   0.773885  0.852632      0.431300       0.000044

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
cDC2 Time elapsed: 8.929643674691517 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for dnT
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 21:49:38 Max_iter: 1000
At iteration 926, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.732 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 21:50:22 Max_iter: 1000
At iteration 902, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.71 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 21:51:04 Max_iter: 1000
At iteration 912, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.709 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 21:51:47 Max_iter: 1000
At iteration 887, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.695 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 21:52:29 Max_iter: 1000
At iteration 504, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.51 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 21:52:59 Max_iter: 1000
At iteration 440, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.444 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 21:53:26 Max_iter: 1000
At iteration 424, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.421 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 21:53:51 Max_iter: 1000
At iteration 413, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.386 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 21:54:14 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.351 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 21:54:36 Max_iter: 1000
At iteration 374, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.32 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 21:54:55 Max_iter: 1000
At iteration 365, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.292 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 21:55:12 Max_iter: 1000
At iteration 344, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.261 min
==========
Testing lambda: 0.001 starting at 2024-09-19 21:55:28 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.244 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 21:55:43 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.229 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 21:55:56 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.233 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 21:56:10 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.219 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 21:56:23 Max_iter: 1000
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.209 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 21:56:36 Max_iter: 1000
At iteration 319, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.205 min
==========
Testing lambda: 0.01 starting at 2024-09-19 21:56:48 Max_iter: 1000
At iteration 351, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.225 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 21:57:02 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.214 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 21:57:15 Max_iter: 1000
At iteration 272, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.177 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 21:57:25 Max_iter: 1000
At iteration 249, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.162 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 21:57:35 Max_iter: 1000
At iteration 190, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.046415888336127774, cost : 0.129 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 21:57:43 Max_iter: 1000
At iteration 133, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.06812920690579607, cost : 0.096 min
==========
Testing lambda: 0.1 starting at 2024-09-19 21:57:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 21:57:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 21:57:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 21:57:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 21:57:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 21:57:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 21:57:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.242219    0.177700          0.175926            6662  0.940897  ...  0.581840   0.733333  0.568966      0.169259       0.012217
0.000015    0.235020    0.181185          0.175926            6464  0.945144  ...  0.572665   0.756098  0.553571      0.222450       0.001044
0.000022    0.228439    0.181185          0.180556            6283  0.940708  ...  0.635183   0.800000  0.620690      0.288049       0.001359
0.000032    0.225749    0.184669          0.180556            6209  0.947411  ...  0.649213   0.791667  0.638655      0.365227       0.004313
0.000046    0.266143    0.160279          0.157407            7320  0.944852  ...  0.479240   0.568627  0.475410      0.514003       0.000979

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
dnT Time elapsed: 8.418712226549784 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for gdT
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 21:58:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 353, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.674 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 21:59:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 676, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.978 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 22:00:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 815, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.979 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 22:01:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 873, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.017 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 22:02:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 747, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.884 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 22:03:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 693, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.851 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 22:03:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 671, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.797 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 22:04:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 642, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.687 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 22:05:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 633, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.689 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 22:06:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 636, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.677 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 22:06:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 632, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.707 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 22:07:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 627, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.713 min
==========
Testing lambda: 0.001 starting at 2024-09-19 22:08:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 658, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.768 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 22:08:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 704, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.869 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 22:09:45 Max_iter: 1000
At iteration 356, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.245 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 22:10:00 Max_iter: 1000
At iteration 353, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.235 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 22:10:14 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.215 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 22:10:27 Max_iter: 1000
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.207 min
==========
Testing lambda: 0.01 starting at 2024-09-19 22:10:40 Max_iter: 1000
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.2 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 22:10:52 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.212 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 22:11:04 Max_iter: 1000
At iteration 419, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.262 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 22:11:20 Max_iter: 1000
At iteration 266, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.173 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 22:11:30 Max_iter: 1000
At iteration 201, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.136 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 22:11:39 Max_iter: 1000
At iteration 127, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.093 min
==========
Testing lambda: 0.1 starting at 2024-09-19 22:11:44 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.021 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 22:11:45 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 22:11:47 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 22:11:47 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 22:11:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 22:11:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 22:11:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.393543    0.096030          0.095970           10824  0.962825  ...  0.674487   0.601533  0.681128      0.434484       0.000176
0.000015    0.306937    0.129024          0.129098            8442  0.975271  ...  0.718456   0.696347  0.727924      0.227006       0.000027
0.000022    0.264143    0.146996          0.146858            7265  0.978215  ...  0.745164   0.731765  0.753939      0.227799       0.000475
0.000032    0.226513    0.167382          0.168033            6230  0.980880  ...  0.773022   0.764988  0.780906      0.231307       0.000243
0.000046    0.190918    0.190987          0.191257            5251  0.981805  ...  0.786066   0.789604  0.793532      0.236743       0.000455

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
gdT Time elapsed: 13.530077588558196 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for pDC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 22:12:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 837, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.796 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 22:14:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 922, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.841 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 22:16:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.023 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 22:18:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 974, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 2.103 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 22:20:09 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 400, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 1.062 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 22:21:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 934, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.16 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 22:23:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 836, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.23 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 22:25:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 916, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 2.36 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 22:27:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 186, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.374 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 22:28:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 705, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 2.281 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 22:30:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 929, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 2.475 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 22:33:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 821, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 2.455 min
==========
Testing lambda: 0.001 starting at 2024-09-19 22:35:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 759, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 2.241 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 22:37:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 673, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 2.123 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 22:39:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 622, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.052 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 22:41:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 264, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.413 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 22:42:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 246, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.241 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 22:42:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 303, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.207 min
==========
Testing lambda: 0.01 starting at 2024-09-19 22:42:50 Max_iter: 1000
At iteration 370, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.256 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 22:43:05 Max_iter: 1000
At iteration 378, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.24 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 22:43:20 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.02154434690031883, cost : 0.232 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 22:43:34 Max_iter: 1000
At iteration 287, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0316227766016838, cost : 0.19 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 22:43:45 Max_iter: 1000
At iteration 249, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.177 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 22:43:56 Max_iter: 1000
At iteration 262, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.172 min
==========
Testing lambda: 0.1 starting at 2024-09-19 22:44:06 Max_iter: 1000
At iteration 57, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.051 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 22:44:09 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.024 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 22:44:11 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.021 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 22:44:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.019 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 22:44:13 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 22:44:14 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 22:44:15 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC  ...       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.339478    0.242881          0.243478            9337  0.999595  ...  0.815080   0.673267  0.802360      0.112886       0.001885
0.000015    0.292939    0.279732          0.280435            8057  0.999114  ...  0.895125   0.809524  0.891803      0.110228       0.000275
0.000022    0.261671    0.304858          0.304348            7197  0.999908  ...  0.924401   0.856250  0.922559      0.116993       0.040313
0.000032    0.239383    0.328308          0.330435            6584  0.999954  ...  0.912897   0.835366  0.910299      0.127443       0.002960
0.000046    0.321990    0.254606          0.254348            8856  0.992617  ...  0.864308   0.755556  0.858044      0.442027       0.000137

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
pDC Time elapsed: 32.01470003128052 minutes.
***** Finished lambda tuning
====================

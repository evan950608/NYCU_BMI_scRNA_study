/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 121, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 0.216 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 13:31:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 93, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.169 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 13:31:25 Max_iter: 1000
At iteration 75, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.119 min
==========
Testing lambda: 0.001 starting at 2024-09-19 13:31:32 Max_iter: 1000
At iteration 83, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.104 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 13:31:38 Max_iter: 1000
At iteration 66, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.082 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 13:31:43 Max_iter: 1000
At iteration 61, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.072 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 13:31:47 Max_iter: 1000
At iteration 51, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.061 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 13:31:51 Max_iter: 1000
At iteration 44, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.056 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 13:31:54 Max_iter: 1000
At iteration 47, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.056 min
==========
Testing lambda: 0.01 starting at 2024-09-19 13:31:58 Max_iter: 1000
At iteration 45, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.052 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 13:32:01 Max_iter: 1000
At iteration 41, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.049 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 13:32:04 Max_iter: 1000
At iteration 31, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.044 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 13:32:06 Max_iter: 1000
At iteration 28, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.043 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 13:32:09 Max_iter: 1000
At iteration 22, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.034 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 13:32:11 Max_iter: 1000
At iteration 21, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.032 min
==========
Testing lambda: 0.1 starting at 2024-09-19 13:32:13 Max_iter: 1000
At iteration 15, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.028 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 13:32:15 Max_iter: 1000
At iteration 10, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.038 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 13:32:17 Max_iter: 1000
At iteration 4, Convergence with loss difference, Device: cuda
lambda is : 0.21544346900318834, cost : 0.041 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 13:32:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.021 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 13:32:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 13:32:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.018 min
==========
Testing lambda: 1.0 starting at 2024-09-19 13:32:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.322644    0.123270          0.123437            8874  0.990883  0.971270  0.898545   0.875896  0.915476      0.115126       0.010032
0.000015    0.291885    0.137505          0.137551            8028  0.990584  0.969443  0.893276   0.872531  0.911179      0.129130       0.005795
0.000022    0.263598    0.150603          0.150675            7250  0.991115  0.970659  0.895480   0.878170  0.913115      0.144308       0.005276
0.000032    0.233457    0.168149          0.168379            6421  0.991807  0.971747  0.897971   0.882514  0.915230      0.158446       0.006725
0.000046    0.216332    0.182681          0.182803            5950  0.990535  0.967859  0.894926   0.883081  0.912796      0.173441       0.000056
Exporting resultDF
Exporting result Dict
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:947: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax1 = plt.subplots(figsize = (fig_width,fig_height))
CD8_T Time elapsed: 5.027367194493611 minutes.
Z-transformed rep_cells adata: (59897, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for DC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.5
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 13:32:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 70, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.47 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 13:33:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 303, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.413 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 13:34:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 69, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.445 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 13:35:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 215, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.526 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 13:35:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 220, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.623 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 13:36:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 243, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.698 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 13:37:09 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 219, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.692 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 13:37:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 204, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.648 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 13:38:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.782 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 13:40:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 465, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 4.304 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 13:44:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 2.445 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 13:47:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 107, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.667 min
==========
Testing lambda: 0.001 starting at 2024-09-19 13:47:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 126, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.576 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 13:48:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 80, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.383 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 13:48:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 124, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.863 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 13:49:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 137, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 1.054 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 13:50:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 130, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.99 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 13:51:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 105, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.747 min
==========
Testing lambda: 0.01 starting at 2024-09-19 13:52:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 42, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.009999999999999995, cost : 0.186 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 13:52:29 Max_iter: 1000
At iteration 40, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.056 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 13:52:33 Max_iter: 1000
At iteration 52, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.06 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 13:52:36 Max_iter: 1000
At iteration 47, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.058 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 13:52:40 Max_iter: 1000
At iteration 50, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.063 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 13:52:43 Max_iter: 1000
At iteration 44, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.058 min
==========
Testing lambda: 0.1 starting at 2024-09-19 13:52:47 Max_iter: 1000
At iteration 32, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.043 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 13:52:50 Max_iter: 1000
At iteration 12, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.032 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 13:52:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 13:52:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 13:52:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 13:52:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.039 min
==========
Testing lambda: 1.0 starting at 2024-09-19 13:52:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.371401    0.263544          0.263899           10215  0.997908  0.987962  0.924406   0.887013  0.927989      0.049428      19.704073
0.000015    0.261744    0.375282          0.374736            7199  0.998109  0.990128  0.950588   0.933151  0.953310      0.055574       0.003252
0.000022    0.359875    0.281744          0.281668            9898  0.997980  0.988763  0.926992   0.891645  0.930518      0.083851       0.040846
0.000032    0.213896    0.432280          0.432090            5883  0.998780  0.991251  0.956963   0.943526  0.959384      0.090223       0.003232
0.000046    0.193535    0.456546          0.456721            5323  0.998721  0.991125  0.956963   0.943526  0.959384      0.116558       0.003660
Exporting resultDF
Exporting result Dict
DC Time elapsed: 20.128953667481742 minutes.
Z-transformed rep_cells adata: (59897, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.5
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 13:53:32 Max_iter: 1000
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.776 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 13:54:19 Max_iter: 1000
OWL-QN did not convergence, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.764 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 13:55:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 937, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.748 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 13:55:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 310, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.41 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 13:56:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 190, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.462 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 13:56:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 120, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.269 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 13:56:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 101, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.271 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 13:57:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 98, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.27 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 13:57:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 99, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.187 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 13:57:42 Max_iter: 1000
At iteration 53, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 0.143 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 13:57:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 41, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.119 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 13:57:57 Max_iter: 1000
At iteration 59, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.095 min
==========
Testing lambda: 0.001 starting at 2024-09-19 13:58:03 Max_iter: 1000
At iteration 61, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.082 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 13:58:08 Max_iter: 1000
At iteration 43, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.065 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 13:58:12 Max_iter: 1000
At iteration 67, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.078 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 13:58:16 Max_iter: 1000
At iteration 84, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.087 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 13:58:22 Max_iter: 1000
At iteration 91, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.089 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 13:58:27 Max_iter: 1000
At iteration 67, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.076 min
==========
Testing lambda: 0.01 starting at 2024-09-19 13:58:32 Max_iter: 1000
At iteration 75, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.08 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 13:58:36 Max_iter: 1000
At iteration 71, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.087 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 13:58:42 Max_iter: 1000
At iteration 56, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.073 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 13:58:46 Max_iter: 1000
At iteration 91, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.099 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 13:58:52 Max_iter: 1000
At iteration 72, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.077 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 13:58:57 Max_iter: 1000
At iteration 79, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.088 min
==========
Testing lambda: 0.1 starting at 2024-09-19 13:59:02 Max_iter: 1000
At iteration 52, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.072 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 13:59:06 Max_iter: 1000
At iteration 46, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.069 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 13:59:11 Max_iter: 1000
At iteration 43, Convergence with loss difference, Device: cuda
lambda is : 0.21544346900318834, cost : 0.108 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 13:59:17 Max_iter: 1000
At iteration 12, Convergence with loss difference, Device: cuda
lambda is : 0.3162277660168378, cost : 0.031 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 13:59:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.019 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 13:59:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.018 min
==========
Testing lambda: 1.0 starting at 2024-09-19 13:59:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.018 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.184846    0.375893          0.375463            5084  0.991671  0.969181  0.928090   0.917874  0.939896      0.016143       0.007547
0.000015    0.177756    0.383085          0.382297            4889  0.991937  0.969472  0.929779   0.917268  0.941264      0.021148       0.006689
0.000022    0.169321    0.389104          0.387917            4657  0.991863  0.968655  0.926945   0.916506  0.938937      0.027411       0.005903
0.000032    0.174375    0.397011          0.396666            4796  0.990872  0.966072  0.923756   0.910441  0.936223      0.035928       0.011112
0.000046    0.157213    0.425219          0.425022            4324  0.990970  0.966883  0.924885   0.914616  0.937222      0.043343       0.011156
Exporting resultDF
Exporting result Dict
Mono Time elapsed: 5.972575438022614 minutes.
Z-transformed rep_cells adata: (59897, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.5
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 13:59:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 757, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.755 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 14:00:42 Max_iter: 1000
At iteration 502, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.507 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 14:01:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 161, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.389 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 14:01:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 182, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.404 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 14:02:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 263, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.36 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 14:02:22 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 99, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.293 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 14:02:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 37, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.218 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 14:02:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 106, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.284 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 14:03:09 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 124, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.289 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 14:03:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 106, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.262 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 14:03:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 92, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.228 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 14:03:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 83, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.166 min
==========
Testing lambda: 0.001 starting at 2024-09-19 14:04:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 71, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.187 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 14:04:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 80, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.133 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 14:04:25 Max_iter: 1000
At iteration 64, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.085 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 14:04:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 46, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.111 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 14:04:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 55, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.078 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 14:04:42 Max_iter: 1000
At iteration 47, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.057 min
==========
Testing lambda: 0.01 starting at 2024-09-19 14:04:45 Max_iter: 1000
At iteration 49, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.059 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 14:04:49 Max_iter: 1000
At iteration 44, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.074 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 14:04:53 Max_iter: 1000
At iteration 38, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.05 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 14:04:56 Max_iter: 1000
At iteration 39, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.049 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 14:04:59 Max_iter: 1000
At iteration 29, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.043 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 14:05:02 Max_iter: 1000
At iteration 29, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.043 min
==========
Testing lambda: 0.1 starting at 2024-09-19 14:05:04 Max_iter: 1000
At iteration 17, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.03 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 14:05:06 Max_iter: 1000
At iteration 10, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.023 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 14:05:07 Max_iter: 1000
At iteration 4, Convergence with loss difference, Device: cuda
lambda is : 0.21544346900318834, cost : 0.02 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 14:05:08 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 14:05:09 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 14:05:10 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-19 14:05:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.022 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.245382    0.180766          0.181312            6749  0.997230  0.991254  0.948497   0.929134  0.955982      0.051085       0.006625
0.000015    0.231275    0.192337          0.192585            6361  0.996801  0.990224  0.946150   0.928421  0.954029      0.065134       0.008633
0.000022    0.238765    0.191900          0.192041            6567  0.997309  0.990648  0.946624   0.927111  0.954386      0.084582       0.000249
0.000032    0.201462    0.218426          0.219068            5541  0.997379  0.991711  0.948069   0.930000  0.955652      0.099324       0.015255
0.000046    0.161940    0.248990          0.249491            4454  0.997186  0.991074  0.953768   0.944146  0.960656      0.116297       0.008420
Exporting resultDF
Exporting result Dict
NK Time elapsed: 5.411932114760081 minutes.
Z-transformed rep_cells adata: (59897, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for other
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.5
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 14:05:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 305, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.651 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 14:08:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 110, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.523 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 14:08:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 78, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.513 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 14:09:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 64, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.417 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 14:09:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 67, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.386 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 14:10:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 122, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.91 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 14:11:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 62, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.38 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 14:11:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 84, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.57 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 14:12:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 62, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 0.442 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 14:12:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 93, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 0.664 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 14:13:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 81, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.645 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 14:13:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 104, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.831 min
==========
Testing lambda: 0.001 starting at 2024-09-19 14:14:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 71, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.559 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 14:15:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 118, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.968 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 14:16:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 115, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.974 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 14:17:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 110, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.894 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 14:18:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 135, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 1.168 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 14:19:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 146, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 1.22 min
==========
Testing lambda: 0.01 starting at 2024-09-19 14:20:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 126, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 1.012 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 14:21:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 22, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.091 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 14:21:36 Max_iter: 1000
At iteration 40, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.049 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 14:21:39 Max_iter: 1000
At iteration 37, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.046 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 14:21:42 Max_iter: 1000
At iteration 33, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.045 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 14:21:45 Max_iter: 1000
At iteration 33, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.045 min
==========
Testing lambda: 0.1 starting at 2024-09-19 14:21:47 Max_iter: 1000
At iteration 29, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.04 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 14:21:50 Max_iter: 1000
At iteration 5, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.019 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 14:21:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 14:21:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 14:21:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 14:21:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 14:21:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.345150    0.099942          0.100146            9493  0.957444  0.848988  0.743613   0.700361  0.757319      0.124094       7.904819
0.000015    0.281923    0.122603          0.122807            7754  0.958030  0.847118  0.736386   0.681344  0.749522      0.142489       0.200620
0.000022    0.292030    0.120279          0.120614            8032  0.957804  0.852253  0.739181   0.692857  0.752911      0.228940       0.025661
0.000032    0.253527    0.132481          0.131944            6973  0.958285  0.851699  0.744857   0.710754  0.759076      0.346907       0.995217
0.000046    0.212842    0.155433          0.156067            5854  0.954866  0.846454  0.760411   0.736573  0.774194      0.343718       0.003137
Exporting resultDF
Exporting result Dict
other Time elapsed: 16.287401564915974 minutes.
Z-transformed rep_cells adata: (59897, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for other_T
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.5
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-19 14:22:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 72, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.48 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-19 14:22:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 35, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.397 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-19 14:23:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 198, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.415 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-19 14:23:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 174, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.43 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-19 14:24:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 227, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.388 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-19 14:24:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 196, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.341 min
==========
Testing lambda: 0.0001 starting at 2024-09-19 14:24:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 96, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.248 min
==========
Testing lambda: 0.000147 starting at 2024-09-19 14:25:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 143, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.256 min
==========
Testing lambda: 0.000215 starting at 2024-09-19 14:25:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 72, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.243 min
==========
Testing lambda: 0.000316 starting at 2024-09-19 14:25:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 96, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.281 min
==========
Testing lambda: 0.000464 starting at 2024-09-19 14:25:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 76, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.248 min
==========
Testing lambda: 0.000681 starting at 2024-09-19 14:26:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 66, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.361 min
==========
Testing lambda: 0.001 starting at 2024-09-19 14:26:34 Max_iter: 1000
At iteration 75, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.125 min
==========
Testing lambda: 0.001468 starting at 2024-09-19 14:26:42 Max_iter: 1000
At iteration 77, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.107 min
==========
Testing lambda: 0.002154 starting at 2024-09-19 14:26:48 Max_iter: 1000
At iteration 76, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.093 min
==========
Testing lambda: 0.003162 starting at 2024-09-19 14:26:54 Max_iter: 1000
At iteration 49, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.068 min
==========
Testing lambda: 0.004642 starting at 2024-09-19 14:26:58 Max_iter: 1000
At iteration 52, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.061 min
==========
Testing lambda: 0.006813 starting at 2024-09-19 14:27:01 Max_iter: 1000
At iteration 47, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.054 min
==========
Testing lambda: 0.01 starting at 2024-09-19 14:27:05 Max_iter: 1000
At iteration 45, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.053 min
==========
Testing lambda: 0.014678 starting at 2024-09-19 14:27:08 Max_iter: 1000
At iteration 43, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.051 min
==========
Testing lambda: 0.021544 starting at 2024-09-19 14:27:11 Max_iter: 1000
At iteration 35, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.044 min
==========
Testing lambda: 0.031623 starting at 2024-09-19 14:27:14 Max_iter: 1000
At iteration 31, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.04 min
==========
Testing lambda: 0.046416 starting at 2024-09-19 14:27:16 Max_iter: 1000
At iteration 24, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.035 min
==========
Testing lambda: 0.068129 starting at 2024-09-19 14:27:18 Max_iter: 1000
At iteration 17, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.028 min
==========
Testing lambda: 0.1 starting at 2024-09-19 14:27:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-19 14:27:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-19 14:27:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-19 14:27:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-19 14:27:24 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-19 14:27:25 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-19 14:27:26 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.368892    0.100926          0.101203           10146  0.976894  0.893859  0.784157   0.739130  0.800554      0.206353       0.095390
0.000015    0.398633    0.091111          0.091219           10964  0.977418  0.895197  0.778298   0.725458  0.794533      0.401139       0.005879
0.000022    0.270942    0.141852          0.142274            7452  0.980002  0.895994  0.788922   0.747841  0.805207      0.210766       0.003573
0.000032    0.236947    0.160185          0.160880            6517  0.980865  0.904076  0.799014   0.755383  0.814299      0.219822       0.003879
0.000046    0.199280    0.185000          0.184933            5481  0.980516  0.901032  0.815088   0.794659  0.830207      0.229370       0.002597
Exporting resultDF
Exporting result Dict
other_T Time elapsed: 5.104465365409851 minutes.
***** Finished lambda tuning
====================
nohup: ignoring input
Z-transformed rep_cells adata: (57515, 27504) <class 'numpy.ndarray'>
all cell types: ['ASDC', 'B_intermediate', 'B_memory', 'B_naive', 'CD14_Mono', 'CD16_Mono', 'CD4_CTL', 'CD4_Naive', 'CD4_Proliferating', 'CD4_TCM', 'CD4_TEM', 'CD8_Naive', 'CD8_Proliferating', 'CD8_TCM', 'CD8_TEM', 'Doublet', 'Eryth', 'HSPC', 'ILC', 'MAIT', 'NK', 'NK_CD56bright', 'NK_Proliferating', 'Plasmablast', 'Platelet', 'Treg', 'cDC1', 'cDC2', 'dnT', 'gdT', 'pDC']
====================
Queue ['ASDC', 'B_intermediate', 'B_memory', 'B_naive', 'CD14_Mono', 'CD16_Mono', 'CD4_CTL', 'CD4_Naive', 'CD4_Proliferating', 'CD4_TCM', 'CD4_TEM', 'CD8_Naive', 'CD8_Proliferating', 'CD8_TCM', 'CD8_TEM', 'Doublet', 'Eryth', 'HSPC', 'ILC', 'MAIT', 'NK', 'NK_CD56bright', 'NK_Proliferating', 'Plasmablast', 'Platelet', 'Treg', 'cDC1', 'cDC2', 'dnT', 'gdT', 'pDC']
====================
Subsetted raw count adata: (57515, 27504) <class 'anndata._core.views.SparseCSCView'>
***** Starting tuning
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for ASDC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 15:20:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999997e-06, cost : 6.512 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 15:26:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 605, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.512 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 15:27:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 631, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.489 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 15:27:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 219, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.39 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 15:28:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 201, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.359 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 15:28:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 201, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.336 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 15:28:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 186, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.31 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 15:29:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 178, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.272 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 15:29:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 763, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 2.186 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 15:31:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 468, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.419 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 15:31:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 436, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.352 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 15:32:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 567, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.386 min
==========
Testing lambda: 0.001 starting at 2024-09-25 15:32:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 562, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.367 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 15:32:59 Max_iter: 1000
At iteration 152, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.109 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 15:33:06 Max_iter: 1000
At iteration 130, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.098 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 15:33:11 Max_iter: 1000
At iteration 122, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.091 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 15:33:17 Max_iter: 1000
At iteration 91, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.072 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 15:33:21 Max_iter: 1000
At iteration 70, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.059 min
==========
Testing lambda: 0.01 starting at 2024-09-25 15:33:25 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.017 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 15:33:26 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.016 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 15:33:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.02154434690031883, cost : 0.016 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 15:33:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.016 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 15:33:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.016 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 15:33:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.015 min
==========
Testing lambda: 0.1 starting at 2024-09-25 15:33:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 15:33:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 15:33:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 15:33:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 15:33:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 15:33:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 15:33:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.380308    0.250000          0.250000           10460  0.999944  0.946173  0.816248   0.666667  0.800000      0.272160       1.740531
0.000015    0.110457    0.592105          0.596774            3038  1.000000  1.000000  0.963582   1.000000  0.962963      0.067116       0.001787
0.000022    0.105694    0.592105          0.596774            2907  1.000000  1.000000  0.963582   1.000000  0.962963      0.091310       0.067113
0.000032    0.339732    0.289474          0.290323            9344  0.999944  0.946173  0.881764   0.777778  0.875000      0.668022       0.000048
0.000046    0.307955    0.315789          0.322581            8470  0.999944  0.934412  0.966050   0.933333  0.965517      0.671128       0.000044
Exporting resultDF
Exporting result Dict
ASDC Time elapsed: 13.66050925652186 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for B_intermediate
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 15:34:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 408, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.584 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 15:34:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 405, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.532 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 15:35:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 384, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.503 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 15:35:45 Max_iter: 1000
At iteration 371, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.474 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 15:36:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 367, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.449 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 15:36:40 Max_iter: 1000
At iteration 357, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.393 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 15:37:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 351, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.381 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 15:37:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 344, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.368 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 15:37:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.399 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 15:38:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 438, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.125 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 15:39:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 378, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.736 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 15:40:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 312, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.266 min
==========
Testing lambda: 0.001 starting at 2024-09-25 15:40:20 Max_iter: 1000
At iteration 352, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.262 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 15:40:36 Max_iter: 1000
At iteration 300, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.206 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 15:40:49 Max_iter: 1000
At iteration 284, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.189 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 15:41:00 Max_iter: 1000
At iteration 280, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.186 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 15:41:11 Max_iter: 1000
At iteration 272, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.178 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 15:41:22 Max_iter: 1000
At iteration 253, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.166 min
==========
Testing lambda: 0.01 starting at 2024-09-25 15:41:32 Max_iter: 1000
At iteration 234, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.155 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 15:41:41 Max_iter: 1000
At iteration 216, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.144 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 15:41:50 Max_iter: 1000
At iteration 227, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.151 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 15:41:59 Max_iter: 1000
At iteration 221, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.147 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 15:42:07 Max_iter: 1000
At iteration 148, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.105 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 15:42:14 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.021 min
==========
Testing lambda: 0.1 starting at 2024-09-25 15:42:15 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 15:42:16 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 15:42:17 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 15:42:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 15:42:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 15:42:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 15:42:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.386816    0.130212          0.127621           10639  0.976254  0.878213  0.794872   0.729231  0.796639      0.593301       0.000038
0.000015    0.359766    0.141917          0.140383            9895  0.979422  0.881274  0.806530   0.750000  0.808874      0.598567       0.002092
0.000022    0.327916    0.157279          0.155880            9019  0.980328  0.887125  0.804373   0.739938  0.806071      0.603782       0.000019
0.000032    0.292176    0.176298          0.175023            8036  0.981111  0.890223  0.811033   0.761290  0.813793      0.609048       0.003796
0.000046    0.256763    0.198244          0.196901            7062  0.982079  0.894655  0.827211   0.781046  0.829861      0.614108       0.000028
Exporting resultDF
Exporting result Dict
B_intermediate Time elapsed: 8.369644053777058 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for B_memory
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 15:42:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 921, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.639 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 15:45:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.53 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 15:47:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 902, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.541 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 15:49:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 876, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 2.305 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 15:51:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 331, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.977 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 15:52:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 350, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.053 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 15:53:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 429, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 1.375 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 15:55:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 401, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.236 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 15:56:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 195, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.318 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 15:56:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 341, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.944 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 15:57:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 355, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.971 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 15:58:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 362, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.05 min
==========
Testing lambda: 0.001 starting at 2024-09-25 15:59:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 254, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.502 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 16:00:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 509, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 1.818 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 16:02:09 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 273, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.535 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 16:02:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 287, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.507 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 16:03:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 237, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.216 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 16:03:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 282, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.201 min
==========
Testing lambda: 0.01 starting at 2024-09-25 16:03:36 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.209 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 16:03:49 Max_iter: 1000
At iteration 266, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.172 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 16:03:59 Max_iter: 1000
At iteration 227, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.15 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 16:04:08 Max_iter: 1000
At iteration 204, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.137 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 16:04:16 Max_iter: 1000
At iteration 211, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.141 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 16:04:25 Max_iter: 1000
At iteration 90, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.071 min
==========
Testing lambda: 0.1 starting at 2024-09-25 16:04:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 16:04:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 16:04:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 16:04:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 16:04:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 16:04:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 16:04:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.335733    0.142276          0.142959            9234  0.995516  0.959416  0.893824   0.851955  0.895742      0.275307       0.000079
0.000015    0.366129    0.130662          0.131523           10070  0.996336  0.961144  0.903814   0.864789  0.905605      0.525312       0.000114
0.000022    0.267670    0.176539          0.176555            7362  0.998015  0.968454  0.904224   0.862745  0.905882      0.279717       0.000073
0.000032    0.232003    0.199768          0.200143            6381  0.998023  0.967229  0.909900   0.870423  0.911504      0.292787       0.000080
0.000046    0.266616    0.184669          0.185132            7333  0.996496  0.966299  0.911460   0.881844  0.913433      0.541543       0.000074
Exporting resultDF
Exporting result Dict
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:948: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax1 = plt.subplots(figsize = (fig_width,fig_height))
B_memory Time elapsed: 21.851560691992443 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for B_naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 16:05:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 775, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.267 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 16:07:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 781, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 2.352 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 16:09:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 756, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.264 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 16:12:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 954, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 2.314 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 16:14:19 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.281 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 16:16:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.266 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 16:18:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.268 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 16:21:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 0.00014677992676220676, cost : 2.149 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 16:23:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 299, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.932 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 16:24:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 885, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 2.046 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 16:26:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 759, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.807 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 16:28:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 722, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 1.717 min
==========
Testing lambda: 0.001 starting at 2024-09-25 16:29:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 704, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 1.723 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 16:31:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 701, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 1.627 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 16:33:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 669, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 1.646 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 16:34:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 401, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 1.079 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 16:35:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.723 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 16:36:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 463, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 1.438 min
==========
Testing lambda: 0.01 starting at 2024-09-25 16:38:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 396, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 1.066 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 16:39:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.52 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 16:39:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 280, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.27 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 16:39:52 Max_iter: 1000
At iteration 304, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.206 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 16:40:04 Max_iter: 1000
At iteration 309, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.197 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 16:40:16 Max_iter: 1000
At iteration 294, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.189 min
==========
Testing lambda: 0.1 starting at 2024-09-25 16:40:27 Max_iter: 1000
At iteration 283, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.182 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 16:40:38 Max_iter: 1000
At iteration 227, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.149 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 16:40:47 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 16:40:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 16:40:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 16:40:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.019 min
==========
Testing lambda: 1.0 starting at 2024-09-25 16:40:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.314463    0.131694          0.132432            8649  0.999313  0.989036  0.944071   0.905882  0.946237      0.268662       0.000054
0.000015    0.279196    0.148194          0.148649            7679  0.999482  0.991296  0.952680   0.925982  0.954829      0.268893       0.000065
0.000022    0.244255    0.168431          0.168726            6718  0.999371  0.991673  0.961011   0.944359  0.962963      0.270784       0.000238
0.000032    0.177938    0.211083          0.211390            4894  0.999623  0.993148  0.964711   0.941985  0.966327      0.225482       0.002041
0.000046    0.135544    0.251712          0.251544            3728  0.999482  0.992922  0.969352   0.952087  0.970843      0.224757       0.000929
Exporting resultDF
Exporting result Dict
B_naive Time elapsed: 35.895926455656685 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD14_Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 16:41:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 536, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.129 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 16:42:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 552, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.137 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 16:43:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 545, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.103 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 16:44:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 535, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.155 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 16:45:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 519, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 1.163 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 16:47:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 565, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.187 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 16:48:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 294, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.933 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 16:49:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 366, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.098 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 16:50:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 435, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.174 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 16:51:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 463, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.235 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 16:52:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 454, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.152 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 16:53:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 375, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.11 min
==========
Testing lambda: 0.001 starting at 2024-09-25 16:54:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 420, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 1.079 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 16:56:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 396, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 1.021 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 16:57:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 368, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.941 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 16:58:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 352, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.709 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 16:58:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 352, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.626 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 16:59:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 275, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.445 min
==========
Testing lambda: 0.01 starting at 2024-09-25 16:59:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 349, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.35 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 17:00:09 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.21 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 17:00:21 Max_iter: 1000
At iteration 343, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.221 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 17:00:34 Max_iter: 1000
At iteration 406, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.257 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 17:00:50 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.219 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 17:01:03 Max_iter: 1000
At iteration 352, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.226 min
==========
Testing lambda: 0.1 starting at 2024-09-25 17:01:16 Max_iter: 1000
At iteration 416, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.262 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 17:01:32 Max_iter: 1000
At iteration 281, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.184 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 17:01:43 Max_iter: 1000
At iteration 254, Convergence with loss difference, Device: cuda
lambda is : 0.21544346900318834, cost : 0.168 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 17:01:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.02 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 17:01:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.019 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 17:01:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.021 min
==========
Testing lambda: 1.0 starting at 2024-09-25 17:01:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.019 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.305374    0.247833          0.247057            8399  0.991684  0.970801  0.909001   0.890075  0.922566      0.087229       0.014722
0.000015    0.274905    0.272781          0.271630            7561  0.992808  0.973786  0.918305   0.899304  0.930452      0.100229       0.002113
0.000022    0.247964    0.301710          0.300765            6820  0.992773  0.973106  0.917906   0.907701  0.930311      0.119082       0.000912
0.000032    0.214987    0.333919          0.333431            5913  0.992720  0.975252  0.925554   0.916987  0.936816      0.131212       0.000048
0.000046    0.183682    0.372160          0.371101            5052  0.992913  0.972331  0.921275   0.909984  0.933147      0.152834       0.006738
Exporting resultDF
Exporting result Dict
CD14_Mono Time elapsed: 20.7116415699323 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD16_Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 17:02:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 246, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.188 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 17:03:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 771, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 3.499 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 17:07:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 736, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 3.42 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 17:10:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 756, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 3.525 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 17:14:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 705, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 3.234 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 17:17:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 757, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 3.395 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 17:20:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 418, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.12 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 17:22:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 592, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 2.876 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 17:25:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 950, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 3.714 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 17:29:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 621, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 3.056 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 17:32:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 704, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 3.169 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 17:35:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 167, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.451 min
==========
Testing lambda: 0.001 starting at 2024-09-25 17:36:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 517, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 2.553 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 17:38:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 530, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 2.541 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 17:41:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 164, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.31 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 17:41:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 397, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 1.554 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 17:43:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 273, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.695 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 17:43:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 259, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 0.43 min
==========
Testing lambda: 0.01 starting at 2024-09-25 17:44:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 231, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.221 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 17:44:26 Max_iter: 1000
At iteration 282, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.183 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 17:44:37 Max_iter: 1000
At iteration 343, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.219 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 17:44:50 Max_iter: 1000
At iteration 338, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.215 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 17:45:03 Max_iter: 1000
At iteration 297, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.19 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 17:45:14 Max_iter: 1000
At iteration 292, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.187 min
==========
Testing lambda: 0.1 starting at 2024-09-25 17:45:26 Max_iter: 1000
At iteration 211, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.141 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 17:45:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 17:45:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 17:45:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 17:45:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 17:45:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 17:45:39 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.019 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.411104    0.183154          0.183281           11307  0.992983  0.925023  0.865243   0.811912  0.869857      0.465916       0.000063
0.000015    0.389580    0.202509          0.202503           10715  0.991819  0.926125  0.857273   0.815113  0.862979      0.468722       0.000068
0.000022    0.364711    0.224373          0.224408           10031  0.992070  0.929851  0.866834   0.828990  0.872322      0.470795       0.000066
0.000032    0.337224    0.245161          0.245865            9275  0.994060  0.935716  0.875785   0.841845  0.881034      0.473142       0.000061
0.000046    0.311991    0.268459          0.268216            8581  0.993574  0.933407  0.874455   0.842715  0.879862      0.476170       0.000074
Exporting resultDF
Exporting result Dict
CD16_Mono Time elapsed: 43.317478597164154 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_CTL
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 17:46:10 Max_iter: 1000
At iteration 375, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.465 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 17:46:38 Max_iter: 1000
At iteration 366, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.449 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 17:47:05 Max_iter: 1000
At iteration 356, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.429 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 17:47:31 Max_iter: 1000
At iteration 344, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.396 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 17:47:55 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.366 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 17:48:17 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.342 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 17:48:37 Max_iter: 1000
At iteration 312, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.304 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 17:48:55 Max_iter: 1000
At iteration 297, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.28 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 17:49:12 Max_iter: 1000
At iteration 288, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.247 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 17:49:27 Max_iter: 1000
At iteration 276, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.224 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 17:49:40 Max_iter: 1000
At iteration 266, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.204 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 17:49:53 Max_iter: 1000
At iteration 260, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.187 min
==========
Testing lambda: 0.001 starting at 2024-09-25 17:50:04 Max_iter: 1000
At iteration 261, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.188 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 17:50:15 Max_iter: 1000
At iteration 262, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.178 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 17:50:26 Max_iter: 1000
At iteration 263, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.174 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 17:50:36 Max_iter: 1000
At iteration 253, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.167 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 17:50:46 Max_iter: 1000
At iteration 230, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.153 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 17:50:56 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.147 min
==========
Testing lambda: 0.01 starting at 2024-09-25 17:51:04 Max_iter: 1000
At iteration 204, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.137 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 17:51:13 Max_iter: 1000
At iteration 205, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.138 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 17:51:21 Max_iter: 1000
At iteration 125, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.094 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 17:51:26 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.019 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 17:51:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.016 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 17:51:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.017 min
==========
Testing lambda: 0.1 starting at 2024-09-25 17:51:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 17:51:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 17:51:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 17:51:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 17:51:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 17:51:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 17:51:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.344059    0.103810          0.103044            9463  0.997835  0.909173  0.829838   0.763948  0.829837      0.645571       0.001051
0.000015    0.316281    0.114286          0.113583            8699  0.997722  0.910449  0.843822   0.802752  0.845411      0.649236       0.000584
0.000022    0.286831    0.125714          0.125293            7889  0.997916  0.912568  0.837916   0.800926  0.839806      0.653029       0.000955
0.000032    0.252727    0.141905          0.141686            6951  0.998416  0.921241  0.837916   0.800926  0.839806      0.656874       0.000554
0.000046    0.215750    0.162857          0.162763            5934  0.998586  0.923089  0.852762   0.814815  0.854369      0.660762       0.000532
Exporting resultDF
Exporting result Dict
CD4_CTL Time elapsed: 5.576313666502634 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_Naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 17:52:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 382, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.524 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 17:52:39 Max_iter: 1000
At iteration 407, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.504 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 17:53:10 Max_iter: 1000
At iteration 478, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.525 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 17:53:41 Max_iter: 1000
At iteration 466, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.481 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 17:54:10 Max_iter: 1000
At iteration 445, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.441 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 17:54:36 Max_iter: 1000
At iteration 439, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.426 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 17:55:02 Max_iter: 1000
At iteration 422, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.384 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 17:55:25 Max_iter: 1000
At iteration 408, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.362 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 17:55:47 Max_iter: 1000
At iteration 381, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.327 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 17:56:06 Max_iter: 1000
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.296 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 17:56:24 Max_iter: 1000
At iteration 348, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.285 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 17:56:41 Max_iter: 1000
At iteration 343, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.286 min
==========
Testing lambda: 0.001 starting at 2024-09-25 17:56:58 Max_iter: 1000
At iteration 335, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.263 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 17:57:14 Max_iter: 1000
At iteration 322, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.24 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 17:57:29 Max_iter: 1000
At iteration 320, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.218 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 17:57:42 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.207 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 17:57:54 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.204 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 17:58:06 Max_iter: 1000
At iteration 308, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.198 min
==========
Testing lambda: 0.01 starting at 2024-09-25 17:58:18 Max_iter: 1000
At iteration 311, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.201 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 17:58:30 Max_iter: 1000
At iteration 303, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.195 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 17:58:42 Max_iter: 1000
At iteration 294, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.189 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 17:58:53 Max_iter: 1000
At iteration 277, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.181 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 17:59:04 Max_iter: 1000
At iteration 271, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.177 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 17:59:15 Max_iter: 1000
At iteration 222, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.149 min
==========
Testing lambda: 0.1 starting at 2024-09-25 17:59:24 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.019 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 17:59:25 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 17:59:26 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 17:59:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 17:59:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 17:59:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 17:59:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.358602    0.089230          0.089066            9863  0.989938  0.950461  0.865000   0.831395  0.876916      0.447156       0.000014
0.000015    0.324935    0.100018          0.100683            8937  0.991222  0.951666  0.871215   0.839465  0.882637      0.455726       0.001642
0.000022    0.291376    0.112452          0.112301            8014  0.990965  0.949781  0.862486   0.829593  0.874671      0.464959       0.001625
0.000032    0.256435    0.128360          0.128018            7053  0.991359  0.949855  0.865508   0.833890  0.877470      0.474906       0.000856
0.000046    0.222768    0.145730          0.145558            6127  0.992109  0.952365  0.868906   0.843803  0.880815      0.485127       0.000908
Exporting resultDF
Exporting result Dict
CD4_Naive Time elapsed: 7.5266013185183205 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:00:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 717, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.694 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:00:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 528, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.596 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:01:20 Max_iter: 1000
At iteration 731, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.668 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:02:00 Max_iter: 1000
At iteration 738, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.668 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 18:02:40 Max_iter: 1000
At iteration 303, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.433 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 18:03:06 Max_iter: 1000
At iteration 291, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.401 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 18:03:30 Max_iter: 1000
At iteration 267, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.359 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 18:03:51 Max_iter: 1000
At iteration 251, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.319 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 18:04:10 Max_iter: 1000
At iteration 242, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.29 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 18:04:28 Max_iter: 1000
At iteration 219, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.251 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 18:04:43 Max_iter: 1000
At iteration 202, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.212 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 18:04:56 Max_iter: 1000
At iteration 186, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.176 min
==========
Testing lambda: 0.001 starting at 2024-09-25 18:05:06 Max_iter: 1000
At iteration 175, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.148 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 18:05:15 Max_iter: 1000
At iteration 162, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.12 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 18:05:22 Max_iter: 1000
At iteration 159, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.116 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 18:05:29 Max_iter: 1000
At iteration 140, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.104 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 18:05:36 Max_iter: 1000
At iteration 102, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 0.085 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 18:05:41 Max_iter: 1000
At iteration 64, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.056 min
==========
Testing lambda: 0.01 starting at 2024-09-25 18:05:44 Max_iter: 1000
At iteration 17, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.029 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 18:05:46 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.018 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 18:05:47 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.02154434690031883, cost : 0.016 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 18:05:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.016 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 18:05:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.016 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 18:05:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.015 min
==========
Testing lambda: 0.1 starting at 2024-09-25 18:05:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 18:05:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 18:05:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 18:05:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 18:05:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 18:05:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 18:05:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.313773    0.432692          0.433735            8630  0.998495  0.604171  0.668090   0.722222  0.666667      0.226024       0.061452
0.000015    0.328825    0.432692          0.421687            9044  0.997570  0.636984  0.773095   0.739130  0.772727      0.291908       0.020844
0.000022    0.303992    0.451923          0.445783            8361  0.998905  0.617143  0.713351   0.629630  0.708333      0.376631       0.015990
0.000032    0.293666    0.461538          0.457831            8077  0.999038  0.683396  0.726987   0.653846  0.723404      0.474900       0.013527
0.000046    0.328498    0.413462          0.409639            9035  0.999067  0.710070  0.756473   0.633333  0.745098      0.671003       0.000467
Exporting resultDF
Exporting result Dict
CD4_Proliferating Time elapsed: 6.046620603402456 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_TCM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:06:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 535, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.829 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:07:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.517 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:07:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 746, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.9 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:08:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 333, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.455 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 18:09:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 746, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.836 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 18:10:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 686, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.823 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 18:10:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 708, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.823 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 18:11:39 Max_iter: 1000
At iteration 384, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.37 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 18:12:01 Max_iter: 1000
At iteration 356, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.346 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 18:12:22 Max_iter: 1000
At iteration 350, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 0.361 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 18:12:44 Max_iter: 1000
At iteration 334, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.311 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 18:13:02 Max_iter: 1000
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.275 min
==========
Testing lambda: 0.001 starting at 2024-09-25 18:13:19 Max_iter: 1000
At iteration 307, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.237 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 18:13:33 Max_iter: 1000
At iteration 301, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.214 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 18:13:46 Max_iter: 1000
At iteration 298, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.2 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 18:13:58 Max_iter: 1000
At iteration 297, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.195 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 18:14:09 Max_iter: 1000
At iteration 295, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.193 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 18:14:21 Max_iter: 1000
At iteration 304, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.197 min
==========
Testing lambda: 0.01 starting at 2024-09-25 18:14:33 Max_iter: 1000
At iteration 304, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.196 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 18:14:45 Max_iter: 1000
At iteration 316, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.204 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 18:14:57 Max_iter: 1000
At iteration 287, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.185 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 18:15:08 Max_iter: 1000
At iteration 273, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.177 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 18:15:19 Max_iter: 1000
At iteration 239, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.157 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 18:15:28 Max_iter: 1000
At iteration 120, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.088 min
==========
Testing lambda: 0.1 starting at 2024-09-25 18:15:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 18:15:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 18:15:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 18:15:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 18:15:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 18:15:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 18:15:39 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.349295    0.116129          0.116502            9607  0.973555  0.839262  0.747152   0.716007  0.768591      0.308130       0.001158
0.000015    0.347113    0.116734          0.117008            9547  0.974219  0.842189  0.742412   0.712317  0.764325      0.511687       0.000047
0.000022    0.272651    0.147379          0.147587            7499  0.969680  0.820174  0.737743   0.718722  0.760563      0.350128       0.000029
0.000032    0.287158    0.143750          0.144301            7898  0.971178  0.826630  0.733537   0.717605  0.756833      0.526396       0.000069
0.000046    0.214187    0.179839          0.180440            5891  0.971941  0.817456  0.722132   0.701139  0.746269      0.401712       0.000509
Exporting resultDF
Exporting result Dict
CD4_TCM Time elapsed: 9.352488346894582 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD4_TEM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:16:12 Max_iter: 1000
At iteration 395, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.505 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:16:42 Max_iter: 1000
At iteration 392, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.48 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:17:11 Max_iter: 1000
At iteration 387, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.46 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:17:39 Max_iter: 1000
At iteration 370, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.431 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 18:18:04 Max_iter: 1000
At iteration 358, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.4 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 18:18:28 Max_iter: 1000
At iteration 354, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.373 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 18:18:51 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.332 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 18:19:11 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.307 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 18:19:29 Max_iter: 1000
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.29 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 18:19:47 Max_iter: 1000
At iteration 312, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 0.315 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 18:20:05 Max_iter: 1000
At iteration 295, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.262 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 18:20:21 Max_iter: 1000
At iteration 297, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.247 min
==========
Testing lambda: 0.001 starting at 2024-09-25 18:20:36 Max_iter: 1000
At iteration 294, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.214 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 18:20:49 Max_iter: 1000
At iteration 296, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.197 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 18:21:01 Max_iter: 1000
At iteration 279, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.183 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 18:21:12 Max_iter: 1000
At iteration 280, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.182 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 18:21:23 Max_iter: 1000
At iteration 274, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.178 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 18:21:33 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.172 min
==========
Testing lambda: 0.01 starting at 2024-09-25 18:21:44 Max_iter: 1000
At iteration 243, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.159 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 18:21:53 Max_iter: 1000
At iteration 218, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.145 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 18:22:02 Max_iter: 1000
At iteration 202, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.135 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 18:22:10 Max_iter: 1000
At iteration 94, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.073 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 18:22:14 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.018 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 18:22:15 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 18:22:16 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 18:22:17 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 18:22:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 18:22:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 18:22:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 18:22:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 18:22:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.357984    0.099952          0.100178            9846  0.945544  0.600683  0.554571   0.513619  0.568966      0.631618       0.000684
0.000015    0.326716    0.112327          0.112033            8986  0.951610  0.611098  0.561665   0.516315  0.575401      0.635844       0.000696
0.000022    0.297229    0.124703          0.124481            8175  0.953952  0.619020  0.577142   0.520370  0.589099      0.640284       0.000705
0.000032    0.263307    0.139933          0.139301            7242  0.955092  0.609260  0.580773   0.512411  0.591002      0.644856       0.000634
0.000046    0.228294    0.161352          0.160640            6279  0.957295  0.614488  0.565350   0.506375  0.577362      0.649505       0.000989
Exporting resultDF
Exporting result Dict
CD4_TEM Time elapsed: 6.317216078440349 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_Naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:22:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 336, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.618 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:23:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 975, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 2.989 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:26:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.884 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:29:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 787, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 2.788 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 18:32:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 381, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.936 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 18:33:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.505 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 18:35:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 839, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.121 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 18:37:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 374, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.051 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 18:38:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 811, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.84 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 18:40:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 828, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.889 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 18:42:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 307, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.625 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 18:43:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 263, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.254 min
==========
Testing lambda: 0.001 starting at 2024-09-25 18:43:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 255, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.23 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 18:43:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.268 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 18:43:53 Max_iter: 1000
At iteration 321, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.214 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 18:44:06 Max_iter: 1000
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.206 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 18:44:19 Max_iter: 1000
At iteration 316, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.204 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 18:44:31 Max_iter: 1000
At iteration 300, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.195 min
==========
Testing lambda: 0.01 starting at 2024-09-25 18:44:43 Max_iter: 1000
At iteration 289, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.187 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 18:44:54 Max_iter: 1000
At iteration 283, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.183 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 18:45:05 Max_iter: 1000
At iteration 276, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.179 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 18:45:16 Max_iter: 1000
At iteration 271, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.176 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 18:45:26 Max_iter: 1000
At iteration 213, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.142 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 18:45:35 Max_iter: 1000
At iteration 155, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.107 min
==========
Testing lambda: 0.1 starting at 2024-09-25 18:45:41 Max_iter: 1000
At iteration 122, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.088 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 18:45:46 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 18:45:47 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 18:45:48 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 18:45:49 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 18:45:50 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 18:45:51 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.019 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.370492    0.098188          0.098431           10190  0.991702  0.966858  0.866326   0.798077  0.872154      0.463849       0.000108
0.000015    0.338678    0.111221          0.111658            9315  0.991131  0.966634  0.877297   0.820994  0.883472      0.470485       0.000084
0.000022    0.311046    0.123386          0.123962            8555  0.992811  0.970870  0.890194   0.837626  0.895808      0.477394       0.000069
0.000032    0.274796    0.140268          0.140265            7558  0.993014  0.971654  0.890738   0.838565  0.896345      0.485191       0.000081
0.000046    0.243237    0.156902          0.157182            6690  0.992878  0.970878  0.900347   0.860950  0.906098      0.493282       0.000105
Exporting resultDF
Exporting result Dict
CD8_Naive Time elapsed: 23.12292146285375 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:46:24 Max_iter: 1000
At iteration 677, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.652 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:47:03 Max_iter: 1000
At iteration 740, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.679 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:47:44 Max_iter: 1000
At iteration 657, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.611 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:48:21 Max_iter: 1000
At iteration 671, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.622 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 18:48:58 Max_iter: 1000
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.392 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 18:49:22 Max_iter: 1000
At iteration 267, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.356 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 18:49:43 Max_iter: 1000
At iteration 251, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.329 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 18:50:03 Max_iter: 1000
At iteration 225, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.299 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 18:50:21 Max_iter: 1000
At iteration 214, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.258 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 18:50:36 Max_iter: 1000
At iteration 191, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.216 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 18:50:49 Max_iter: 1000
At iteration 176, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.183 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 18:51:00 Max_iter: 1000
At iteration 162, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.154 min
==========
Testing lambda: 0.001 starting at 2024-09-25 18:51:10 Max_iter: 1000
At iteration 146, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.121 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 18:51:17 Max_iter: 1000
At iteration 138, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.104 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 18:51:23 Max_iter: 1000
At iteration 61, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.06 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 18:51:27 Max_iter: 1000
At iteration 35, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.041 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 18:51:29 Max_iter: 1000
At iteration 7, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.023 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 18:51:30 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.006812920690579607, cost : 0.017 min
==========
Testing lambda: 0.01 starting at 2024-09-25 18:51:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.009999999999999995, cost : 0.015 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 18:51:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.014677992676220683, cost : 0.016 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 18:51:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.02154434690031883, cost : 0.015 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 18:51:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.015 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 18:51:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.015 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 18:51:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.015 min
==========
Testing lambda: 0.1 starting at 2024-09-25 18:51:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.015 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 18:51:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 18:51:39 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 18:51:40 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 18:51:41 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 18:51:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 18:51:43 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.316936    0.314607          0.328571            8717  0.926795  0.113994  0.156501   0.157895  0.157895      0.286214       0.002455
0.000015    0.328643    0.303371          0.328571            9039  0.896213  0.093649  0.152461   0.150000  0.153846      0.369842       0.002367
0.000022    0.306428    0.314607          0.342857            8428  0.946016  0.126044  0.156501   0.157895  0.157895      0.467322       0.029133
0.000032    0.299847    0.325843          0.342857            8247  0.949275  0.149959  0.185808   0.166667  0.186047      0.570354       0.018572
0.000046    0.307628    0.314607          0.328571            8461  0.940338  0.117171  0.209220   0.210526  0.210526      0.672652       0.000637
Exporting resultDF
Exporting result Dict
CD8_Proliferating Time elapsed: 5.454558082421621 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_TCM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:52:14 Max_iter: 1000
At iteration 353, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.488 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:52:43 Max_iter: 1000
At iteration 358, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.469 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:53:11 Max_iter: 1000
At iteration 338, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.422 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:53:36 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.414 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 18:54:01 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.371 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 18:54:23 Max_iter: 1000
At iteration 302, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.34 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 18:54:44 Max_iter: 1000
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.312 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 18:55:02 Max_iter: 1000
At iteration 276, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.279 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 18:55:19 Max_iter: 1000
At iteration 269, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.255 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 18:55:35 Max_iter: 1000
At iteration 258, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.226 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 18:55:48 Max_iter: 1000
At iteration 252, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.215 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 18:56:01 Max_iter: 1000
At iteration 249, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.217 min
==========
Testing lambda: 0.001 starting at 2024-09-25 18:56:14 Max_iter: 1000
At iteration 250, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.194 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 18:56:26 Max_iter: 1000
At iteration 257, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.178 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 18:56:36 Max_iter: 1000
At iteration 260, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.173 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 18:56:47 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.174 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 18:56:57 Max_iter: 1000
At iteration 231, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.155 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 18:57:06 Max_iter: 1000
At iteration 198, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.134 min
==========
Testing lambda: 0.01 starting at 2024-09-25 18:57:14 Max_iter: 1000
At iteration 190, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.129 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 18:57:22 Max_iter: 1000
At iteration 201, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.135 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 18:57:30 Max_iter: 1000
At iteration 84, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.068 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 18:57:34 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.019 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 18:57:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.016 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 18:57:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 18:57:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 18:57:39 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 18:57:40 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 18:57:41 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 18:57:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 18:57:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 18:57:43 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.360638    0.104554          0.104754            9919  0.983444  0.735196  0.664804   0.640227  0.673621      0.642152       0.000489
0.000015    0.330243    0.116742          0.116035            9083  0.981183  0.724302  0.649165   0.614754  0.657895      0.646020       0.000652
0.000022    0.297375    0.130853          0.129734            8179  0.983344  0.755086  0.688457   0.669565  0.696833      0.649989       0.000743
0.000032    0.263525    0.146889          0.145850            7248  0.983463  0.735509  0.664017   0.633333  0.672566      0.654014       0.000573
0.000046    0.228439    0.166132          0.165995            6283  0.983568  0.727848  0.667563   0.626344  0.675362      0.658134       0.000667
Exporting resultDF
Exporting result Dict
CD8_TCM Time elapsed: 5.641968679428101 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for CD8_TEM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 18:58:15 Max_iter: 1000
At iteration 395, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.516 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 18:58:46 Max_iter: 1000
At iteration 419, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.5 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 18:59:16 Max_iter: 1000
At iteration 459, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.514 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 18:59:47 Max_iter: 1000
At iteration 465, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.485 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 19:00:16 Max_iter: 1000
At iteration 449, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.457 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 19:00:43 Max_iter: 1000
At iteration 443, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.419 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 19:01:08 Max_iter: 1000
At iteration 423, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.386 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 19:01:31 Max_iter: 1000
At iteration 407, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.366 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 19:01:53 Max_iter: 1000
At iteration 392, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.329 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 19:02:13 Max_iter: 1000
At iteration 364, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.331 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 19:02:33 Max_iter: 1000
At iteration 355, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 0.315 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 19:02:52 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 0.277 min
==========
Testing lambda: 0.001 starting at 2024-09-25 19:03:08 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.239 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 19:03:23 Max_iter: 1000
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.223 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 19:03:36 Max_iter: 1000
At iteration 318, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.207 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 19:03:49 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.204 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 19:04:01 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.203 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 19:04:13 Max_iter: 1000
At iteration 317, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.204 min
==========
Testing lambda: 0.01 starting at 2024-09-25 19:04:25 Max_iter: 1000
At iteration 323, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.206 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 19:04:38 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.2 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 19:04:50 Max_iter: 1000
At iteration 322, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.205 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 19:05:02 Max_iter: 1000
At iteration 262, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.17 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 19:05:12 Max_iter: 1000
At iteration 205, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.139 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 19:05:20 Max_iter: 1000
At iteration 194, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.13 min
==========
Testing lambda: 0.1 starting at 2024-09-25 19:05:28 Max_iter: 1000
At iteration 118, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.086 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 19:05:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 19:05:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 19:05:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 19:05:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 19:05:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 19:05:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.018 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.367219    0.099977          0.099971           10100  0.987620  0.914556  0.806558   0.748039  0.818231      0.500589       0.001938
0.000015    0.336860    0.111476          0.111241            9265  0.987203  0.916225  0.820913   0.778006  0.832783      0.507634       0.001354
0.000022    0.304065    0.124384          0.124122            8363  0.986799  0.912032  0.813261   0.771047  0.825728      0.515095       0.001329
0.000032    0.271742    0.139404          0.139052            7474  0.987808  0.912918  0.819865   0.782292  0.832133      0.522951       0.000740
0.000046    0.236656    0.158414          0.157787            6509  0.987335  0.913652  0.831650   0.808903  0.843715      0.530883       0.000652
Exporting resultDF
Exporting result Dict
CD8_TEM Time elapsed: 7.556242024898529 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Doublet
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 19:06:11 Max_iter: 1000
At iteration 315, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.504 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 19:06:42 Max_iter: 1000
At iteration 341, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.51 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 19:07:12 Max_iter: 1000
At iteration 307, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.461 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 19:07:40 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.453 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 19:08:07 Max_iter: 1000
At iteration 342, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.433 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 19:08:33 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.4 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 19:08:57 Max_iter: 1000
At iteration 305, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.365 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 19:09:19 Max_iter: 1000
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.315 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 19:09:38 Max_iter: 1000
At iteration 261, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.281 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 19:09:55 Max_iter: 1000
At iteration 244, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.238 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 19:10:09 Max_iter: 1000
At iteration 226, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.212 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 19:10:22 Max_iter: 1000
At iteration 219, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.209 min
==========
Testing lambda: 0.001 starting at 2024-09-25 19:10:34 Max_iter: 1000
At iteration 213, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.179 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 19:10:45 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.156 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 19:10:54 Max_iter: 1000
At iteration 215, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.146 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 19:11:03 Max_iter: 1000
At iteration 184, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.127 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 19:11:11 Max_iter: 1000
At iteration 179, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.124 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 19:11:18 Max_iter: 1000
At iteration 165, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.116 min
==========
Testing lambda: 0.01 starting at 2024-09-25 19:11:25 Max_iter: 1000
At iteration 23, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.036 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 19:11:27 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.014677992676220683, cost : 0.019 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 19:11:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.02154434690031883, cost : 0.017 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 19:11:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.016 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 19:11:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.017 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 19:11:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.018 min
==========
Testing lambda: 0.1 starting at 2024-09-25 19:11:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 19:11:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 19:11:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 19:11:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 19:11:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 19:11:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 19:11:38 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.417321    0.181208          0.180556           11478  0.853235  0.164884  0.318349   0.285714  0.321608      0.658950       0.000807
0.000015    0.388234    0.203579          0.200000           10678  0.849419  0.197961  0.350677   0.344086  0.355556      0.662069       0.000205
0.000022    0.358093    0.225951          0.222222            9849  0.854043  0.227425  0.370207   0.370787  0.375000      0.665400       0.000652
0.000032    0.325371    0.248322          0.244444            8949  0.880226  0.259163  0.365977   0.362637  0.370787      0.668571       0.000530
0.000046    0.290721    0.272931          0.272222            7996  0.878995  0.266987  0.367009   0.354167  0.371585      0.671941       0.000758
Exporting resultDF
Exporting result Dict
Doublet Time elapsed: 5.598507908980052 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Eryth
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 19:12:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 818, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.095 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 19:14:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 6.151 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 19:20:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 460, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.456 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 19:21:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 134, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.354 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 19:22:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 770, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.13 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 19:24:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 496, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.22 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 19:25:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999991e-05, cost : 7.218 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 19:32:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.066 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 19:33:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 405, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.108 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 19:34:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 377, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.05 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 19:36:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 424, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127757, cost : 1.134 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 19:37:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 456, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.147 min
==========
Testing lambda: 0.001 starting at 2024-09-25 19:38:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 410, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 1.057 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 19:39:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 436, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 1.221 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 19:40:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 464, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 1.267 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 19:41:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 558, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 1.666 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 19:43:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 613, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 1.54 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 19:45:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 177, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.149 min
==========
Testing lambda: 0.01 starting at 2024-09-25 19:45:11 Max_iter: 1000
At iteration 135, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.097 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 19:45:17 Max_iter: 1000
At iteration 60, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.055 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 19:45:20 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.02 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 19:45:22 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.016 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 19:45:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.015 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 19:45:23 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.015 min
==========
Testing lambda: 0.1 starting at 2024-09-25 19:45:24 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.015 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 19:45:25 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 19:45:26 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 19:45:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 19:45:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 19:45:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-25 19:45:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.216768    0.144578          0.135593            5962  0.950460  0.862814  0.840328   0.807692  0.840000      0.146867       0.000094
0.000015    0.265525    0.120482          0.118644            7303  0.979034  0.861102  0.800208   0.769231  0.800000      0.056090       1.666931
0.000022    0.227276    0.144578          0.135593            6251  0.970471  0.857607  0.824573   0.777778  0.823529      0.369735       0.000272
0.000032    0.253454    0.132530          0.135593            6971  0.963818  0.869505  0.824573   0.777778  0.823529      0.670433       0.000243
0.000046    0.070244    0.289157          0.288136            1932  0.973981  0.872700  0.880447   0.846154  0.880000      0.132345       0.000945
Exporting resultDF
Exporting result Dict
Eryth Time elapsed: 33.483174626032515 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for HSPC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 19:46:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 925, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.805 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 19:47:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 695, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.831 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 19:49:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 723, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.782 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 19:51:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 743, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.943 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 19:53:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 4.723 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 19:58:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 721, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.596 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 19:59:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 670, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 1.754 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 20:01:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 623, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.701 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 20:03:09 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 621, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.793 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 20:04:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 526, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.619 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 20:06:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 0.00046415888336127757, cost : 6.269 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 20:12:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 540, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.693 min
==========
Testing lambda: 0.001 starting at 2024-09-25 20:14:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 549, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 1.804 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 20:16:20 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 576, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 2.043 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 20:18:23 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 618, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.128 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 20:20:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 283, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 1.202 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 20:21:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 643, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 2.25 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 20:23:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 731, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 2.14 min
==========
Testing lambda: 0.01 starting at 2024-09-25 20:26:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
Hessian initialization fail, gradient diff = 0
lambda is : 0.009999999999999995, cost : 1.077 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 20:27:11 Max_iter: 1000
At iteration 211, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.14 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 20:27:19 Max_iter: 1000
At iteration 134, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.096 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 20:27:25 Max_iter: 1000
At iteration 25, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.033 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 20:27:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.017 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 20:27:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 20:27:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 20:27:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 20:27:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 20:27:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 20:27:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 20:27:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.018 min
==========
Testing lambda: 1.0 starting at 2024-09-25 20:27:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.055955    0.602230          0.600962            1539  0.999991  0.998399  0.968573   0.938462  0.968254      0.023292       0.003681
0.000015    0.265089    0.315985          0.317308            7291  0.999956  0.991935  0.813171   0.663043  0.797386      0.051352       0.066050
0.000022    0.188700    0.390335          0.389423            5190  0.999956  0.991935  0.831593   0.693182  0.818792      0.087091       0.003415
0.000032    0.140343    0.442379          0.442308            3860  0.999954  0.991413  0.861706   0.743902  0.853147      0.078308       0.001191
0.000046    0.115947    0.501859          0.504808            3189  0.999990  0.998175  0.946842   0.897059  0.945736      0.072186       3.701820
Exporting resultDF
Exporting result Dict
HSPC Time elapsed: 41.71936478217443 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for ILC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 20:28:07 Max_iter: 1000
At iteration 293, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.421 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 20:28:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 638, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.649 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 20:29:11 Max_iter: 1000
At iteration 320, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.4 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 20:29:35 Max_iter: 1000
At iteration 280, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.353 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 20:29:57 Max_iter: 1000
At iteration 254, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.314 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 20:30:15 Max_iter: 1000
At iteration 226, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.273 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 20:30:32 Max_iter: 1000
At iteration 212, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.239 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 20:30:46 Max_iter: 1000
At iteration 199, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.212 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 20:30:59 Max_iter: 1000
At iteration 181, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.183 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 20:31:10 Max_iter: 1000
At iteration 160, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.15 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 20:31:19 Max_iter: 1000
At iteration 146, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.128 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 20:31:27 Max_iter: 1000
At iteration 129, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.104 min
==========
Testing lambda: 0.001 starting at 2024-09-25 20:31:33 Max_iter: 1000
At iteration 113, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.086 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 20:31:38 Max_iter: 1000
At iteration 99, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.079 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 20:31:43 Max_iter: 1000
At iteration 83, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.071 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 20:31:47 Max_iter: 1000
At iteration 56, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.053 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 20:31:50 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.02 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 20:31:51 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.017 min
==========
Testing lambda: 0.01 starting at 2024-09-25 20:31:52 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.009999999999999995, cost : 0.015 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 20:31:53 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.014677992676220683, cost : 0.016 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 20:31:54 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.02154434690031883, cost : 0.016 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 20:31:55 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.016 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 20:31:56 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.016 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 20:31:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 20:31:58 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.015 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 20:31:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 20:32:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 20:32:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 20:32:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 20:32:03 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-25 20:32:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.362238    0.105691          0.107527            9963  0.984782  0.842941  0.770878   0.714286  0.769231      0.665573       0.005728
0.000015    0.296102    0.130081          0.129032            8144  0.986545  0.849762  0.782180   0.735294  0.781250      0.510204       0.015764
0.000022    0.291885    0.138211          0.129032            8028  0.990241  0.832298  0.782180   0.735294  0.781250      0.672856       0.000626
0.000032    0.254872    0.154472          0.150538            7010  0.992937  0.856819  0.813198   0.827586  0.813559      0.676195       0.000633
0.000046    0.216550    0.178862          0.172043            5956  0.997083  0.884247  0.842888   0.888889  0.842105      0.679334       0.000401
Exporting resultDF
Exporting result Dict
ILC Time elapsed: 4.081216955184937 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for MAIT
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 20:32:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 231, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.546 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 20:33:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 272, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.711 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 20:33:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 754, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 3.418 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 20:37:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 885, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 4.434 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 20:41:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 339, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 1.062 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 20:42:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 433, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.646 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 20:44:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 325, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 1.016 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 20:45:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 288, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.814 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 20:46:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 0.0002154434690031884, cost : 4.825 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 20:51:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 451, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.806 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 20:52:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 251, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.556 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 20:53:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 303, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.81 min
==========
Testing lambda: 0.001 starting at 2024-09-25 20:54:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 209, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.305 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 20:54:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 382, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 1.343 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 20:55:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 199, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.193 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 20:56:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 250, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.387 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 20:56:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 226, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.172 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 20:56:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 284, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.193 min
==========
Testing lambda: 0.01 starting at 2024-09-25 20:56:49 Max_iter: 1000
At iteration 277, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.179 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 20:57:00 Max_iter: 1000
At iteration 241, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.158 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 20:57:09 Max_iter: 1000
At iteration 208, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.141 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 20:57:18 Max_iter: 1000
At iteration 175, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.121 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 20:57:25 Max_iter: 1000
At iteration 98, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.076 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 20:57:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.018 min
==========
Testing lambda: 0.1 starting at 2024-09-25 20:57:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 20:57:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 20:57:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 20:57:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 20:57:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.017 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 20:57:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 20:57:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.353767    0.095520          0.095745            9730  0.998891  0.963265  0.906717   0.867692  0.908213      0.596689       0.000056
0.000015    0.321044    0.107378          0.107201            8830  0.999339  0.972976  0.912528   0.878505  0.914100      0.600821       0.000103
0.000022    0.268288    0.131752          0.131751            7379  0.998991  0.968021  0.916587   0.889241  0.918301      0.514639       0.001248
0.000032    0.215896    0.159420          0.159574            5938  0.999017  0.968639  0.914394   0.878882  0.915858      0.522002       0.001127
0.000046    0.222077    0.155468          0.155483            6108  0.999071  0.969470  0.911478   0.873457  0.912903      0.614434       0.000079
Exporting resultDF
Exporting result Dict
MAIT Time elapsed: 25.174785538514456 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 20:58:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 425, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.965 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 20:59:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 594, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.149 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 21:00:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 404, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.943 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 21:01:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 401, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.857 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 21:02:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 399, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.822 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 21:02:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 335, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.638 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 21:03:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 457, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.792 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 21:04:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 358, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.604 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 21:04:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 318, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.495 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 21:05:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 380, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.556 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 21:05:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 403, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.547 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 21:06:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 235, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.223 min
==========
Testing lambda: 0.001 starting at 2024-09-25 21:06:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 262, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.272 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 21:07:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 264, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.245 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 21:07:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 250, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.208 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 21:07:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 319, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.231 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 21:07:41 Max_iter: 1000
At iteration 340, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.221 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 21:07:54 Max_iter: 1000
At iteration 352, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.225 min
==========
Testing lambda: 0.01 starting at 2024-09-25 21:08:08 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.221 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 21:08:21 Max_iter: 1000
At iteration 366, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.231 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 21:08:35 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.212 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 21:08:48 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.214 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 21:09:01 Max_iter: 1000
At iteration 258, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.169 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 21:09:11 Max_iter: 1000
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.187 min
==========
Testing lambda: 0.1 starting at 2024-09-25 21:09:22 Max_iter: 1000
At iteration 275, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.178 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 21:09:33 Max_iter: 1000
At iteration 227, Convergence with loss difference, Device: cuda
lambda is : 0.14677992676220672, cost : 0.15 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 21:09:42 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.018 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 21:09:43 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 21:09:44 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.018 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 21:09:45 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 21:09:46 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.361875    0.114951          0.114995            9953  0.995822  0.979396  0.906780   0.860465  0.913983      0.257341       0.000112
0.000015    0.337769    0.124931          0.124540            9290  0.996055  0.979443  0.912571   0.874470  0.919715      0.267780       0.000085
0.000022    0.307046    0.137313          0.137305            8445  0.996281  0.980476  0.921798   0.886889  0.928251      0.277874       0.000088
0.000032    0.268434    0.157642          0.157314            7383  0.996010  0.982157  0.923045   0.893322  0.929603      0.291104       0.000077
0.000046    0.234184    0.180189          0.179393            6441  0.995258  0.981796  0.922637   0.896070  0.929348      0.303104       0.000064
Exporting resultDF
Exporting result Dict
NK Time elapsed: 11.79026065270106 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK_CD56bright
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 21:10:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 298, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.489 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 21:10:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 318, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.501 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 21:11:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 300, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.444 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 21:11:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 307, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.416 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 21:12:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 418, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.632 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 21:12:47 Max_iter: 1000
At iteration 326, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.348 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 21:13:08 Max_iter: 1000
At iteration 310, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.316 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 21:13:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 293, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.299 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 21:13:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 291, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.306 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 21:14:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 270, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.249 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 21:14:19 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 249, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.211 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 21:14:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 262, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.245 min
==========
Testing lambda: 0.001 starting at 2024-09-25 21:14:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 253, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.191 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 21:14:57 Max_iter: 1000
At iteration 273, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 0.183 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 21:15:08 Max_iter: 1000
At iteration 291, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.192 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 21:15:20 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.173 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 21:15:30 Max_iter: 1000
At iteration 242, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.16 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 21:15:40 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.147 min
==========
Testing lambda: 0.01 starting at 2024-09-25 21:15:49 Max_iter: 1000
At iteration 189, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.128 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 21:15:56 Max_iter: 1000
At iteration 161, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.112 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 21:16:03 Max_iter: 1000
At iteration 133, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.096 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 21:16:09 Max_iter: 1000
At iteration 48, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.048 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 21:16:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.019 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 21:16:13 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.017 min
==========
Testing lambda: 0.1 starting at 2024-09-25 21:16:14 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 21:16:15 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 21:16:16 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 21:16:17 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 21:16:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 21:16:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 21:16:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.373000    0.115086          0.115538           10259  0.992865  0.882874  0.807219   0.739645  0.806452      0.640816       0.000052
0.000015    0.343841    0.129082          0.127490            9457  0.990421  0.880085  0.813465   0.775641  0.814815      0.644454       0.000038
0.000022    0.313700    0.143079          0.141434            8628  0.990331  0.877357  0.811735   0.791946  0.813793      0.648254       0.000036
0.000032    0.275524    0.158631          0.157371            7578  0.995903  0.895214  0.832696   0.812081  0.834483      0.652064       0.000049
0.000046    0.239420    0.180404          0.181275            6585  0.994103  0.895980  0.859499   0.864286  0.861210      0.655853       0.000043
Exporting resultDF
Exporting result Dict
NK_CD56bright Time elapsed: 6.171118668715159 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for NK_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 21:16:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 187, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 0.597 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 21:17:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 230, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.815 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 21:18:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 306, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.19 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 21:19:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 989, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 2.642 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 21:22:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 274, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 1.018 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 21:23:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 327, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.304 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 21:24:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999991e-05, cost : 4.658 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 21:29:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 186, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.475 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 21:29:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 158, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.292 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 21:29:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 200, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.5 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 21:30:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 156, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.237 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 21:30:35 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 157, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.202 min
==========
Testing lambda: 0.001 starting at 2024-09-25 21:30:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 187, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.286 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 21:31:04 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 177, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.167 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 21:31:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 208, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318825, cost : 0.162 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 21:31:24 Max_iter: 1000
At iteration 263, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.176 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 21:31:34 Max_iter: 1000
At iteration 269, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.177 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 21:31:45 Max_iter: 1000
At iteration 253, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.166 min
==========
Testing lambda: 0.01 starting at 2024-09-25 21:31:55 Max_iter: 1000
At iteration 239, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.157 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 21:32:04 Max_iter: 1000
At iteration 209, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.14 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 21:32:13 Max_iter: 1000
At iteration 183, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.124 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 21:32:20 Max_iter: 1000
At iteration 132, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.095 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 21:32:26 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.019 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 21:32:27 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 21:32:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 21:32:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 21:32:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 21:32:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 21:32:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 21:32:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 21:32:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.413831    0.182039          0.181009           11382  0.987885  0.859054  0.761500   0.704545  0.760736      0.641200       0.000038
0.000015    0.385508    0.201456          0.201780           10603  0.989553  0.853870  0.760895   0.692308  0.759036      0.643886       0.000033
0.000022    0.358130    0.220874          0.219585            9850  0.993131  0.865571  0.786294   0.727273  0.785276      0.646683       0.000048
0.000032    0.247091    0.300971          0.299703            6796  0.996898  0.883406  0.798691   0.738636  0.797546      0.324108       0.000066
0.000046    0.298538    0.266990          0.267062            8211  0.994393  0.865890  0.790847   0.735632  0.790123      0.653078       0.000032
Exporting resultDF
Exporting result Dict
NK_Proliferating Time elapsed: 15.859065457185109 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Plasmablast
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 21:33:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 870, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.941 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 21:35:02 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 578, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.272 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 21:36:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 624, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.456 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 21:37:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 745, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.521 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 21:39:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 711, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 1.467 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 21:40:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 374, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.254 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 21:42:00 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 786, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 1.421 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 21:43:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 703, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.407 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 21:44:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 852, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 1.436 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 21:46:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 599, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.234 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 21:47:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 635, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.282 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 21:48:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 402, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.157 min
==========
Testing lambda: 0.001 starting at 2024-09-25 21:49:56 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 151, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.153 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 21:50:05 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 169, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.151 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 21:50:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 201, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.171 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 21:50:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 258, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.207 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 21:50:37 Max_iter: 1000
At iteration 258, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.169 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 21:50:47 Max_iter: 1000
At iteration 247, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.162 min
==========
Testing lambda: 0.01 starting at 2024-09-25 21:50:57 Max_iter: 1000
At iteration 222, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.147 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 21:51:06 Max_iter: 1000
At iteration 202, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.137 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 21:51:14 Max_iter: 1000
At iteration 181, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.125 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 21:51:21 Max_iter: 1000
At iteration 138, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.098 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 21:51:27 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.018 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 21:51:28 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 21:51:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 21:51:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 21:51:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 21:51:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 21:51:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 21:51:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.017 min
==========
Testing lambda: 1.0 starting at 2024-09-25 21:51:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.299484    0.319728          0.327511            8237  0.999995  0.999078  0.924360   0.855263  0.921986      0.175065       0.116963
0.000015    0.335515    0.295918          0.301310            9228  0.999997  0.999537  0.900797   0.812500  0.896552      0.190849       0.000946
0.000022    0.292757    0.333333          0.336245            8052  0.999999  0.999765  0.912352   0.833333  0.909091      0.181150       0.000926
0.000032    0.239165    0.387755          0.393013            6578  0.999999  0.999765  0.977564   0.955882  0.977444      0.137657       0.000038
0.000046    0.202552    0.438776          0.445415            5571  0.999999  0.999765  0.977564   0.955882  0.977444      0.173718       0.000192
Exporting resultDF
Exporting result Dict
Plasmablast Time elapsed: 18.652707775433857 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Platelet
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 21:52:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 602, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.586 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 21:53:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 574, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.579 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 21:55:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 558, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.548 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 21:56:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 665, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.821 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 21:58:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 568, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 1.585 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 22:00:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 521, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.503 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 22:01:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 569, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 1.654 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 22:03:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 507, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 1.578 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 22:04:59 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 175, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.545 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 22:05:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 539, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 1.735 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 22:07:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 512, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.6 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 22:08:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 514, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.618 min
==========
Testing lambda: 0.001 starting at 2024-09-25 22:10:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 532, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 1.704 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 22:12:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 537, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 2.032 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 22:14:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 503, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.131 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 22:16:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 533, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 2.32 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 22:18:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 493, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612776, cost : 2.248 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 22:20:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 575, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579607, cost : 2.451 min
==========
Testing lambda: 0.01 starting at 2024-09-25 22:23:22 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 232, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.009999999999999995, cost : 0.828 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 22:24:12 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 438, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 1.671 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 22:25:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 245, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.453 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 22:26:19 Max_iter: 1000
At iteration 306, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.195 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 22:26:31 Max_iter: 1000
At iteration 297, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.191 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 22:26:42 Max_iter: 1000
At iteration 197, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.134 min
==========
Testing lambda: 0.1 starting at 2024-09-25 22:26:50 Max_iter: 1000
At iteration 159, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.111 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 22:26:57 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 22:26:58 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 22:26:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.015 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 22:27:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 22:27:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-25 22:27:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.202880    0.071975          0.070209            5580  0.996611  0.965760  0.924757   0.890110  0.925714      0.272251       0.034214
0.000015    0.168157    0.085758          0.084440            4625  0.996877  0.969428  0.931786   0.903346  0.932821      0.293755       0.000490
0.000022    0.135944    0.107198          0.105313            3739  0.997178  0.969360  0.923466   0.884058  0.924242      0.306349       0.000223
0.000032    0.105439    0.136294          0.134725            2900  0.995409  0.974204  0.925694   0.899254  0.926923      0.303153       0.000256
0.000046    0.085624    0.170750          0.166983            2355  0.993504  0.968142  0.926380   0.911877  0.927875      0.328279       0.000271
Exporting resultDF
Exporting result Dict
Platelet Time elapsed: 35.05292200644811 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for Treg
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 22:27:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 955, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 4.23 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 22:31:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 4.388 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 22:36:10 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 957, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 4.341 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 22:40:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 197, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.332 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 22:40:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 222, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.378 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 22:41:13 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 944, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 4.091 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 22:45:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 914, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 4.124 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 22:49:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 230, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.444 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 22:49:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 0.0002154434690031884, cost : 4.006 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 22:53:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 188, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.222 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 22:54:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 884, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 3.868 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 22:57:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579611, cost : 3.922 min
==========
Testing lambda: 0.001 starting at 2024-09-25 23:01:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 282, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.877 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 23:02:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 763, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 3.506 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 23:06:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 210, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.248 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 23:06:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 239, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.25 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 23:06:46 Max_iter: 1000
At iteration 283, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.183 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 23:06:57 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.172 min
==========
Testing lambda: 0.01 starting at 2024-09-25 23:07:08 Max_iter: 1000
At iteration 221, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.146 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 23:07:16 Max_iter: 1000
At iteration 172, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.117 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 23:07:23 Max_iter: 1000
At iteration 116, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.085 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 23:07:28 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.017 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 23:07:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.016 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 23:07:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.016 min
==========
Testing lambda: 0.1 starting at 2024-09-25 23:07:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 23:07:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 23:07:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 23:07:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 23:07:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 23:07:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 23:07:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.344859    0.085000          0.084973            9485  0.986133  0.888955  0.801201   0.745455  0.803922      0.611373       0.000052
0.000015    0.325334    0.091429          0.091234            8948  0.987340  0.893770  0.803375   0.737463  0.805153      0.615492       0.000080
0.000022    0.280468    0.106429          0.106440            7714  0.986949  0.893638  0.818287   0.770186  0.821192      0.618955       0.000131
0.000032    0.247309    0.122143          0.120751            6802  0.986989  0.896686  0.821147   0.769231  0.823723      0.624359       0.000056
0.000046    0.209133    0.142500          0.142218            5752  0.987969  0.898113  0.827606   0.793548  0.831081      0.627290       0.000247
Exporting resultDF
Exporting result Dict
Treg Time elapsed: 40.21765362024307 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for cDC1
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 23:08:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 889, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.271 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 23:10:24 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 937, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 2.231 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 23:12:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 837, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.19 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 23:14:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 636, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 2.088 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 23:16:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 845, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.194 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 23:19:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 767, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.015 min
==========
Testing lambda: 0.0001 starting at 2024-09-25 23:21:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 782, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.224 min
==========
Testing lambda: 0.000147 starting at 2024-09-25 23:23:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 603, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 2.123 min
==========
Testing lambda: 0.000215 starting at 2024-09-25 23:25:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 994, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 2.199 min
==========
Testing lambda: 0.000316 starting at 2024-09-25 23:27:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 866, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 2.029 min
==========
Testing lambda: 0.000464 starting at 2024-09-25 23:29:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 571, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 2.011 min
==========
Testing lambda: 0.000681 starting at 2024-09-25 23:31:43 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 490, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 1.852 min
==========
Testing lambda: 0.001 starting at 2024-09-25 23:33:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 491, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 1.886 min
==========
Testing lambda: 0.001468 starting at 2024-09-25 23:35:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 529, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 1.905 min
==========
Testing lambda: 0.002154 starting at 2024-09-25 23:37:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 548, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.083 min
==========
Testing lambda: 0.003162 starting at 2024-09-25 23:39:26 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 543, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 2.07 min
==========
Testing lambda: 0.004642 starting at 2024-09-25 23:41:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 519, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 1.972 min
==========
Testing lambda: 0.006813 starting at 2024-09-25 23:43:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 305, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 1.383 min
==========
Testing lambda: 0.01 starting at 2024-09-25 23:44:52 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 627, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 1.783 min
==========
Testing lambda: 0.014678 starting at 2024-09-25 23:46:39 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 196, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.185 min
==========
Testing lambda: 0.021544 starting at 2024-09-25 23:46:50 Max_iter: 1000
At iteration 138, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.097 min
==========
Testing lambda: 0.031623 starting at 2024-09-25 23:46:56 Max_iter: 1000
At iteration 76, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.061 min
==========
Testing lambda: 0.046416 starting at 2024-09-25 23:46:59 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.017 min
==========
Testing lambda: 0.068129 starting at 2024-09-25 23:47:00 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.015 min
==========
Testing lambda: 0.1 starting at 2024-09-25 23:47:01 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.016 min
==========
Testing lambda: 0.14678 starting at 2024-09-25 23:47:02 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.016 min
==========
Testing lambda: 0.215443 starting at 2024-09-25 23:47:03 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-25 23:47:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-25 23:47:05 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-25 23:47:06 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-25 23:47:07 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.276105    0.413043          0.412281            7594  0.999967  0.988459  0.938841   0.920000  0.938776      0.111121       0.152130
0.000015    0.258944    0.420290          0.421053            7122  0.999993  0.996731  0.960685   0.923077  0.960000      0.123899       0.076624
0.000022    0.254690    0.427536          0.429825            7005  0.999996  0.998299  0.925659   0.857143  0.923077      0.138131       0.000233
0.000032    0.311373    0.369565          0.368421            8564  0.999887  0.976298  0.938841   0.920000  0.938776      0.117660       0.000872
0.000046    0.188264    0.507246          0.517544            5178  0.999989  0.994957  0.925659   0.857143  0.923077      0.142856       0.000081
Exporting resultDF
Exporting result Dict
cDC1 Time elapsed: 39.12625628709793 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for cDC2
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-25 23:47:38 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999997e-06, cost : 2.841 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-25 23:50:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 894, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 2.878 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-25 23:53:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 483, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 1.949 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-25 23:55:18 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 392, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.449 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-25 23:56:45 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 617, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.692 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-25 23:59:27 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 324, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 1.06 min
==========
Testing lambda: 0.0001 starting at 2024-09-26 00:00:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999991e-05, cost : 3.34 min
==========
Testing lambda: 0.000147 starting at 2024-09-26 00:03:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 625, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 2.646 min
==========
Testing lambda: 0.000215 starting at 2024-09-26 00:06:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 514, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 2.101 min
==========
Testing lambda: 0.000316 starting at 2024-09-26 00:08:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 304, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.923 min
==========
Testing lambda: 0.000464 starting at 2024-09-26 00:09:31 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 468, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 1.894 min
==========
Testing lambda: 0.000681 starting at 2024-09-26 00:11:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 722, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 3.209 min
==========
Testing lambda: 0.001 starting at 2024-09-26 00:14:37 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 372, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 1.334 min
==========
Testing lambda: 0.001468 starting at 2024-09-26 00:15:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 360, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 1.276 min
==========
Testing lambda: 0.002154 starting at 2024-09-26 00:17:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 579, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.363 min
==========
Testing lambda: 0.003162 starting at 2024-09-26 00:19:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 328, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168379, cost : 0.934 min
==========
Testing lambda: 0.004642 starting at 2024-09-26 00:20:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 280, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.615 min
==========
Testing lambda: 0.006813 starting at 2024-09-26 00:21:09 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 295, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.629 min
==========
Testing lambda: 0.01 starting at 2024-09-26 00:21:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 221, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.245 min
==========
Testing lambda: 0.014678 starting at 2024-09-26 00:22:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 312, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.45 min
==========
Testing lambda: 0.021544 starting at 2024-09-26 00:22:28 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 295, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.214 min
==========
Testing lambda: 0.031623 starting at 2024-09-26 00:22:41 Max_iter: 1000
At iteration 339, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.214 min
==========
Testing lambda: 0.046416 starting at 2024-09-26 00:22:54 Max_iter: 1000
At iteration 230, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.152 min
==========
Testing lambda: 0.068129 starting at 2024-09-26 00:23:03 Max_iter: 1000
At iteration 237, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.155 min
==========
Testing lambda: 0.1 starting at 2024-09-26 00:23:12 Max_iter: 1000
At iteration 90, Convergence with loss difference, Device: cuda
lambda is : 0.0999999999999999, cost : 0.07 min
==========
Testing lambda: 0.14678 starting at 2024-09-26 00:23:16 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-26 00:23:17 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-26 00:23:18 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-26 00:23:19 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-26 00:23:20 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-26 00:23:21 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.338969    0.307087          0.308772            9323  0.995925  0.957751  0.903632   0.867857  0.905028      0.110547       0.010218
0.000015    0.324571    0.327845          0.328947            8927  0.996226  0.962253  0.905788   0.868327  0.907063      0.118014       0.000324
0.000022    0.386780    0.266285          0.267544           10638  0.993094  0.948309  0.880600   0.828767  0.881603      0.490352       0.000111
0.000032    0.355803    0.294918          0.295614            9786  0.995762  0.953256  0.900974   0.870036  0.902622      0.494996       0.000109
0.000046    0.328061    0.324266          0.325439            9023  0.994972  0.954906  0.910338   0.880435  0.911820      0.501010       0.000094
Exporting resultDF
Exporting result Dict
cDC2 Time elapsed: 35.85826199054718 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for dnT
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-26 00:23:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999997e-06, cost : 4.692 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-26 00:28:34 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 193, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 0.378 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-26 00:28:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 428, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.541 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-26 00:29:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 443, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.477 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-26 00:29:58 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 176, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.291 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-26 00:30:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 179, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.276 min
==========
Testing lambda: 0.0001 starting at 2024-09-26 00:30:32 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 661, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.522 min
==========
Testing lambda: 0.000147 starting at 2024-09-26 00:31:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 170, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.224 min
==========
Testing lambda: 0.000215 starting at 2024-09-26 00:31:17 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 175, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.207 min
==========
Testing lambda: 0.000316 starting at 2024-09-26 00:31:29 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 622, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 0.457 min
==========
Testing lambda: 0.000464 starting at 2024-09-26 00:31:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 616, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.44 min
==========
Testing lambda: 0.000681 starting at 2024-09-26 00:32:23 Max_iter: 1000
At iteration 187, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.142 min
==========
Testing lambda: 0.001 starting at 2024-09-26 00:32:32 Max_iter: 1000
At iteration 167, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0009999999999999994, cost : 0.126 min
==========
Testing lambda: 0.001468 starting at 2024-09-26 00:32:39 Max_iter: 1000
At iteration 154, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.111 min
==========
Testing lambda: 0.002154 starting at 2024-09-26 00:32:46 Max_iter: 1000
At iteration 137, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.099 min
==========
Testing lambda: 0.003162 starting at 2024-09-26 00:32:52 Max_iter: 1000
At iteration 112, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.085 min
==========
Testing lambda: 0.004642 starting at 2024-09-26 00:32:57 Max_iter: 1000
At iteration 76, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.065 min
==========
Testing lambda: 0.006813 starting at 2024-09-26 00:33:01 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.022 min
==========
Testing lambda: 0.01 starting at 2024-09-26 00:33:02 Max_iter: 1000
At iteration 1, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.019 min
==========
Testing lambda: 0.014678 starting at 2024-09-26 00:33:03 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.014677992676220683, cost : 0.016 min
==========
Testing lambda: 0.021544 starting at 2024-09-26 00:33:04 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.02154434690031883, cost : 0.014 min
==========
Testing lambda: 0.031623 starting at 2024-09-26 00:33:05 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0316227766016838, cost : 0.015 min
==========
Testing lambda: 0.046416 starting at 2024-09-26 00:33:06 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.046415888336127774, cost : 0.015 min
==========
Testing lambda: 0.068129 starting at 2024-09-26 00:33:07 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.06812920690579607, cost : 0.015 min
==========
Testing lambda: 0.1 starting at 2024-09-26 00:33:08 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.015 min
==========
Testing lambda: 0.14678 starting at 2024-09-26 00:33:09 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.015 min
==========
Testing lambda: 0.215443 starting at 2024-09-26 00:33:10 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.015 min
==========
Testing lambda: 0.316228 starting at 2024-09-26 00:33:11 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.018 min
==========
Testing lambda: 0.464159 starting at 2024-09-26 00:33:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.015 min
==========
Testing lambda: 0.681292 starting at 2024-09-26 00:33:12 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.015 min
==========
Testing lambda: 1.0 starting at 2024-09-26 00:33:13 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.015 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.226731    0.195122          0.193133            6236  0.944351  0.711494  0.707853   0.935484  0.682353      0.161511       0.101034
0.000015    0.332497    0.128920          0.128755            9145  0.946685  0.676033  0.691681   0.785714  0.687500      0.662999       0.000051
0.000022    0.238693    0.184669          0.184549            6565  0.932813  0.682943  0.688952   0.857143  0.674157      0.252696       0.003646
0.000032    0.199316    0.212544          0.210300            5482  0.938782  0.703911  0.688952   0.857143  0.674157      0.267237       0.004021
0.000046    0.229603    0.184669          0.184549            6315  0.936616  0.703135  0.679238   0.833333  0.666667      0.673224       0.000033
Exporting resultDF
Exporting result Dict
dnT Time elapsed: 9.48909120162328 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for gdT
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-26 00:33:44 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 721, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.074 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-26 00:34:49 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 733, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 1.018 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-26 00:35:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 728, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 0.974 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-26 00:36:48 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 742, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 0.975 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-26 00:37:47 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 715, Convergence with loss difference, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 0.919 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-26 00:38:42 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 718, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 0.852 min
==========
Testing lambda: 0.0001 starting at 2024-09-26 00:39:33 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 711, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999991e-05, cost : 0.854 min
==========
Testing lambda: 0.000147 starting at 2024-09-26 00:40:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 703, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 0.719 min
==========
Testing lambda: 0.000215 starting at 2024-09-26 00:41:08 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 694, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 0.642 min
==========
Testing lambda: 0.000316 starting at 2024-09-26 00:41:46 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 656, Convergence with loss difference, Device: cuda
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 0.586 min
==========
Testing lambda: 0.000464 starting at 2024-09-26 00:42:21 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 629, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 0.55 min
==========
Testing lambda: 0.000681 starting at 2024-09-26 00:42:54 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 602, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 0.509 min
==========
Testing lambda: 0.001 starting at 2024-09-26 00:43:25 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 590, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 0.528 min
==========
Testing lambda: 0.001468 starting at 2024-09-26 00:43:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 575, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 0.56 min
==========
Testing lambda: 0.002154 starting at 2024-09-26 00:44:30 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 571, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 0.592 min
==========
Testing lambda: 0.003162 starting at 2024-09-26 00:45:06 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 290, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 0.228 min
==========
Testing lambda: 0.004642 starting at 2024-09-26 00:45:19 Max_iter: 1000
At iteration 267, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 0.174 min
==========
Testing lambda: 0.006813 starting at 2024-09-26 00:45:30 Max_iter: 1000
At iteration 258, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 0.168 min
==========
Testing lambda: 0.01 starting at 2024-09-26 00:45:40 Max_iter: 1000
At iteration 244, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 0.16 min
==========
Testing lambda: 0.014678 starting at 2024-09-26 00:45:50 Max_iter: 1000
At iteration 256, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 0.168 min
==========
Testing lambda: 0.021544 starting at 2024-09-26 00:46:00 Max_iter: 1000
At iteration 247, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.161 min
==========
Testing lambda: 0.031623 starting at 2024-09-26 00:46:09 Max_iter: 1000
At iteration 186, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.126 min
==========
Testing lambda: 0.046416 starting at 2024-09-26 00:46:17 Max_iter: 1000
At iteration 232, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.153 min
==========
Testing lambda: 0.068129 starting at 2024-09-26 00:46:26 Max_iter: 1000
At iteration 101, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.076 min
==========
Testing lambda: 0.1 starting at 2024-09-26 00:46:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.017 min
==========
Testing lambda: 0.14678 starting at 2024-09-26 00:46:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.018 min
==========
Testing lambda: 0.215443 starting at 2024-09-26 00:46:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.016 min
==========
Testing lambda: 0.316228 starting at 2024-09-26 00:46:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.016 min
==========
Testing lambda: 0.464159 starting at 2024-09-26 00:46:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-26 00:46:36 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-26 00:46:37 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.016 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.264725    0.148605          0.147925            7281  0.988975  0.901065  0.826750   0.813953  0.832232      0.140730       0.000134
0.000015    0.228658    0.167382          0.166667            6289  0.988973  0.904111  0.843841   0.833333  0.848806      0.143525       0.000198
0.000022    0.195390    0.189914          0.188755            5374  0.987489  0.911565  0.856391   0.844156  0.860927      0.147310       0.000002
0.000032    0.160558    0.216738          0.215529            4416  0.990324  0.915189  0.845433   0.833766  0.850331      0.152302       0.000126
0.000046    0.128236    0.254292          0.253012            3527  0.988963  0.912978  0.846881   0.841689  0.851802      0.159113       0.000114
Exporting resultDF
Exporting result Dict
gdT Time elapsed: 13.044716461499531 minutes.
Z-transformed rep_cells adata: (57515, 27504)
TYPE <class 'numpy.ndarray'>
====================
Starting job for pDC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509
  -1.91882091  -1.53505673  -1.15129255  -0.76752836  -0.38376418
   0.        ]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01 1.46779927e-01 2.15443469e-01 3.16227766e-01
 4.64158883e-01 6.81292069e-01 1.00000000e+00]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-09-26 00:47:11 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 463, Convergence with loss difference, Device: cuda
lambda is : 9.999999999999997e-06, cost : 1.511 min
==========
Testing lambda: 1.5e-05 starting at 2024-09-26 00:48:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 795, Convergence with loss difference, Device: cuda
lambda is : 1.4677992676220687e-05, cost : 2.139 min
==========
Testing lambda: 2.2e-05 starting at 2024-09-26 00:50:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 797, Convergence with loss difference, Device: cuda
lambda is : 2.1544346900318816e-05, cost : 2.188 min
==========
Testing lambda: 3.2e-05 starting at 2024-09-26 00:53:01 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 487, Convergence with loss difference, Device: cuda
lambda is : 3.16227766016838e-05, cost : 1.661 min
==========
Testing lambda: 4.6e-05 starting at 2024-09-26 00:54:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 4.6415888336127784e-05, cost : 2.248 min
==========
Testing lambda: 6.8e-05 starting at 2024-09-26 00:56:55 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 887, Convergence with loss difference, Device: cuda
lambda is : 6.81292069057961e-05, cost : 2.305 min
==========
Testing lambda: 0.0001 starting at 2024-09-26 00:59:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
OWL-QN did not convergence, Device: cuda
lambda is : 9.999999999999991e-05, cost : 2.437 min
==========
Testing lambda: 0.000147 starting at 2024-09-26 01:01:40 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 836, Convergence with loss difference, Device: cuda
lambda is : 0.00014677992676220676, cost : 2.39 min
==========
Testing lambda: 0.000215 starting at 2024-09-26 01:04:03 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 862, Convergence with loss difference, Device: cuda
lambda is : 0.0002154434690031884, cost : 2.544 min
==========
Testing lambda: 0.000316 starting at 2024-09-26 01:06:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 853, Convergence with loss difference, Device: cuda
lambda is : 0.00031622776601683783, cost : 2.64 min
==========
Testing lambda: 0.000464 starting at 2024-09-26 01:09:14 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 793, Convergence with loss difference, Device: cuda
lambda is : 0.00046415888336127757, cost : 2.65 min
==========
Testing lambda: 0.000681 starting at 2024-09-26 01:11:53 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 733, Convergence with loss difference, Device: cuda
lambda is : 0.0006812920690579611, cost : 2.373 min
==========
Testing lambda: 0.001 starting at 2024-09-26 01:14:16 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 753, Convergence with loss difference, Device: cuda
lambda is : 0.0009999999999999994, cost : 2.335 min
==========
Testing lambda: 0.001468 starting at 2024-09-26 01:16:36 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 644, Convergence with loss difference, Device: cuda
lambda is : 0.0014677992676220694, cost : 2.35 min
==========
Testing lambda: 0.002154 starting at 2024-09-26 01:18:57 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 637, Convergence with loss difference, Device: cuda
lambda is : 0.0021544346900318825, cost : 2.165 min
==========
Testing lambda: 0.003162 starting at 2024-09-26 01:21:07 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 615, Convergence with loss difference, Device: cuda
lambda is : 0.003162277660168379, cost : 1.729 min
==========
Testing lambda: 0.004642 starting at 2024-09-26 01:22:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 558, Convergence with loss difference, Device: cuda
lambda is : 0.004641588833612776, cost : 1.994 min
==========
Testing lambda: 0.006813 starting at 2024-09-26 01:24:50 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 624, Convergence with loss difference, Device: cuda
lambda is : 0.006812920690579607, cost : 2.421 min
==========
Testing lambda: 0.01 starting at 2024-09-26 01:27:15 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 394, Convergence with loss difference, Device: cuda
lambda is : 0.009999999999999995, cost : 1.426 min
==========
Testing lambda: 0.014678 starting at 2024-09-26 01:28:41 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 386, Convergence with loss difference, Device: cuda
lambda is : 0.014677992676220683, cost : 1.171 min
==========
Testing lambda: 0.021544 starting at 2024-09-26 01:29:51 Max_iter: 1000
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff.py:167: UserWarning: line search did not converge.
  warnings.warn('line search did not converge.')
At iteration 226, Convergence with loss difference, Device: cuda
lambda is : 0.02154434690031883, cost : 0.246 min
==========
Testing lambda: 0.031623 starting at 2024-09-26 01:30:06 Max_iter: 1000
At iteration 280, Convergence with loss difference, Device: cuda
lambda is : 0.0316227766016838, cost : 0.181 min
==========
Testing lambda: 0.046416 starting at 2024-09-26 01:30:17 Max_iter: 1000
At iteration 200, Convergence with loss difference, Device: cuda
lambda is : 0.046415888336127774, cost : 0.135 min
==========
Testing lambda: 0.068129 starting at 2024-09-26 01:30:25 Max_iter: 1000
At iteration 95, Convergence with loss difference, Device: cuda
lambda is : 0.06812920690579607, cost : 0.074 min
==========
Testing lambda: 0.1 starting at 2024-09-26 01:30:29 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.0999999999999999, cost : 0.018 min
==========
Testing lambda: 0.14678 starting at 2024-09-26 01:30:30 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.14677992676220672, cost : 0.017 min
==========
Testing lambda: 0.215443 starting at 2024-09-26 01:30:31 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.21544346900318834, cost : 0.017 min
==========
Testing lambda: 0.316228 starting at 2024-09-26 01:30:32 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.3162277660168378, cost : 0.017 min
==========
Testing lambda: 0.464159 starting at 2024-09-26 01:30:33 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.4641588833612774, cost : 0.016 min
==========
Testing lambda: 0.681292 starting at 2024-09-26 01:30:34 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 0.6812920690579604, cost : 0.016 min
==========
Testing lambda: 1.0 starting at 2024-09-26 01:30:35 Max_iter: 1000
Hessian initialization fail, gradient diff = 0
lambda is : 1.0, cost : 0.017 min
==========
          Percentage  Prevalence  Train_prevalence  Feature_number       AUC      AUPR       MCC  Precision  F1 score  loss_history  error_history
0.000010    0.413903    0.184255          0.182773           11384  0.999911  0.991670  0.750655   0.568075  0.724551      0.346147       0.000191
0.000015    0.314863    0.262144          0.258403            8660  0.999868  0.987903  0.820081   0.675978  0.806667      0.263992       0.128515
0.000022    0.287340    0.289782          0.287815            7903  0.999824  0.984000  0.906228   0.823129  0.902985      0.260147       0.001816
0.000032    0.326498    0.256281          0.254202            8980  0.999857  0.988649  0.832300   0.701754  0.821918      0.375708       0.000133
0.000046    0.180483    0.392797          0.390756            4964  0.992690  0.983705  0.914530   0.845070  0.912548      0.151840       0.020410
Exporting resultDF
Exporting result Dict
pDC Time elapsed: 43.563340675830844 minutes.
***** Finished lambda tuning
====================

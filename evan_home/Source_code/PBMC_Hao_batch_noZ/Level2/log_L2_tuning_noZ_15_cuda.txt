nohup: ignoring input
Representative adata: (57515, 27504) <class 'scipy.sparse._csc.csc_matrix'>
all cell types: ['ASDC', 'B_intermediate', 'B_memory', 'B_naive', 'CD14_Mono', 'CD16_Mono', 'CD4_CTL', 'CD4_Naive', 'CD4_Proliferating', 'CD4_TCM', 'CD4_TEM', 'CD8_Naive', 'CD8_Proliferating', 'CD8_TCM', 'CD8_TEM', 'Doublet', 'Eryth', 'HSPC', 'ILC', 'MAIT', 'NK', 'NK_CD56bright', 'NK_Proliferating', 'Plasmablast', 'Platelet', 'Treg', 'cDC1', 'cDC2', 'dnT', 'gdT', 'pDC']
====================
Queue ['ASDC', 'B_intermediate', 'B_memory', 'B_naive', 'CD14_Mono', 'CD16_Mono', 'CD4_CTL', 'CD4_Naive', 'CD4_Proliferating', 'CD4_TCM', 'CD4_TEM', 'CD8_Naive', 'CD8_Proliferating', 'CD8_TCM', 'CD8_TEM']
====================
***** Starting tuning
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for ASDC
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-02 17:11:31 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.01382057461887598 ; diff loss =  4.6100467443466187e-07 ; diff weight =  0.00490354560315609
lambda is : 9.999999999999997e-06, cost : 0.439 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-02 17:11:57 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.013985378667712212 ; diff loss =  5.606561899185181e-07 ; diff weight =  0.0059430100955069065
lambda is : 1.4677992676220687e-05, cost : 0.364 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-02 17:12:19 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.014221369288861752 ; diff loss =  7.35744833946228e-07 ; diff weight =  0.007656129077076912
lambda is : 2.1544346900318854e-05, cost : 0.377 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-02 17:12:41 Max_iter: 1000
At iteration 355, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  356 ; minimum lost =  0.0009634946472942829 ; diff loss =  9.913928806781769e-07 ; diff weight =  0.009089161641895771
lambda is : 3.16227766016838e-05, cost : 5.792 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-02 17:18:30 Max_iter: 1000
At iteration 362, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  363 ; minimum lost =  0.0011989327613264322 ; diff loss =  9.62521880865097e-07 ; diff weight =  0.020097211003303528
lambda is : 4.6415888336127784e-05, cost : 5.684 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-02 17:24:11 Max_iter: 1000
At iteration 349, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  350 ; minimum lost =  0.0015220922650769353 ; diff loss =  9.622890502214432e-07 ; diff weight =  0.011580239981412888
lambda is : 6.81292069057961e-05, cost : 5.455 min
==========
Testing lambda: 0.0001 starting at 2024-10-02 17:29:38 Max_iter: 1000
At iteration 337, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  338 ; minimum lost =  0.0019493114668875933 ; diff loss =  9.82312485575676e-07 ; diff weight =  0.010501952841877937
lambda is : 9.999999999999991e-05, cost : 5.267 min
==========
Testing lambda: 0.000147 starting at 2024-10-02 17:34:55 Max_iter: 1000
At iteration 306, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  307 ; minimum lost =  0.00251232972368598 ; diff loss =  9.648501873016357e-07 ; diff weight =  0.009159721434116364
lambda is : 0.00014677992676220703, cost : 4.791 min
==========
Testing lambda: 0.000215 starting at 2024-10-02 17:39:42 Max_iter: 1000
At iteration 298, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  299 ; minimum lost =  0.0032111881300807 ; diff loss =  9.543728083372116e-07 ; diff weight =  0.006563245318830013
lambda is : 0.0002154434690031884, cost : 4.666 min
==========
Testing lambda: 0.000316 starting at 2024-10-02 17:44:22 Max_iter: 1000
At iteration 270, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  271 ; minimum lost =  0.004166004713624716 ; diff loss =  8.475035429000854e-07 ; diff weight =  0.007997848093509674
lambda is : 0.00031622776601683783, cost : 4.237 min
==========
Testing lambda: 0.000464 starting at 2024-10-02 17:48:36 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  265 ; minimum lost =  0.0052672820165753365 ; diff loss =  9.257346391677856e-07 ; diff weight =  0.003919882234185934
lambda is : 0.00046415888336127795, cost : 4.142 min
==========
Testing lambda: 0.000681 starting at 2024-10-02 17:52:45 Max_iter: 1000
At iteration 272, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  273 ; minimum lost =  0.0067372508347034454 ; diff loss =  9.080395102500916e-07 ; diff weight =  0.00520313112065196
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 4.263 min
==========
Testing lambda: 0.001 starting at 2024-10-02 17:57:01 Max_iter: 1000
At iteration 252, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  253 ; minimum lost =  0.008530033752322197 ; diff loss =  9.94652509689331e-07 ; diff weight =  0.006217409856617451
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 3.955 min
==========
Testing lambda: 0.001468 starting at 2024-10-02 18:00:58 Max_iter: 1000
At iteration 249, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  250 ; minimum lost =  0.010522997006773949 ; diff loss =  7.618218660354614e-07 ; diff weight =  0.002750214422121644
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 3.908 min
==========
Testing lambda: 0.002154 starting at 2024-10-02 18:04:52 Max_iter: 1000
At iteration 105, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  106 ; minimum lost =  0.012040352448821068 ; diff loss =  9.471550583839417e-07 ; diff weight =  0.001683059032075107
lambda is : 0.0021544346900318843, cost : 1.686 min
==========
Testing lambda: 0.003162 starting at 2024-10-02 18:06:33 Max_iter: 1000
At iteration 91, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  92 ; minimum lost =  0.013227618299424648 ; diff loss =  8.00006091594696e-07 ; diff weight =  0.0025098661426454782
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.003162277660168382, cost : 1.463 min
==========
Testing lambda: 0.004642 starting at 2024-10-02 18:08:01 Max_iter: 1000
At iteration 120, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  121 ; minimum lost =  0.014869697391986847 ; diff loss =  8.87550413608551e-07 ; diff weight =  0.001687520183622837
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.004641588833612781, cost : 1.909 min
==========
Testing lambda: 0.006813 starting at 2024-10-02 18:09:56 Max_iter: 1000
At iteration 105, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  106 ; minimum lost =  0.017190372571349144 ; diff loss =  2.477318048477173e-07 ; diff weight =  1.2755393981933594e-05
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.006812920690579613, cost : 1.676 min
==========
Testing lambda: 0.01 starting at 2024-10-02 18:11:36 Max_iter: 1000
At iteration 106, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  107 ; minimum lost =  0.020558468997478485 ; diff loss =  7.450580596923828e-09 ; diff weight =  6.110934191383421e-05
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.010000000000000004, cost : 1.692 min
==========
Testing lambda: 0.014678 starting at 2024-10-02 18:13:18 Max_iter: 1000
At iteration 111, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  112 ; minimum lost =  0.02521343342959881 ; diff loss =  8.065253496170044e-07 ; diff weight =  0.00019592046737670898
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.014677992676220709, cost : 1.77 min
==========
Testing lambda: 0.021544 starting at 2024-10-02 18:15:04 Max_iter: 1000
At iteration 120, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  121 ; minimum lost =  0.03176334872841835 ; diff loss =  1.30385160446167e-07 ; diff weight =  0.000345766544342041
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.02154434690031885, cost : 1.907 min
==========
Testing lambda: 0.031623 starting at 2024-10-02 18:16:59 Max_iter: 1000
At iteration 122, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  123 ; minimum lost =  0.04083457589149475 ; diff loss =  1.9371509552001953e-07 ; diff weight =  0.00033849477767944336
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0316227766016838, cost : 1.939 min
==========
Testing lambda: 0.046416 starting at 2024-10-02 18:18:55 Max_iter: 1000
At iteration 130, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  131 ; minimum lost =  0.05329354852437973 ; diff loss =  5.923211574554443e-07 ; diff weight =  0.0005339384078979492
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.04641588833612786, cost : 2.063 min
==========
Testing lambda: 0.068129 starting at 2024-10-02 18:20:59 Max_iter: 1000
At iteration 133, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  134 ; minimum lost =  0.07025538384914398 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.0005919337272644043
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0681292069057962, cost : 2.11 min
==========
Testing lambda: 0.1 starting at 2024-10-02 18:23:05 Max_iter: 1000
At iteration 131, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  132 ; minimum lost =  0.09313294291496277 ; diff loss =  2.7567148208618164e-07 ; diff weight =  0.00026285648345947266
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.10000000000000002, cost : 2.074 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.390670    0.236842          0.130434           10745  ...        1.0       1.0      0.013821       0.004904
0.000015    0.376382    0.250000          0.137224           10352  ...        1.0       1.0      0.013985       0.005943
0.000022    0.359002    0.263158          0.144867            9874  ...        1.0       1.0      0.014221       0.007656
0.000032    0.006908    1.000000          0.739750             190  ...        1.0       1.0      0.000963       0.009089
0.000046    0.004072    1.000000          0.776023             112  ...        1.0       1.0      0.001199       0.020097

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
ASDC Time elapsed: 73.72571821212769 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for B_intermediate
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-02 18:25:21 Max_iter: 1000
At iteration 612, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  613 ; minimum lost =  0.0070732831954956055 ; diff loss =  3.7439167499542236e-07 ; diff weight =  0.0009603252401575446
lambda is : 9.999999999999997e-06, cost : 9.758 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-02 18:35:06 Max_iter: 1000
At iteration 490, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  491 ; minimum lost =  0.009687626734375954 ; diff loss =  9.723007678985596e-07 ; diff weight =  0.0007362462347373366
lambda is : 1.4677992676220687e-05, cost : 7.908 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-02 18:43:01 Max_iter: 1000
At iteration 528, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  529 ; minimum lost =  0.010936870239675045 ; diff loss =  7.394701242446899e-07 ; diff weight =  0.007874183356761932
lambda is : 2.1544346900318854e-05, cost : 8.612 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-02 18:51:37 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  454 ; minimum lost =  0.01331890095025301 ; diff loss =  9.55536961555481e-07 ; diff weight =  0.001213402603752911
lambda is : 3.16227766016838e-05, cost : 7.303 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-02 18:58:56 Max_iter: 1000
At iteration 475, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  476 ; minimum lost =  0.014936741441488266 ; diff loss =  8.856877684593201e-07 ; diff weight =  0.00032445319811813533
lambda is : 4.6415888336127784e-05, cost : 7.685 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-02 19:06:37 Max_iter: 1000
At iteration 527, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  528 ; minimum lost =  0.016894089058041573 ; diff loss =  7.916241884231567e-07 ; diff weight =  0.0007443930371664464
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 8.446 min
==========
Testing lambda: 0.0001 starting at 2024-10-02 19:15:03 Max_iter: 1000
At iteration 490, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  491 ; minimum lost =  0.019379032775759697 ; diff loss =  6.221234798431396e-07 ; diff weight =  0.0008115890668705106
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 7.814 min
==========
Testing lambda: 0.000147 starting at 2024-10-02 19:22:52 Max_iter: 1000
At iteration 490, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  491 ; minimum lost =  0.022108804434537888 ; diff loss =  6.742775440216064e-07 ; diff weight =  0.00046878549619577825
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 7.779 min
==========
Testing lambda: 0.000215 starting at 2024-10-02 19:30:39 Max_iter: 1000
At iteration 436, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  437 ; minimum lost =  0.025269541889429092 ; diff loss =  4.991888999938965e-07 ; diff weight =  0.0004434439179021865
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 6.91 min
==========
Testing lambda: 0.000316 starting at 2024-10-02 19:37:34 Max_iter: 1000
At iteration 506, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  507 ; minimum lost =  0.028561096638441086 ; diff loss =  8.717179298400879e-07 ; diff weight =  0.0018706611590459943
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 7.925 min
==========
Testing lambda: 0.000464 starting at 2024-10-02 19:45:29 Max_iter: 1000
At iteration 408, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  408 ; minimum lost =  0.032758936285972595 ; diff loss =  -4.470348358154297e-07 ; diff weight =  0.015454118140041828
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 6.511 min
==========
Testing lambda: 0.000681 starting at 2024-10-02 19:52:00 Max_iter: 1000
At iteration 474, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  475 ; minimum lost =  0.03683110326528549 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0014262873446568847
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 7.418 min
==========
Testing lambda: 0.001 starting at 2024-10-02 19:59:25 Max_iter: 1000
At iteration 451, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  452 ; minimum lost =  0.041492220014333725 ; diff loss =  8.866190910339355e-07 ; diff weight =  0.0018885701429098845
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 7.046 min
==========
Testing lambda: 0.001468 starting at 2024-10-02 20:06:28 Max_iter: 1000
At iteration 430, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  431 ; minimum lost =  0.046819452196359634 ; diff loss =  9.872019290924072e-07 ; diff weight =  0.0017910957103595138
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 6.72 min
==========
Testing lambda: 0.002154 starting at 2024-10-02 20:13:11 Max_iter: 1000
At iteration 426, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  427 ; minimum lost =  0.05293811857700348 ; diff loss =  6.034970283508301e-07 ; diff weight =  0.0009730450110509992
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 6.647 min
==========
Testing lambda: 0.003162 starting at 2024-10-02 20:19:50 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  443 ; minimum lost =  0.05974921956658363 ; diff loss =  9.648501873016357e-07 ; diff weight =  0.0015672770095989108
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 6.886 min
==========
Testing lambda: 0.004642 starting at 2024-10-02 20:26:43 Max_iter: 1000
At iteration 384, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  385 ; minimum lost =  0.06732554733753204 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0010192561894655228
lambda is : 0.004641588833612781, cost : 5.977 min
==========
Testing lambda: 0.006813 starting at 2024-10-02 20:32:41 Max_iter: 1000
At iteration 319, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  320 ; minimum lost =  0.07612926512956619 ; diff loss =  7.003545761108398e-07 ; diff weight =  0.0001782996259862557
lambda is : 0.006812920690579613, cost : 4.978 min
==========
Testing lambda: 0.01 starting at 2024-10-02 20:37:40 Max_iter: 1000
At iteration 382, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  383 ; minimum lost =  0.08632306754589081 ; diff loss =  6.854534149169922e-07 ; diff weight =  0.0012370580807328224
lambda is : 0.010000000000000004, cost : 5.948 min
==========
Testing lambda: 0.014678 starting at 2024-10-02 20:43:37 Max_iter: 1000
At iteration 371, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  372 ; minimum lost =  0.09849566221237183 ; diff loss =  3.129243850708008e-07 ; diff weight =  0.0001416193408658728
lambda is : 0.014677992676220709, cost : 5.774 min
==========
Testing lambda: 0.021544 starting at 2024-10-02 20:49:23 Max_iter: 1000
At iteration 313, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  314 ; minimum lost =  0.11264990270137787 ; diff loss =  2.980232238769531e-07 ; diff weight =  0.00030012495699338615
lambda is : 0.02154434690031885, cost : 4.886 min
==========
Testing lambda: 0.031623 starting at 2024-10-02 20:54:16 Max_iter: 1000
At iteration 301, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  302 ; minimum lost =  0.12916353344917297 ; diff loss =  7.152557373046875e-07 ; diff weight =  0.0007853080751374364
lambda is : 0.0316227766016838, cost : 4.704 min
==========
Testing lambda: 0.046416 starting at 2024-10-02 20:58:59 Max_iter: 1000
At iteration 211, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  212 ; minimum lost =  0.14492560923099518 ; diff loss =  4.917383193969727e-07 ; diff weight =  0.00018696169718168676
lambda is : 0.04641588833612786, cost : 3.315 min
==========
Testing lambda: 0.068129 starting at 2024-10-02 21:02:18 Max_iter: 1000
At iteration 191, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  191 ; minimum lost =  0.1580829620361328 ; diff loss =  -2.9802322387695312e-08 ; diff weight =  0.0009587170789018273
lambda is : 0.0681292069057962, cost : 3.011 min
==========
Testing lambda: 0.1 starting at 2024-10-02 21:05:18 Max_iter: 1000
At iteration 170, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  171 ; minimum lost =  0.17635366320610046 ; diff loss =  2.980232238769531e-07 ; diff weight =  0.0001189945251098834
lambda is : 0.10000000000000002, cost : 2.679 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.089587    0.463789          0.396960            2464  ...        1.0       1.0      0.007073       0.000960
0.000015    0.106385    0.426847          0.369176            2926  ...        1.0       1.0      0.009688       0.000736
0.000022    0.070826    0.517922          0.444744            1948  ...        1.0       1.0      0.010937       0.007874
0.000032    0.074971    0.515728          0.447852            2062  ...        1.0       1.0      0.013319       0.001213
0.000046    0.058210    0.583029          0.502725            1601  ...        1.0       1.0      0.014937       0.000324

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
B_intermediate Time elapsed: 162.70824576616286 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for B_memory
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-02 21:08:09 Max_iter: 1000
At iteration 579, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  580 ; minimum lost =  0.004550798796117306 ; diff loss =  8.586794137954712e-07 ; diff weight =  0.002869597403332591
lambda is : 9.999999999999997e-06, cost : 9.229 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-02 21:17:23 Max_iter: 1000
At iteration 623, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  624 ; minimum lost =  0.005308700725436211 ; diff loss =  7.622875273227692e-07 ; diff weight =  0.004501818213611841
lambda is : 1.4677992676220687e-05, cost : 10.027 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-02 21:27:25 Max_iter: 1000
At iteration 523, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  524 ; minimum lost =  0.0069687990471720695 ; diff loss =  9.378418326377869e-07 ; diff weight =  0.0015134336426854134
lambda is : 2.1544346900318854e-05, cost : 8.361 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-02 21:35:46 Max_iter: 1000
At iteration 536, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  537 ; minimum lost =  0.00820065476000309 ; diff loss =  6.165355443954468e-07 ; diff weight =  0.0009170119883492589
lambda is : 3.16227766016838e-05, cost : 8.52 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-02 21:44:17 Max_iter: 1000
At iteration 530, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  531 ; minimum lost =  0.009868563152849674 ; diff loss =  7.990747690200806e-07 ; diff weight =  0.000829446769785136
lambda is : 4.6415888336127784e-05, cost : 8.399 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-02 21:52:41 Max_iter: 1000
At iteration 480, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  481 ; minimum lost =  0.011649161577224731 ; diff loss =  3.334134817123413e-07 ; diff weight =  0.010769978165626526
lambda is : 6.81292069057961e-05, cost : 7.626 min
==========
Testing lambda: 0.0001 starting at 2024-10-02 22:00:19 Max_iter: 1000
At iteration 525, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  526 ; minimum lost =  0.013450250029563904 ; diff loss =  5.848705768585205e-07 ; diff weight =  0.004848322831094265
lambda is : 9.999999999999991e-05, cost : 8.281 min
==========
Testing lambda: 0.000147 starting at 2024-10-02 22:08:36 Max_iter: 1000
At iteration 494, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  495 ; minimum lost =  0.01570194587111473 ; diff loss =  7.80448317527771e-07 ; diff weight =  0.004937019199132919
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 7.799 min
==========
Testing lambda: 0.000215 starting at 2024-10-02 22:16:24 Max_iter: 1000
At iteration 522, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  523 ; minimum lost =  0.018215756863355637 ; diff loss =  6.51925802230835e-07 ; diff weight =  0.0005129952332936227
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 8.192 min
==========
Testing lambda: 0.000316 starting at 2024-10-02 22:24:35 Max_iter: 1000
At iteration 530, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  531 ; minimum lost =  0.02125353366136551 ; diff loss =  9.257346391677856e-07 ; diff weight =  0.003112185513600707
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 8.283 min
==========
Testing lambda: 0.000464 starting at 2024-10-02 22:32:52 Max_iter: 1000
At iteration 498, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  499 ; minimum lost =  0.02498505264520645 ; diff loss =  9.57399606704712e-07 ; diff weight =  0.002894745906814933
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 7.921 min
==========
Testing lambda: 0.000681 starting at 2024-10-02 22:40:48 Max_iter: 1000
At iteration 491, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.029438123106956482 ; diff loss =  4.76837158203125e-07 ; diff weight =  0.002770261839032173
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 7.669 min
==========
Testing lambda: 0.001 starting at 2024-10-02 22:48:28 Max_iter: 1000
At iteration 525, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  526 ; minimum lost =  0.03495020419359207 ; diff loss =  7.152557373046875e-07 ; diff weight =  0.0026166613679379225
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 8.192 min
==========
Testing lambda: 0.001468 starting at 2024-10-02 22:56:39 Max_iter: 1000
At iteration 478, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  479 ; minimum lost =  0.041819848120212555 ; diff loss =  6.444752216339111e-07 ; diff weight =  0.002377450233325362
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.463 min
==========
Testing lambda: 0.002154 starting at 2024-10-02 23:04:07 Max_iter: 1000
At iteration 522, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  523 ; minimum lost =  0.05033810809254646 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.00230531208217144
lambda is : 0.0021544346900318843, cost : 8.137 min
==========
Testing lambda: 0.003162 starting at 2024-10-02 23:12:15 Max_iter: 1000
At iteration 416, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  416 ; minimum lost =  0.06117141991853714 ; diff loss =  -5.587935447692871e-07 ; diff weight =  0.009144102223217487
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 6.521 min
==========
Testing lambda: 0.004642 starting at 2024-10-02 23:18:47 Max_iter: 1000
At iteration 481, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  482 ; minimum lost =  0.0736415833234787 ; diff loss =  9.611248970031738e-07 ; diff weight =  0.000672078225761652
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 7.497 min
==========
Testing lambda: 0.006813 starting at 2024-10-02 23:26:16 Max_iter: 1000
At iteration 467, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  468 ; minimum lost =  0.08792911469936371 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.0009423423907719553
lambda is : 0.006812920690579613, cost : 7.277 min
==========
Testing lambda: 0.01 starting at 2024-10-02 23:33:33 Max_iter: 1000
At iteration 375, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  376 ; minimum lost =  0.10307227075099945 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0006906171911396086
lambda is : 0.010000000000000004, cost : 5.855 min
==========
Testing lambda: 0.014678 starting at 2024-10-02 23:39:24 Max_iter: 1000
At iteration 336, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  337 ; minimum lost =  0.11659212410449982 ; diff loss =  6.92903995513916e-07 ; diff weight =  4.552240716293454e-05
lambda is : 0.014677992676220709, cost : 5.242 min
==========
Testing lambda: 0.021544 starting at 2024-10-02 23:44:39 Max_iter: 1000
At iteration 348, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  349 ; minimum lost =  0.1311190128326416 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.001733513898216188
lambda is : 0.02154434690031885, cost : 5.426 min
==========
Testing lambda: 0.031623 starting at 2024-10-02 23:50:04 Max_iter: 1000
At iteration 272, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  272 ; minimum lost =  0.1474114954471588 ; diff loss =  0.0 ; diff weight =  1.4409424693440087e-05
lambda is : 0.0316227766016838, cost : 4.255 min
==========
Testing lambda: 0.046416 starting at 2024-10-02 23:54:20 Max_iter: 1000
At iteration 204, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  205 ; minimum lost =  0.16417834162712097 ; diff loss =  1.4901161193847656e-07 ; diff weight =  9.915630653267726e-05
lambda is : 0.04641588833612786, cost : 3.206 min
==========
Testing lambda: 0.068129 starting at 2024-10-02 23:57:32 Max_iter: 1000
At iteration 209, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  210 ; minimum lost =  0.17741529643535614 ; diff loss =  3.427267074584961e-07 ; diff weight =  0.0002015872159972787
lambda is : 0.0681292069057962, cost : 3.286 min
==========
Testing lambda: 0.1 starting at 2024-10-03 00:00:49 Max_iter: 1000
At iteration 185, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  186 ; minimum lost =  0.19474676251411438 ; diff loss =  4.470348358154297e-07 ; diff weight =  2.4978209694381803e-05
lambda is : 0.10000000000000002, cost : 2.916 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.071117    0.488386          0.445011            1956  ...        1.0       1.0      0.004551       0.002870
0.000015    0.051302    0.560976          0.497034            1411  ...        1.0       1.0      0.005309       0.004502
0.000022    0.057083    0.567944          0.510557            1570  ...        1.0       1.0      0.006969       0.001513
0.000032    0.046611    0.622822          0.560769            1282  ...        1.0       1.0      0.008201       0.000917
0.000046    0.037885    0.668990          0.599547            1042  ...        1.0       1.0      0.009869       0.000829

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff_noZ.py:929: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax1 = plt.subplots(figsize = (fig_width,fig_height))
B_memory Time elapsed: 175.6539203206698 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for B_naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 00:03:54 Max_iter: 1000
At iteration 609, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  610 ; minimum lost =  0.004778820555657148 ; diff loss =  6.39352947473526e-07 ; diff weight =  0.0011973986402153969
lambda is : 9.999999999999997e-06, cost : 9.686 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 00:13:36 Max_iter: 1000
At iteration 557, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  558 ; minimum lost =  0.0061188084073364735 ; diff loss =  9.60659235715866e-07 ; diff weight =  0.0009524397319182754
lambda is : 1.4677992676220687e-05, cost : 8.908 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 00:22:30 Max_iter: 1000
At iteration 559, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  560 ; minimum lost =  0.007015823852270842 ; diff loss =  6.300397217273712e-07 ; diff weight =  0.0007848813547752798
lambda is : 2.1544346900318854e-05, cost : 9.053 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 00:31:33 Max_iter: 1000
At iteration 564, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  565 ; minimum lost =  0.00803704559803009 ; diff loss =  6.835907697677612e-07 ; diff weight =  0.0004555611521936953
lambda is : 3.16227766016838e-05, cost : 8.947 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 00:40:30 Max_iter: 1000
At iteration 586, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  587 ; minimum lost =  0.009129922837018967 ; diff loss =  7.553026080131531e-07 ; diff weight =  0.003983534872531891
lambda is : 4.6415888336127784e-05, cost : 9.256 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 00:49:45 Max_iter: 1000
At iteration 542, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  543 ; minimum lost =  0.010550111532211304 ; diff loss =  5.746260285377502e-07 ; diff weight =  0.007551921531558037
lambda is : 6.81292069057961e-05, cost : 8.558 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 00:58:19 Max_iter: 1000
At iteration 584, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  585 ; minimum lost =  0.011737300083041191 ; diff loss =  7.7858567237854e-07 ; diff weight =  0.0009271123562939465
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 9.189 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 01:07:30 Max_iter: 1000
At iteration 600, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  601 ; minimum lost =  0.013126271776854992 ; diff loss =  9.955838322639465e-07 ; diff weight =  0.0037503736093640327
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 9.403 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 01:16:54 Max_iter: 1000
At iteration 597, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  598 ; minimum lost =  0.014713091775774956 ; diff loss =  6.984919309616089e-07 ; diff weight =  0.0035888198763132095
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 9.32 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 01:26:14 Max_iter: 1000
At iteration 589, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  590 ; minimum lost =  0.016561079770326614 ; diff loss =  7.7858567237854e-07 ; diff weight =  0.00398787809535861
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 9.189 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 01:35:25 Max_iter: 1000
At iteration 561, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  562 ; minimum lost =  0.018781837075948715 ; diff loss =  8.121132850646973e-07 ; diff weight =  0.004457319155335426
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 8.747 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 01:44:10 Max_iter: 1000
At iteration 559, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  560 ; minimum lost =  0.0215067770332098 ; diff loss =  8.121132850646973e-07 ; diff weight =  0.004740462638437748
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 8.691 min
==========
Testing lambda: 0.001 starting at 2024-10-03 01:52:51 Max_iter: 1000
At iteration 517, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  518 ; minimum lost =  0.02493755891919136 ; diff loss =  8.586794137954712e-07 ; diff weight =  0.004328462295234203
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 8.04 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 02:00:54 Max_iter: 1000
At iteration 491, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.029238209128379822 ; diff loss =  8.419156074523926e-07 ; diff weight =  0.003401529509574175
lambda is : 0.0014677992676220694, cost : 7.633 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 02:08:32 Max_iter: 1000
At iteration 468, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  469 ; minimum lost =  0.03465251624584198 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.004057885147631168
lambda is : 0.0021544346900318843, cost : 7.28 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 02:15:49 Max_iter: 1000
At iteration 555, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  555 ; minimum lost =  0.041390568017959595 ; diff loss =  -2.7194619178771973e-07 ; diff weight =  0.00811885204166174
lambda is : 0.003162277660168382, cost : 8.617 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 02:24:26 Max_iter: 1000
At iteration 483, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  484 ; minimum lost =  0.04996884986758232 ; diff loss =  8.977949619293213e-07 ; diff weight =  0.002451217034831643
lambda is : 0.004641588833612781, cost : 7.51 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 02:31:56 Max_iter: 1000
At iteration 481, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  482 ; minimum lost =  0.0609726682305336 ; diff loss =  8.493661880493164e-07 ; diff weight =  0.002106303349137306
lambda is : 0.006812920690579613, cost : 7.669 min
==========
Testing lambda: 0.01 starting at 2024-10-03 02:39:36 Max_iter: 1000
At iteration 471, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  472 ; minimum lost =  0.07493700087070465 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0019565389957278967
lambda is : 0.010000000000000004, cost : 7.327 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 02:46:56 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  443 ; minimum lost =  0.09254111349582672 ; diff loss =  8.344650268554688e-07 ; diff weight =  0.0018513540271669626
lambda is : 0.014677992676220709, cost : 6.884 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 02:53:49 Max_iter: 1000
At iteration 380, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  381 ; minimum lost =  0.11449263989925385 ; diff loss =  8.046627044677734e-07 ; diff weight =  0.0010121320374310017
lambda is : 0.02154434690031885, cost : 5.927 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 02:59:45 Max_iter: 1000
At iteration 349, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  350 ; minimum lost =  0.14084851741790771 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0009777593659237027
lambda is : 0.0316227766016838, cost : 5.445 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 03:05:11 Max_iter: 1000
At iteration 307, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  308 ; minimum lost =  0.1712626814842224 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0006040335865691304
lambda is : 0.04641588833612786, cost : 4.797 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 03:09:59 Max_iter: 1000
At iteration 264, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  265 ; minimum lost =  0.20746532082557678 ; diff loss =  8.940696716308594e-08 ; diff weight =  0.00014869391452521086
lambda is : 0.0681292069057962, cost : 4.134 min
==========
Testing lambda: 0.1 starting at 2024-10-03 03:14:07 Max_iter: 1000
At iteration 226, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  227 ; minimum lost =  0.24921928346157074 ; diff loss =  8.344650268554688e-07 ; diff weight =  0.0002779513015411794
lambda is : 0.10000000000000002, cost : 3.546 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.072935    0.431663          0.449782            2006  ...        1.0       1.0      0.004779       0.001197
0.000015    0.072426    0.437733          0.453225            1992  ...        1.0       1.0      0.006119       0.000952
0.000022    0.057555    0.495953          0.503121            1583  ...        1.0       1.0      0.007016       0.000785
0.000032    0.039885    0.575342          0.566064            1097  ...        1.0       1.0      0.008037       0.000456
0.000046    0.027596    0.664695          0.633390             759  ...        1.0       1.0      0.009130       0.003984

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
B_naive Time elapsed: 193.83191056251525 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD14_Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 03:17:50 Max_iter: 1000
At iteration 671, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  672 ; minimum lost =  0.013340131379663944 ; diff loss =  9.424984455108643e-07 ; diff weight =  0.00033748376881703734
lambda is : 9.999999999999997e-06, cost : 10.849 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 03:28:41 Max_iter: 1000
At iteration 613, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  613 ; minimum lost =  0.016902923583984375 ; diff loss =  -2.0489096641540527e-08 ; diff weight =  0.015768760815262794
lambda is : 1.4677992676220687e-05, cost : 10.091 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 03:38:46 Max_iter: 1000
At iteration 600, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  601 ; minimum lost =  0.019553709775209427 ; diff loss =  9.94652509689331e-07 ; diff weight =  0.0004760752199217677
lambda is : 2.1544346900318854e-05, cost : 9.71 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 03:48:29 Max_iter: 1000
At iteration 631, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  632 ; minimum lost =  0.02161487191915512 ; diff loss =  9.201467037200928e-07 ; diff weight =  0.0003601177886594087
lambda is : 3.16227766016838e-05, cost : 10.226 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 03:58:42 Max_iter: 1000
At iteration 519, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  520 ; minimum lost =  0.026020044460892677 ; diff loss =  8.959323167800903e-07 ; diff weight =  0.0001788297522580251
lambda is : 4.6415888336127784e-05, cost : 8.388 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 04:07:06 Max_iter: 1000
At iteration 577, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  578 ; minimum lost =  0.027153782546520233 ; diff loss =  8.922070264816284e-07 ; diff weight =  0.0002761954383458942
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 9.594 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 04:16:41 Max_iter: 1000
At iteration 588, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  589 ; minimum lost =  0.029175229370594025 ; diff loss =  7.953494787216187e-07 ; diff weight =  0.0003013405075762421
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 9.528 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 04:26:13 Max_iter: 1000
At iteration 553, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  554 ; minimum lost =  0.03149142861366272 ; diff loss =  6.966292858123779e-07 ; diff weight =  0.00032573030330240726
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 8.851 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 04:35:04 Max_iter: 1000
At iteration 563, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  564 ; minimum lost =  0.03363340348005295 ; diff loss =  4.246830940246582e-07 ; diff weight =  0.0006873334059491754
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 8.955 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 04:44:01 Max_iter: 1000
At iteration 555, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  556 ; minimum lost =  0.036237865686416626 ; diff loss =  5.662441253662109e-07 ; diff weight =  0.005843996535986662
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 8.708 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 04:52:44 Max_iter: 1000
At iteration 527, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  528 ; minimum lost =  0.039360061287879944 ; diff loss =  9.611248970031738e-07 ; diff weight =  0.006394244730472565
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 8.268 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 05:01:00 Max_iter: 1000
At iteration 587, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  588 ; minimum lost =  0.04207887873053551 ; diff loss =  5.550682544708252e-07 ; diff weight =  0.0004049235431011766
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 9.158 min
==========
Testing lambda: 0.001 starting at 2024-10-03 05:10:09 Max_iter: 1000
At iteration 599, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  600 ; minimum lost =  0.04574963450431824 ; diff loss =  5.513429641723633e-07 ; diff weight =  0.0005433661863207817
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 9.326 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 05:19:29 Max_iter: 1000
At iteration 528, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  529 ; minimum lost =  0.050202637910842896 ; diff loss =  7.562339305877686e-07 ; diff weight =  0.0026184481102973223
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 8.214 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 05:27:42 Max_iter: 1000
At iteration 506, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  506 ; minimum lost =  0.05558473616838455 ; diff loss =  -3.7997961044311523e-07 ; diff weight =  0.007565536070615053
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 7.909 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 05:35:36 Max_iter: 1000
At iteration 609, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  610 ; minimum lost =  0.06204255670309067 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0014894068008288741
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 9.465 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 05:45:04 Max_iter: 1000
At iteration 548, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  549 ; minimum lost =  0.07066448032855988 ; diff loss =  9.760260581970215e-07 ; diff weight =  0.0015065436018630862
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 8.665 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 05:53:44 Max_iter: 1000
At iteration 557, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  558 ; minimum lost =  0.08169086277484894 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0012641737703233957
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 8.668 min
==========
Testing lambda: 0.01 starting at 2024-10-03 06:02:24 Max_iter: 1000
At iteration 536, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  537 ; minimum lost =  0.09595613926649094 ; diff loss =  6.034970283508301e-07 ; diff weight =  0.0005622393800877035
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 8.345 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 06:10:45 Max_iter: 1000
At iteration 416, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  417 ; minimum lost =  0.11436806619167328 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0007239446858875453
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220709, cost : 6.491 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 06:17:14 Max_iter: 1000
At iteration 366, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  367 ; minimum lost =  0.1374717354774475 ; diff loss =  8.344650268554688e-07 ; diff weight =  0.001188351190648973
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.02154434690031885, cost : 5.714 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 06:22:57 Max_iter: 1000
At iteration 362, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  363 ; minimum lost =  0.16601431369781494 ; diff loss =  6.556510925292969e-07 ; diff weight =  0.0005333462613634765
lambda is : 0.0316227766016838, cost : 5.652 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 06:28:36 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  399 ; minimum lost =  0.20218726992607117 ; diff loss =  7.450580596923828e-07 ; diff weight =  0.00014754687435925007
lambda is : 0.04641588833612786, cost : 6.214 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 06:34:49 Max_iter: 1000
At iteration 401, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  402 ; minimum lost =  0.24522912502288818 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0001936402404680848
lambda is : 0.0681292069057962, cost : 6.255 min
==========
Testing lambda: 0.1 starting at 2024-10-03 06:41:05 Max_iter: 1000
At iteration 354, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  355 ; minimum lost =  0.2979537546634674 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0001922848605317995
lambda is : 0.10000000000000002, cost : 5.521 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.185500    0.404252          0.236182            5102  ...        1.0       1.0      0.013340       0.000337
0.000015    0.176847    0.415964          0.242287            4864  ...        1.0       1.0      0.016903       0.015769
0.000022    0.133981    0.495666          0.287768            3685  ...        1.0       1.0      0.019554       0.000476
0.000032    0.126418    0.513235          0.303551            3477  ...        1.0       1.0      0.021615       0.000360
0.000046    0.116019    0.539119          0.325051            3191  ...        1.0       1.0      0.026020       0.000179

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD14_Mono Time elapsed: 208.8321331779162 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD16_Mono
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 06:46:46 Max_iter: 1000
At iteration 512, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  513 ; minimum lost =  0.009112393483519554 ; diff loss =  9.96515154838562e-07 ; diff weight =  0.00039546331390738487
lambda is : 9.999999999999997e-06, cost : 8.514 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 06:55:17 Max_iter: 1000
At iteration 554, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  555 ; minimum lost =  0.00979641079902649 ; diff loss =  9.741634130477905e-07 ; diff weight =  0.0008508962928317487
lambda is : 1.4677992676220687e-05, cost : 9.04 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 07:04:19 Max_iter: 1000
At iteration 494, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  495 ; minimum lost =  0.01231367513537407 ; diff loss =  8.754432201385498e-07 ; diff weight =  0.0002474849170539528
lambda is : 2.1544346900318854e-05, cost : 8.114 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 07:12:26 Max_iter: 1000
At iteration 536, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  537 ; minimum lost =  0.012848824262619019 ; diff loss =  8.475035429000854e-07 ; diff weight =  0.005281565245240927
lambda is : 3.16227766016838e-05, cost : 8.788 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 07:21:13 Max_iter: 1000
At iteration 559, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  560 ; minimum lost =  0.014377906918525696 ; diff loss =  6.388872861862183e-07 ; diff weight =  0.0003051546518690884
lambda is : 4.6415888336127784e-05, cost : 9.006 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 07:30:14 Max_iter: 1000
At iteration 511, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  512 ; minimum lost =  0.016555584967136383 ; diff loss =  8.475035429000854e-07 ; diff weight =  0.0008059059618972242
lambda is : 6.81292069057961e-05, cost : 8.245 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 07:38:29 Max_iter: 1000
At iteration 502, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  503 ; minimum lost =  0.01855982095003128 ; diff loss =  8.121132850646973e-07 ; diff weight =  0.0005882731638848782
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 8.126 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 07:46:36 Max_iter: 1000
At iteration 498, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  499 ; minimum lost =  0.020493747666478157 ; diff loss =  8.67992639541626e-07 ; diff weight =  0.0008845842094160616
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 7.967 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 07:54:34 Max_iter: 1000
At iteration 566, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  567 ; minimum lost =  0.02216002158820629 ; diff loss =  7.525086402893066e-07 ; diff weight =  0.00024206026864703745
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 8.922 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 08:03:29 Max_iter: 1000
At iteration 523, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  524 ; minimum lost =  0.024446552619338036 ; diff loss =  7.431954145431519e-07 ; diff weight =  0.0005776379257440567
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 8.218 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 08:11:42 Max_iter: 1000
At iteration 534, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  535 ; minimum lost =  0.02694065123796463 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.00238299579359591
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 8.331 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 08:20:02 Max_iter: 1000
At iteration 537, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  538 ; minimum lost =  0.029976222664117813 ; diff loss =  5.010515451431274e-07 ; diff weight =  0.0025054907891899347
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 8.37 min
==========
Testing lambda: 0.001 starting at 2024-10-03 08:28:24 Max_iter: 1000
At iteration 531, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  532 ; minimum lost =  0.03378470987081528 ; diff loss =  8.307397365570068e-07 ; diff weight =  0.002133357571437955
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 8.272 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 08:36:41 Max_iter: 1000
At iteration 516, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  517 ; minimum lost =  0.03839685022830963 ; diff loss =  8.642673492431641e-07 ; diff weight =  0.0020122674759477377
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 8.025 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 08:44:42 Max_iter: 1000
At iteration 479, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  480 ; minimum lost =  0.044049039483070374 ; diff loss =  8.344650268554688e-07 ; diff weight =  0.0018587568774819374
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 7.45 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 08:52:09 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  453 ; minimum lost =  0.050715554505586624 ; diff loss =  -4.6566128730773926e-07 ; diff weight =  0.009394416585564613
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 7.062 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 08:59:13 Max_iter: 1000
At iteration 454, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  455 ; minimum lost =  0.05836839601397514 ; diff loss =  4.880130290985107e-07 ; diff weight =  0.0019407327054068446
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 7.186 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 09:06:24 Max_iter: 1000
At iteration 481, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  482 ; minimum lost =  0.0685209184885025 ; diff loss =  5.438923835754395e-07 ; diff weight =  0.0013549035647884011
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 7.488 min
==========
Testing lambda: 0.01 starting at 2024-10-03 09:13:53 Max_iter: 1000
At iteration 405, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  406 ; minimum lost =  0.0817243680357933 ; diff loss =  3.650784492492676e-07 ; diff weight =  0.0008158794371411204
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 6.317 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 09:20:12 Max_iter: 1000
At iteration 393, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  394 ; minimum lost =  0.09884515404701233 ; diff loss =  3.3527612686157227e-07 ; diff weight =  0.0004542884125839919
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220709, cost : 6.128 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 09:26:20 Max_iter: 1000
At iteration 429, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  430 ; minimum lost =  0.12015955150127411 ; diff loss =  4.470348358154297e-07 ; diff weight =  0.0005915594520047307
lambda is : 0.02154434690031885, cost : 6.683 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 09:33:01 Max_iter: 1000
At iteration 372, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  373 ; minimum lost =  0.14643847942352295 ; diff loss =  2.384185791015625e-07 ; diff weight =  0.0001899941562442109
lambda is : 0.0316227766016838, cost : 5.8 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 09:38:49 Max_iter: 1000
At iteration 370, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  371 ; minimum lost =  0.17788751423358917 ; diff loss =  2.2351741790771484e-07 ; diff weight =  0.0002278934553032741
lambda is : 0.04641588833612786, cost : 5.766 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 09:44:35 Max_iter: 1000
At iteration 363, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  364 ; minimum lost =  0.21203190088272095 ; diff loss =  2.980232238769531e-07 ; diff weight =  0.0002113364462275058
lambda is : 0.0681292069057962, cost : 5.659 min
==========
Testing lambda: 0.1 starting at 2024-10-03 09:50:15 Max_iter: 1000
At iteration 208, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  209 ; minimum lost =  0.24002383649349213 ; diff loss =  8.493661880493164e-07 ; diff weight =  0.00029279940645210445
lambda is : 0.10000000000000002, cost : 3.266 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.170521    0.474194          0.264632            4690  ...        1.0       1.0      0.009112       0.000395
0.000015    0.134271    0.555556          0.306935            3693  ...        1.0       1.0      0.009796       0.000851
0.000022    0.136053    0.551075          0.306807            3742  ...        1.0       1.0      0.012314       0.000247
0.000032    0.080316    0.679928          0.383298            2209  ...        1.0       1.0      0.012849       0.005282
0.000046    0.072680    0.739785          0.429127            1999  ...        1.0       1.0      0.014378       0.000305

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD16_Mono Time elapsed: 186.8158272067706 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD4_CTL
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 09:53:41 Max_iter: 1000
At iteration 519, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  520 ; minimum lost =  0.0054763928055763245 ; diff loss =  9.806826710700989e-07 ; diff weight =  0.0011965985177084804
lambda is : 9.999999999999997e-06, cost : 8.322 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 10:02:00 Max_iter: 1000
At iteration 515, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  516 ; minimum lost =  0.00649200240150094 ; diff loss =  9.229406714439392e-07 ; diff weight =  0.0007345942431129515
lambda is : 1.4677992676220687e-05, cost : 8.257 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 10:10:16 Max_iter: 1000
At iteration 545, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  546 ; minimum lost =  0.00768432579934597 ; diff loss =  4.842877388000488e-07 ; diff weight =  0.00213099317625165
lambda is : 2.1544346900318854e-05, cost : 8.656 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 10:18:55 Max_iter: 1000
At iteration 505, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  506 ; minimum lost =  0.009606827981770039 ; diff loss =  8.23289155960083e-07 ; diff weight =  0.0010585569543763995
lambda is : 3.16227766016838e-05, cost : 8.064 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 10:26:59 Max_iter: 1000
At iteration 443, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  444 ; minimum lost =  0.01198892667889595 ; diff loss =  9.937211871147156e-07 ; diff weight =  0.0008458984084427357
lambda is : 4.6415888336127784e-05, cost : 7.071 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 10:34:03 Max_iter: 1000
At iteration 511, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  511 ; minimum lost =  0.01366929430514574 ; diff loss =  -4.1816383600234985e-07 ; diff weight =  0.004827182739973068
lambda is : 6.81292069057961e-05, cost : 8.076 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 10:42:08 Max_iter: 1000
At iteration 486, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  487 ; minimum lost =  0.01649177074432373 ; diff loss =  7.990747690200806e-07 ; diff weight =  0.000985694001428783
lambda is : 9.999999999999991e-05, cost : 7.678 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 10:49:48 Max_iter: 1000
At iteration 476, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  477 ; minimum lost =  0.019509438425302505 ; diff loss =  5.289912223815918e-07 ; diff weight =  0.0014134891098365188
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 7.707 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 10:57:31 Max_iter: 1000
At iteration 552, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  553 ; minimum lost =  0.022730205208063126 ; diff loss =  6.314367055892944e-07 ; diff weight =  0.0026771551929414272
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 8.659 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 11:06:10 Max_iter: 1000
At iteration 528, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  528 ; minimum lost =  0.026611559092998505 ; diff loss =  -2.2351741790771484e-07 ; diff weight =  0.010251488536596298
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 8.28 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 11:14:27 Max_iter: 1000
At iteration 484, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  485 ; minimum lost =  0.030955813825130463 ; diff loss =  4.805624485015869e-07 ; diff weight =  0.0004018307663500309
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 7.577 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 11:22:02 Max_iter: 1000
At iteration 528, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  529 ; minimum lost =  0.03603319078683853 ; diff loss =  6.51925802230835e-07 ; diff weight =  0.0017963781720027328
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 8.239 min
==========
Testing lambda: 0.001 starting at 2024-10-03 11:30:16 Max_iter: 1000
At iteration 495, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  496 ; minimum lost =  0.04226457700133324 ; diff loss =  5.327165126800537e-07 ; diff weight =  0.0005806576227769256
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 7.725 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 11:38:00 Max_iter: 1000
At iteration 466, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  467 ; minimum lost =  0.04941532015800476 ; diff loss =  9.08970832824707e-07 ; diff weight =  0.0016266610473394394
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.271 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 11:45:16 Max_iter: 1000
At iteration 451, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  452 ; minimum lost =  0.05755867436528206 ; diff loss =  9.648501873016357e-07 ; diff weight =  0.0016010490944609046
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 7.033 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 11:52:18 Max_iter: 1000
At iteration 448, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  449 ; minimum lost =  0.06636177003383636 ; diff loss =  9.08970832824707e-07 ; diff weight =  0.0013929905835539103
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 6.975 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 11:59:16 Max_iter: 1000
At iteration 405, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  406 ; minimum lost =  0.07477526366710663 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0013519602362066507
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 6.314 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 12:05:35 Max_iter: 1000
At iteration 350, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  350 ; minimum lost =  0.08347849547863007 ; diff loss =  -1.4901161193847656e-07 ; diff weight =  0.003089625621214509
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 5.529 min
==========
Testing lambda: 0.01 starting at 2024-10-03 12:11:07 Max_iter: 1000
At iteration 393, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  394 ; minimum lost =  0.09235692024230957 ; diff loss =  8.642673492431641e-07 ; diff weight =  0.0012974905548617244
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 6.291 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 12:17:24 Max_iter: 1000
At iteration 320, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  321 ; minimum lost =  0.10124874114990234 ; diff loss =  3.0547380447387695e-07 ; diff weight =  0.0006912949029356241
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220709, cost : 5.006 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 12:22:25 Max_iter: 1000
At iteration 238, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  239 ; minimum lost =  0.11066418141126633 ; diff loss =  6.854534149169922e-07 ; diff weight =  0.0008560619316995144
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.02154434690031885, cost : 3.744 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 12:26:09 Max_iter: 1000
At iteration 246, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  247 ; minimum lost =  0.1191692054271698 ; diff loss =  2.8312206268310547e-07 ; diff weight =  0.00034530999255366623
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0316227766016838, cost : 3.858 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 12:30:01 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  221 ; minimum lost =  0.12867148220539093 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.00016695100930519402
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.04641588833612786, cost : 3.46 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 12:33:28 Max_iter: 1000
At iteration 199, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  200 ; minimum lost =  0.1416415274143219 ; diff loss =  1.043081283569336e-07 ; diff weight =  0.00012922286987304688
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0681292069057962, cost : 3.133 min
==========
Testing lambda: 0.1 starting at 2024-10-03 12:36:36 Max_iter: 1000
At iteration 176, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  177 ; minimum lost =  0.159959077835083 ; diff loss =  1.4901161193847656e-08 ; diff weight =  3.248453140258789e-05
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.10000000000000002, cost : 2.777 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.079625    0.403810          0.446321            2190  ...        1.0       1.0      0.005476       0.001197
0.000015    0.070135    0.440000          0.477393            1929  ...        1.0       1.0      0.006492       0.000735
0.000022    0.050356    0.528571          0.550890            1385  ...        1.0       1.0      0.007684       0.002131
0.000032    0.046466    0.556667          0.573851            1278  ...        1.0       1.0      0.009607       0.001059
0.000046    0.036649    0.605714          0.605517            1008  ...        1.0       1.0      0.011989       0.000846

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_CTL Time elapsed: 165.78350070317586 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD4_Naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 12:39:33 Max_iter: 1000
At iteration 684, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  685 ; minimum lost =  0.020872587338089943 ; diff loss =  8.922070264816284e-07 ; diff weight =  0.000805047107860446
lambda is : 9.999999999999997e-06, cost : 10.965 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 12:50:31 Max_iter: 1000
At iteration 598, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  599 ; minimum lost =  0.02648356184363365 ; diff loss =  1.2479722499847412e-07 ; diff weight =  0.012493262067437172
lambda is : 1.4677992676220687e-05, cost : 9.601 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 13:00:07 Max_iter: 1000
At iteration 557, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  558 ; minimum lost =  0.03199160844087601 ; diff loss =  7.972121238708496e-07 ; diff weight =  0.00034006862551905215
lambda is : 2.1544346900318854e-05, cost : 8.95 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 13:09:04 Max_iter: 1000
At iteration 561, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  562 ; minimum lost =  0.03641869127750397 ; diff loss =  8.828938007354736e-07 ; diff weight =  0.0004156911454629153
lambda is : 3.16227766016838e-05, cost : 9.018 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 13:18:05 Max_iter: 1000
At iteration 569, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  570 ; minimum lost =  0.040660399943590164 ; diff loss =  8.977949619293213e-07 ; diff weight =  0.0003342234995216131
lambda is : 4.6415888336127784e-05, cost : 9.135 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 13:27:14 Max_iter: 1000
At iteration 560, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  561 ; minimum lost =  0.04597224295139313 ; diff loss =  7.189810276031494e-07 ; diff weight =  0.0003837346739601344
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 9.045 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 13:36:16 Max_iter: 1000
At iteration 572, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  573 ; minimum lost =  0.052282966673374176 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0004653223732020706
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 9.168 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 13:45:26 Max_iter: 1000
At iteration 495, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  496 ; minimum lost =  0.06045494228601456 ; diff loss =  8.568167686462402e-07 ; diff weight =  0.0002022454427788034
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 7.957 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 13:53:24 Max_iter: 1000
At iteration 548, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  549 ; minimum lost =  0.06730057299137115 ; diff loss =  5.513429641723633e-07 ; diff weight =  0.0008594738901592791
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 8.687 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 14:02:05 Max_iter: 1000
At iteration 491, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.07703327387571335 ; diff loss =  8.344650268554688e-07 ; diff weight =  0.0001772968244040385
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 7.996 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 14:10:05 Max_iter: 1000
At iteration 553, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  554 ; minimum lost =  0.08581109344959259 ; diff loss =  9.462237358093262e-07 ; diff weight =  0.00022290008200798184
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 8.758 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 14:18:50 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  443 ; minimum lost =  0.09612511098384857 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.00025128322886303067
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 7.034 min
==========
Testing lambda: 0.001 starting at 2024-10-03 14:25:52 Max_iter: 1000
At iteration 529, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  530 ; minimum lost =  0.10599935799837112 ; diff loss =  5.364418029785156e-07 ; diff weight =  8.225641795434058e-05
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 8.358 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 14:34:14 Max_iter: 1000
At iteration 483, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  484 ; minimum lost =  0.11880786716938019 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0004121066886000335
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.588 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 14:41:49 Max_iter: 1000
At iteration 492, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.13228344917297363 ; diff loss =  -9.834766387939453e-07 ; diff weight =  0.00555452099069953
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 7.71 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 14:49:32 Max_iter: 1000
At iteration 484, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  485 ; minimum lost =  0.14752724766731262 ; diff loss =  8.195638656616211e-07 ; diff weight =  0.00033908404293470085
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 7.563 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 14:57:05 Max_iter: 1000
At iteration 529, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  530 ; minimum lost =  0.1647968888282776 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0014743084320798516
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 8.255 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 15:05:21 Max_iter: 1000
At iteration 376, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  377 ; minimum lost =  0.18552649021148682 ; diff loss =  6.556510925292969e-07 ; diff weight =  0.0026883261743932962
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 5.883 min
==========
Testing lambda: 0.01 starting at 2024-10-03 15:11:14 Max_iter: 1000
At iteration 449, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  449 ; minimum lost =  0.20621085166931152 ; diff loss =  -8.344650268554688e-07 ; diff weight =  0.009109538048505783
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 7.037 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 15:18:16 Max_iter: 1000
At iteration 516, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  516 ; minimum lost =  0.22867411375045776 ; diff loss =  -1.9371509552001953e-07 ; diff weight =  0.0013424813514575362
lambda is : 0.014677992676220709, cost : 8.05 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 15:26:19 Max_iter: 1000
At iteration 501, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  502 ; minimum lost =  0.2534431517124176 ; diff loss =  4.172325134277344e-07 ; diff weight =  0.00033471756614744663
lambda is : 0.02154434690031885, cost : 7.784 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 15:34:06 Max_iter: 1000
At iteration 333, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  334 ; minimum lost =  0.27894076704978943 ; diff loss =  8.046627044677734e-07 ; diff weight =  0.0004336596466600895
lambda is : 0.0316227766016838, cost : 5.397 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 15:39:30 Max_iter: 1000
At iteration 456, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  457 ; minimum lost =  0.3026543855667114 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0005840329686179757
lambda is : 0.04641588833612786, cost : 7.095 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 15:46:36 Max_iter: 1000
At iteration 404, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  405 ; minimum lost =  0.32407891750335693 ; diff loss =  5.066394805908203e-07 ; diff weight =  0.00030549734947271645
lambda is : 0.0681292069057962, cost : 6.293 min
==========
Testing lambda: 0.1 starting at 2024-10-03 15:52:53 Max_iter: 1000
At iteration 278, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  278 ; minimum lost =  0.3461742401123047 ; diff loss =  0.0 ; diff weight =  5.161304216017015e-05
lambda is : 0.10000000000000002, cost : 4.35 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.124891    0.264948          0.347231            3435  ...        1.0       1.0      0.020873       0.000805
0.000015    0.112638    0.282958          0.367963            3098  ...        1.0       1.0      0.026484       0.012493
0.000022    0.100713    0.308740          0.397715            2770  ...        1.0       1.0      0.031992       0.000340
0.000032    0.080097    0.356555          0.448661            2203  ...        1.0       1.0      0.036419       0.000416
0.000046    0.060609    0.409033          0.502863            1667  ...        1.0       1.0      0.040660       0.000334

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_Naive Time elapsed: 197.74935660759607 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD4_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 15:57:24 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.01863420009613037 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.00653504254296422
lambda is : 9.999999999999997e-06, cost : 0.542 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 15:57:57 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.01877627708017826 ; diff loss =  9.94652509689331e-07 ; diff weight =  0.00736172404140234
lambda is : 1.4677992676220687e-05, cost : 0.549 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 15:58:30 Max_iter: 1000
At iteration 378, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  379 ; minimum lost =  0.001412097131833434 ; diff loss =  5.206093192100525e-07 ; diff weight =  0.002317037433385849
lambda is : 2.1544346900318854e-05, cost : 5.982 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 16:04:29 Max_iter: 1000
At iteration 379, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  380 ; minimum lost =  0.0016919062472879887 ; diff loss =  9.515788406133652e-07 ; diff weight =  0.012494351714849472
lambda is : 3.16227766016838e-05, cost : 5.961 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 16:10:26 Max_iter: 1000
At iteration 357, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  358 ; minimum lost =  0.0020493038464337587 ; diff loss =  8.333008736371994e-07 ; diff weight =  0.011293004266917706
lambda is : 4.6415888336127784e-05, cost : 5.627 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 16:16:04 Max_iter: 1000
At iteration 330, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  331 ; minimum lost =  0.0024452246725559235 ; diff loss =  9.75094735622406e-07 ; diff weight =  0.0073572788387537
lambda is : 6.81292069057961e-05, cost : 5.182 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 16:21:15 Max_iter: 1000
At iteration 332, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  333 ; minimum lost =  0.002886804984882474 ; diff loss =  8.856877684593201e-07 ; diff weight =  0.0060211047530174255
lambda is : 9.999999999999991e-05, cost : 5.213 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 16:26:28 Max_iter: 1000
At iteration 311, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  312 ; minimum lost =  0.0034291394986212254 ; diff loss =  9.05478373169899e-07 ; diff weight =  0.008766703307628632
lambda is : 0.00014677992676220703, cost : 4.889 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 16:31:21 Max_iter: 1000
At iteration 281, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  282 ; minimum lost =  0.004080047365278006 ; diff loss =  9.289942681789398e-07 ; diff weight =  0.005201522260904312
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 4.425 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 16:35:46 Max_iter: 1000
At iteration 273, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  274 ; minimum lost =  0.004772284999489784 ; diff loss =  7.739290595054626e-07 ; diff weight =  0.004355417564511299
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 4.291 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 16:40:04 Max_iter: 1000
At iteration 233, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  234 ; minimum lost =  0.005735163576900959 ; diff loss =  9.424984455108643e-07 ; diff weight =  0.0038115568459033966
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 3.67 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 16:43:44 Max_iter: 1000
At iteration 239, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  240 ; minimum lost =  0.006826712749898434 ; diff loss =  9.066425263881683e-07 ; diff weight =  0.005068729165941477
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 3.756 min
==========
Testing lambda: 0.001 starting at 2024-10-03 16:47:29 Max_iter: 1000
At iteration 212, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  213 ; minimum lost =  0.008212371729314327 ; diff loss =  4.1443854570388794e-07 ; diff weight =  0.001966989366337657
lambda is : 0.0010000000000000002, cost : 3.337 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 16:50:50 Max_iter: 1000
At iteration 179, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  180 ; minimum lost =  0.00993411522358656 ; diff loss =  9.806826710700989e-07 ; diff weight =  0.00440562330186367
lambda is : 0.0014677992676220694, cost : 2.822 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 16:53:39 Max_iter: 1000
At iteration 169, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  170 ; minimum lost =  0.012005479075014591 ; diff loss =  9.937211871147156e-07 ; diff weight =  0.0024804414715617895
lambda is : 0.0021544346900318843, cost : 2.666 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 16:56:19 Max_iter: 1000
At iteration 140, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  141 ; minimum lost =  0.014001048170030117 ; diff loss =  9.601935744285583e-07 ; diff weight =  0.002811161335557699
lambda is : 0.003162277660168382, cost : 2.221 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 16:58:32 Max_iter: 1000
At iteration 75, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  76 ; minimum lost =  0.015936993062496185 ; diff loss =  2.682209014892578e-07 ; diff weight =  0.0008384383982047439
lambda is : 0.004641588833612781, cost : 1.215 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 16:59:45 Max_iter: 1000
At iteration 94, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  95 ; minimum lost =  0.01813741773366928 ; diff loss =  6.780028343200684e-07 ; diff weight =  0.001078228116966784
lambda is : 0.006812920690579613, cost : 1.509 min
==========
Testing lambda: 0.01 starting at 2024-10-03 17:01:16 Max_iter: 1000
At iteration 97, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  98 ; minimum lost =  0.021425187587738037 ; diff loss =  1.1175870895385742e-08 ; diff weight =  8.90493392944336e-05
lambda is : 0.010000000000000004, cost : 1.553 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 17:02:49 Max_iter: 1000
At iteration 107, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  108 ; minimum lost =  0.026076452806591988 ; diff loss =  1.1362135410308838e-07 ; diff weight =  0.0003629922866821289
lambda is : 0.014677992676220709, cost : 1.71 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 17:04:32 Max_iter: 1000
At iteration 98, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  99 ; minimum lost =  0.03270409256219864 ; diff loss =  6.258487701416016e-07 ; diff weight =  0.0012071896344423294
lambda is : 0.02154434690031885, cost : 1.57 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 17:06:06 Max_iter: 1000
At iteration 117, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  118 ; minimum lost =  0.041604433208703995 ; diff loss =  2.4959444999694824e-07 ; diff weight =  0.0003496408462524414
lambda is : 0.0316227766016838, cost : 1.86 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 17:07:57 Max_iter: 1000
At iteration 129, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  130 ; minimum lost =  0.05401106923818588 ; diff loss =  7.152557373046875e-07 ; diff weight =  0.0006066560745239258
lambda is : 0.04641588833612786, cost : 2.05 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 17:10:00 Max_iter: 1000
At iteration 128, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  128 ; minimum lost =  0.07093670964241028 ; diff loss =  -3.5762786865234375e-07 ; diff weight =  0.01205737330019474
lambda is : 0.0681292069057962, cost : 2.033 min
==========
Testing lambda: 0.1 starting at 2024-10-03 17:12:02 Max_iter: 1000
At iteration 137, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  138 ; minimum lost =  0.09373929351568222 ; diff loss =  2.9802322387695312e-08 ; diff weight =  8.52346420288086e-05
lambda is : 0.10000000000000002, cost : 2.168 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.402850    0.326923          0.124523           11080  ...        1.0       1.0      0.018634       0.006535
0.000015    0.388998    0.336538          0.131003           10699  ...        1.0       1.0      0.018776       0.007362
0.000022    0.026869    0.951923          0.578356             739  ...        1.0       1.0      0.001412       0.002317
0.000032    0.014543    0.961538          0.621083             400  ...        1.0       1.0      0.001692       0.012494
0.000046    0.013489    0.971154          0.691488             371  ...        1.0       1.0      0.002049       0.011293

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_Proliferating Time elapsed: 76.88518770933152 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD4_TCM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 17:14:23 Max_iter: 1000
At iteration 559, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  560 ; minimum lost =  0.04566843807697296 ; diff loss =  8.344650268554688e-07 ; diff weight =  0.0002657453587744385
lambda is : 9.999999999999997e-06, cost : 9.293 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 17:23:41 Max_iter: 1000
At iteration 595, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  596 ; minimum lost =  0.04874517768621445 ; diff loss =  9.723007678985596e-07 ; diff weight =  0.0002921901468653232
lambda is : 1.4677992676220687e-05, cost : 10.074 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 17:33:45 Max_iter: 1000
At iteration 549, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  550 ; minimum lost =  0.055518150329589844 ; diff loss =  7.972121238708496e-07 ; diff weight =  7.544791151303798e-05
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 2.1544346900318854e-05, cost : 9.186 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 17:42:56 Max_iter: 1000
At iteration 589, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  590 ; minimum lost =  0.05967382714152336 ; diff loss =  9.872019290924072e-07 ; diff weight =  0.00012118229642510414
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 9.777 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 17:52:43 Max_iter: 1000
At iteration 521, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  522 ; minimum lost =  0.06658303737640381 ; diff loss =  9.313225746154785e-07 ; diff weight =  0.00014974368968978524
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 8.623 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 18:01:20 Max_iter: 1000
At iteration 572, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  573 ; minimum lost =  0.0706639438867569 ; diff loss =  8.195638656616211e-07 ; diff weight =  0.0002528378972783685
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 9.302 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 18:10:38 Max_iter: 1000
At iteration 522, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  523 ; minimum lost =  0.07623729109764099 ; diff loss =  7.897615432739258e-07 ; diff weight =  0.00017874572949949652
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 8.46 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 18:19:06 Max_iter: 1000
At iteration 518, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  519 ; minimum lost =  0.08165846765041351 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.00017876102356240153
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 8.413 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 18:27:31 Max_iter: 1000
At iteration 474, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  475 ; minimum lost =  0.0880274847149849 ; diff loss =  8.866190910339355e-07 ; diff weight =  0.00015965598868206143
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 7.657 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 18:35:10 Max_iter: 1000
At iteration 505, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  506 ; minimum lost =  0.09314560890197754 ; diff loss =  7.152557373046875e-07 ; diff weight =  0.0004968402208760381
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 8.063 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 18:43:14 Max_iter: 1000
At iteration 495, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  496 ; minimum lost =  0.09994432330131531 ; diff loss =  8.195638656616211e-07 ; diff weight =  0.00031953310826793313
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 7.866 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 18:51:06 Max_iter: 1000
At iteration 492, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  493 ; minimum lost =  0.10683546960353851 ; diff loss =  5.438923835754395e-07 ; diff weight =  0.00029822843498550355
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 7.777 min
==========
Testing lambda: 0.001 starting at 2024-10-03 18:58:53 Max_iter: 1000
At iteration 564, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  565 ; minimum lost =  0.11485187709331512 ; diff loss =  6.407499313354492e-07 ; diff weight =  0.0013180992100387812
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 8.83 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 19:07:42 Max_iter: 1000
At iteration 497, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  498 ; minimum lost =  0.12482306361198425 ; diff loss =  5.364418029785156e-07 ; diff weight =  0.00021000408742111176
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.771 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 19:15:29 Max_iter: 1000
At iteration 501, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  502 ; minimum lost =  0.1361583173274994 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0017147051403298974
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 7.809 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 19:23:17 Max_iter: 1000
At iteration 581, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  582 ; minimum lost =  0.14981025457382202 ; diff loss =  5.960464477539063e-08 ; diff weight =  0.0014510996406897902
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 9.036 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 19:32:19 Max_iter: 1000
At iteration 454, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  455 ; minimum lost =  0.16665595769882202 ; diff loss =  8.642673492431641e-07 ; diff weight =  0.00021547693177126348
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 7.089 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 19:39:25 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  453 ; minimum lost =  0.18599329888820648 ; diff loss =  -4.6193599700927734e-07 ; diff weight =  0.004637985955923796
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 7.105 min
==========
Testing lambda: 0.01 starting at 2024-10-03 19:46:31 Max_iter: 1000
At iteration 487, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  488 ; minimum lost =  0.2076655924320221 ; diff loss =  7.897615432739258e-07 ; diff weight =  0.00010146263230126351
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 7.566 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 19:54:05 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  442 ; minimum lost =  0.2302875518798828 ; diff loss =  -9.238719940185547e-07 ; diff weight =  0.006844384595751762
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.014677992676220709, cost : 6.884 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 20:00:58 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  454 ; minimum lost =  0.25190770626068115 ; diff loss =  5.364418029785156e-07 ; diff weight =  0.00038165133446455
lambda is : 0.02154434690031885, cost : 7.034 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 20:08:00 Max_iter: 1000
At iteration 387, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  388 ; minimum lost =  0.2741178870201111 ; diff loss =  4.172325134277344e-07 ; diff weight =  0.0020991265773773193
lambda is : 0.0316227766016838, cost : 6.015 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 20:14:01 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  332 ; minimum lost =  0.29533305764198303 ; diff loss =  3.2782554626464844e-07 ; diff weight =  0.00033708749106153846
lambda is : 0.04641588833612786, cost : 5.155 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 20:19:10 Max_iter: 1000
At iteration 222, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  223 ; minimum lost =  0.31674209237098694 ; diff loss =  2.682209014892578e-07 ; diff weight =  0.00016070481797214597
lambda is : 0.0681292069057962, cost : 3.474 min
==========
Testing lambda: 0.1 starting at 2024-10-03 20:22:39 Max_iter: 1000
At iteration 216, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  217 ; minimum lost =  0.33569979667663574 ; diff loss =  5.960464477539062e-07 ; diff weight =  0.00024863213184289634
lambda is : 0.10000000000000002, cost : 3.381 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.189609    0.226613          0.262087            5215  ...   1.000000  1.000000      0.045668       0.000266
0.000015    0.156777    0.265423          0.297384            4312  ...   1.000000  1.000000      0.048745       0.000292
0.000022    0.147978    0.277520          0.311759            4070  ...   1.000000  1.000000      0.055518       0.000075
0.000032    0.121255    0.321371          0.352088            3335  ...   0.996370  0.996270      0.059674       0.000121
0.000046    0.091587    0.386895          0.407497            2519  ...   0.969685  0.971733      0.066583       0.000150

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_TCM Time elapsed: 191.70403038263322 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD4_TEM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 20:26:11 Max_iter: 1000
At iteration 581, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  581 ; minimum lost =  0.02787569724023342 ; diff loss =  -8.381903171539307e-07 ; diff weight =  0.012413452379405499
lambda is : 9.999999999999997e-06, cost : 9.569 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 20:35:45 Max_iter: 1000
At iteration 524, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  525 ; minimum lost =  0.03336884826421738 ; diff loss =  9.350478649139404e-07 ; diff weight =  0.00017590282368473709
lambda is : 1.4677992676220687e-05, cost : 8.709 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 20:44:28 Max_iter: 1000
At iteration 525, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  526 ; minimum lost =  0.03758714348077774 ; diff loss =  8.642673492431641e-07 ; diff weight =  0.0002352893934585154
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 2.1544346900318854e-05, cost : 8.767 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 20:53:14 Max_iter: 1000
At iteration 460, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  461 ; minimum lost =  0.04329782724380493 ; diff loss =  9.201467037200928e-07 ; diff weight =  0.00042618883890099823
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 7.674 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 21:00:54 Max_iter: 1000
At iteration 528, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  529 ; minimum lost =  0.04715919494628906 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.00013668877363670617
lambda is : 4.6415888336127784e-05, cost : 8.641 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-03 21:09:33 Max_iter: 1000
At iteration 394, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  395 ; minimum lost =  0.05394719913601875 ; diff loss =  8.195638656616211e-08 ; diff weight =  0.009970290586352348
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 6.557 min
==========
Testing lambda: 0.0001 starting at 2024-10-03 21:16:06 Max_iter: 1000
At iteration 453, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  454 ; minimum lost =  0.05647122114896774 ; diff loss =  8.568167686462402e-07 ; diff weight =  0.00014081867993809283
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 7.39 min
==========
Testing lambda: 0.000147 starting at 2024-10-03 21:23:29 Max_iter: 1000
At iteration 465, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  466 ; minimum lost =  0.06050076335668564 ; diff loss =  5.438923835754395e-07 ; diff weight =  0.004420629236847162
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 7.463 min
==========
Testing lambda: 0.000215 starting at 2024-10-03 21:30:57 Max_iter: 1000
At iteration 419, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  420 ; minimum lost =  0.06559222936630249 ; diff loss =  9.313225746154785e-07 ; diff weight =  0.0001592572807567194
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 6.726 min
==========
Testing lambda: 0.000316 starting at 2024-10-03 21:37:41 Max_iter: 1000
At iteration 494, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  495 ; minimum lost =  0.0693434402346611 ; diff loss =  3.2782554626464844e-07 ; diff weight =  0.00016977587074507028
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 7.829 min
==========
Testing lambda: 0.000464 starting at 2024-10-03 21:45:30 Max_iter: 1000
At iteration 469, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  470 ; minimum lost =  0.07431928813457489 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0007112916791811585
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 7.412 min
==========
Testing lambda: 0.000681 starting at 2024-10-03 21:52:55 Max_iter: 1000
At iteration 503, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  504 ; minimum lost =  0.07963406294584274 ; diff loss =  2.3096799850463867e-07 ; diff weight =  0.002475617453455925
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 7.881 min
==========
Testing lambda: 0.001 starting at 2024-10-03 22:00:48 Max_iter: 1000
At iteration 496, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  497 ; minimum lost =  0.08571723848581314 ; diff loss =  9.08970832824707e-07 ; diff weight =  0.0017212574603036046
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 7.813 min
==========
Testing lambda: 0.001468 starting at 2024-10-03 22:08:37 Max_iter: 1000
At iteration 469, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  469 ; minimum lost =  0.0925891324877739 ; diff loss =  -2.4586915969848633e-07 ; diff weight =  0.0032045654952526093
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.345 min
==========
Testing lambda: 0.002154 starting at 2024-10-03 22:15:58 Max_iter: 1000
At iteration 416, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  417 ; minimum lost =  0.10010398924350739 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0007163661066442728
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 6.503 min
==========
Testing lambda: 0.003162 starting at 2024-10-03 22:22:28 Max_iter: 1000
At iteration 465, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  466 ; minimum lost =  0.1081683486700058 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.0010039935586974025
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 7.25 min
==========
Testing lambda: 0.004642 starting at 2024-10-03 22:29:43 Max_iter: 1000
At iteration 446, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  447 ; minimum lost =  0.11767028272151947 ; diff loss =  6.556510925292969e-07 ; diff weight =  0.0007296536932699382
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 6.933 min
==========
Testing lambda: 0.006813 starting at 2024-10-03 22:36:39 Max_iter: 1000
At iteration 452, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  453 ; minimum lost =  0.1281137466430664 ; diff loss =  8.940696716308594e-08 ; diff weight =  2.9784609068883583e-05
lambda is : 0.006812920690579613, cost : 7.023 min
==========
Testing lambda: 0.01 starting at 2024-10-03 22:43:40 Max_iter: 1000
At iteration 395, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  396 ; minimum lost =  0.13850274682044983 ; diff loss =  8.046627044677734e-07 ; diff weight =  0.0007095750188454986
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 6.144 min
==========
Testing lambda: 0.014678 starting at 2024-10-03 22:49:49 Max_iter: 1000
At iteration 387, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  388 ; minimum lost =  0.14906027913093567 ; diff loss =  3.427267074584961e-07 ; diff weight =  0.0006423835293389857
lambda is : 0.014677992676220709, cost : 6.025 min
==========
Testing lambda: 0.021544 starting at 2024-10-03 22:55:50 Max_iter: 1000
At iteration 341, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  342 ; minimum lost =  0.16074484586715698 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.0007374216802418232
lambda is : 0.02154434690031885, cost : 5.306 min
==========
Testing lambda: 0.031623 starting at 2024-10-03 23:01:09 Max_iter: 1000
At iteration 331, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  332 ; minimum lost =  0.17352017760276794 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0008755043381825089
lambda is : 0.0316227766016838, cost : 5.16 min
==========
Testing lambda: 0.046416 starting at 2024-10-03 23:06:18 Max_iter: 1000
At iteration 285, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  286 ; minimum lost =  0.18654200434684753 ; diff loss =  8.046627044677734e-07 ; diff weight =  0.00046870371443219483
lambda is : 0.04641588833612786, cost : 4.448 min
==========
Testing lambda: 0.068129 starting at 2024-10-03 23:10:45 Max_iter: 1000
At iteration 220, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  221 ; minimum lost =  0.19845810532569885 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.00031554698944091797
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0681292069057962, cost : 3.445 min
==========
Testing lambda: 0.1 starting at 2024-10-03 23:14:12 Max_iter: 1000
At iteration 210, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  211 ; minimum lost =  0.21432065963745117 ; diff loss =  1.6391277313232422e-07 ; diff weight =  0.00012943148612976074
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.10000000000000002, cost : 3.292 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.168994    0.232746          0.281878            4648  ...   1.000000  1.000000      0.027876       0.012413
0.000015    0.143361    0.268920          0.314957            3943  ...   1.000000  1.000000      0.033369       0.000176
0.000022    0.133617    0.282247          0.328708            3675  ...   1.000000  1.000000      0.037587       0.000235
0.000032    0.092132    0.367920          0.408714            2534  ...   0.999524  0.999524      0.043298       0.000426
0.000046    0.077734    0.409329          0.449092            2138  ...   1.000000  1.000000      0.047159       0.000137

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD4_TEM Time elapsed: 171.37106447617214 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD8_Naive
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-03 23:17:39 Max_iter: 1000
At iteration 655, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  656 ; minimum lost =  0.010889774188399315 ; diff loss =  6.537884473800659e-07 ; diff weight =  0.0008441093377768993
lambda is : 9.999999999999997e-06, cost : 10.492 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-03 23:28:08 Max_iter: 1000
At iteration 631, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  632 ; minimum lost =  0.0135593730956316 ; diff loss =  9.294599294662476e-07 ; diff weight =  0.0008347967523150146
lambda is : 1.4677992676220687e-05, cost : 10.175 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-03 23:38:19 Max_iter: 1000
At iteration 569, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  569 ; minimum lost =  0.01682019606232643 ; diff loss =  -7.003545761108398e-07 ; diff weight =  0.010998550802469254
lambda is : 2.1544346900318854e-05, cost : 9.257 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-03 23:47:34 Max_iter: 1000
At iteration 640, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  641 ; minimum lost =  0.018063783645629883 ; diff loss =  6.016343832015991e-07 ; diff weight =  0.0007512533920817077
lambda is : 3.16227766016838e-05, cost : 10.161 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-03 23:57:44 Max_iter: 1000
At iteration 523, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  524 ; minimum lost =  0.02264638990163803 ; diff loss =  8.586794137954712e-07 ; diff weight =  0.0001902732183225453
lambda is : 4.6415888336127784e-05, cost : 8.43 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-04 00:06:10 Max_iter: 1000
At iteration 573, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  573 ; minimum lost =  0.024704916402697563 ; diff loss =  -6.891787052154541e-08 ; diff weight =  0.009668217971920967
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 9.13 min
==========
Testing lambda: 0.0001 starting at 2024-10-04 00:15:18 Max_iter: 1000
At iteration 591, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  592 ; minimum lost =  0.027686692774295807 ; diff loss =  5.885958671569824e-07 ; diff weight =  0.00019414900452829897
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 9.423 min
==========
Testing lambda: 0.000147 starting at 2024-10-04 00:24:43 Max_iter: 1000
At iteration 528, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  529 ; minimum lost =  0.03193594515323639 ; diff loss =  8.568167686462402e-07 ; diff weight =  0.00031197877251543105
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 8.427 min
==========
Testing lambda: 0.000215 starting at 2024-10-04 00:33:09 Max_iter: 1000
At iteration 558, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  559 ; minimum lost =  0.035917170345783234 ; diff loss =  8.493661880493164e-07 ; diff weight =  0.00033694462035782635
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 8.801 min
==========
Testing lambda: 0.000316 starting at 2024-10-04 00:41:57 Max_iter: 1000
At iteration 556, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  556 ; minimum lost =  0.04061231017112732 ; diff loss =  -4.246830940246582e-07 ; diff weight =  0.0029980596154928207
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 8.717 min
==========
Testing lambda: 0.000464 starting at 2024-10-04 00:50:40 Max_iter: 1000
At iteration 556, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  557 ; minimum lost =  0.046685636043548584 ; diff loss =  5.364418029785156e-07 ; diff weight =  0.0005160276195965707
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 8.746 min
==========
Testing lambda: 0.000681 starting at 2024-10-04 00:59:24 Max_iter: 1000
At iteration 540, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  541 ; minimum lost =  0.053839679807424545 ; diff loss =  6.370246410369873e-07 ; diff weight =  0.0015492113307118416
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 8.466 min
==========
Testing lambda: 0.001 starting at 2024-10-04 01:07:52 Max_iter: 1000
At iteration 586, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  587 ; minimum lost =  0.061909861862659454 ; diff loss =  1.862645149230957e-07 ; diff weight =  0.0005317309405654669
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 9.139 min
==========
Testing lambda: 0.001468 starting at 2024-10-04 01:17:01 Max_iter: 1000
At iteration 494, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  494 ; minimum lost =  0.07223954051733017 ; diff loss =  -7.674098014831543e-07 ; diff weight =  0.006133685819804668
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.748 min
==========
Testing lambda: 0.002154 starting at 2024-10-04 01:24:46 Max_iter: 1000
At iteration 515, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  515 ; minimum lost =  0.08380357921123505 ; diff loss =  -5.364418029785156e-07 ; diff weight =  0.0059127770364284515
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 8.023 min
==========
Testing lambda: 0.003162 starting at 2024-10-04 01:32:47 Max_iter: 1000
At iteration 592, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  593 ; minimum lost =  0.09748128056526184 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0026016125921159983
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 9.188 min
==========
Testing lambda: 0.004642 starting at 2024-10-04 01:41:58 Max_iter: 1000
At iteration 604, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  605 ; minimum lost =  0.11328022181987762 ; diff loss =  9.760260581970215e-07 ; diff weight =  0.001470675109885633
lambda is : 0.004641588833612781, cost : 9.372 min
==========
Testing lambda: 0.006813 starting at 2024-10-04 01:51:21 Max_iter: 1000
At iteration 571, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  572 ; minimum lost =  0.13172543048858643 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0012055806582793593
lambda is : 0.006812920690579613, cost : 8.861 min
==========
Testing lambda: 0.01 starting at 2024-10-04 02:00:12 Max_iter: 1000
At iteration 513, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  514 ; minimum lost =  0.1523616760969162 ; diff loss =  4.470348358154297e-08 ; diff weight =  0.0010450376430526376
lambda is : 0.010000000000000004, cost : 7.964 min
==========
Testing lambda: 0.014678 starting at 2024-10-04 02:08:10 Max_iter: 1000
At iteration 491, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.17493562400341034 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0006553496932610869
lambda is : 0.014677992676220709, cost : 7.622 min
==========
Testing lambda: 0.021544 starting at 2024-10-04 02:15:47 Max_iter: 1000
At iteration 398, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  398 ; minimum lost =  0.1993420124053955 ; diff loss =  -4.76837158203125e-07 ; diff weight =  0.003966964315623045
lambda is : 0.02154434690031885, cost : 6.203 min
==========
Testing lambda: 0.031623 starting at 2024-10-04 02:22:00 Max_iter: 1000
At iteration 444, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  445 ; minimum lost =  0.22639593482017517 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0006767002632841468
lambda is : 0.0316227766016838, cost : 6.895 min
==========
Testing lambda: 0.046416 starting at 2024-10-04 02:28:53 Max_iter: 1000
At iteration 371, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  372 ; minimum lost =  0.2563973665237427 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0009222205844707787
lambda is : 0.04641588833612786, cost : 5.77 min
==========
Testing lambda: 0.068129 starting at 2024-10-04 02:34:40 Max_iter: 1000
At iteration 245, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  246 ; minimum lost =  0.28153279423713684 ; diff loss =  1.1920928955078125e-07 ; diff weight =  7.240672857733443e-05
lambda is : 0.0681292069057962, cost : 3.832 min
==========
Testing lambda: 0.1 starting at 2024-10-04 02:38:29 Max_iter: 1000
At iteration 221, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  222 ; minimum lost =  0.30075374245643616 ; diff loss =  6.854534149169922e-07 ; diff weight =  0.0001922863448271528
lambda is : 0.10000000000000002, cost : 3.46 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.098967    0.338754          0.386458            2722  ...        1.0       1.0      0.010890       0.000844
0.000015    0.090678    0.366683          0.407922            2494  ...        1.0       1.0      0.013559       0.000835
0.000022    0.109257    0.328203          0.376503            3005  ...        1.0       1.0      0.016820       0.010999
0.000032    0.054756    0.476663          0.518210            1506  ...        1.0       1.0      0.018064       0.000751
0.000046    0.059737    0.471698          0.514088            1643  ...        1.0       1.0      0.022646       0.000190

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD8_Naive Time elapsed: 204.3775863091151 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD8_Proliferating
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-04 02:42:07 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.0158569123595953 ; diff loss =  6.183981895446777e-07 ; diff weight =  0.005401712842285633
lambda is : 9.999999999999997e-06, cost : 0.478 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-04 02:42:36 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.016015786677598953 ; diff loss =  7.320195436477661e-07 ; diff weight =  0.006378346122801304
lambda is : 1.4677992676220687e-05, cost : 0.441 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-04 02:43:02 Max_iter: 1000
At iteration 2, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  3 ; minimum lost =  0.016242390498518944 ; diff loss =  9.257346391677856e-07 ; diff weight =  0.007968584075570107
lambda is : 2.1544346900318854e-05, cost : 0.461 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-04 02:43:30 Max_iter: 1000
At iteration 314, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  315 ; minimum lost =  0.002598324790596962 ; diff loss =  8.558854460716248e-07 ; diff weight =  0.0031602068338543177
lambda is : 3.16227766016838e-05, cost : 5.001 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-04 02:48:30 Max_iter: 1000
At iteration 347, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  348 ; minimum lost =  0.0029040812514722347 ; diff loss =  7.9302117228508e-07 ; diff weight =  0.0023908831644803286
lambda is : 4.6415888336127784e-05, cost : 5.493 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-04 02:54:00 Max_iter: 1000
At iteration 341, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  342 ; minimum lost =  0.0034105274826288223 ; diff loss =  7.862690836191177e-07 ; diff weight =  0.009736182168126106
lambda is : 6.81292069057961e-05, cost : 5.358 min
==========
Testing lambda: 0.0001 starting at 2024-10-04 02:59:21 Max_iter: 1000
At iteration 302, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  303 ; minimum lost =  0.003997196909040213 ; diff loss =  8.582137525081635e-07 ; diff weight =  0.010656068101525307
lambda is : 9.999999999999991e-05, cost : 4.749 min
==========
Testing lambda: 0.000147 starting at 2024-10-04 03:04:06 Max_iter: 1000
At iteration 327, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  328 ; minimum lost =  0.00454344367608428 ; diff loss =  9.64384526014328e-07 ; diff weight =  0.005798092111945152
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 5.13 min
==========
Testing lambda: 0.000215 starting at 2024-10-04 03:09:14 Max_iter: 1000
At iteration 292, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  293 ; minimum lost =  0.005234560929238796 ; diff loss =  9.490177035331726e-07 ; diff weight =  0.002327120630070567
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 4.589 min
==========
Testing lambda: 0.000316 starting at 2024-10-04 03:13:49 Max_iter: 1000
At iteration 276, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  277 ; minimum lost =  0.005974739324301481 ; diff loss =  9.969808161258698e-07 ; diff weight =  0.004147879779338837
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 4.325 min
==========
Testing lambda: 0.000464 starting at 2024-10-04 03:18:09 Max_iter: 1000
At iteration 239, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  240 ; minimum lost =  0.0068978858180344105 ; diff loss =  9.592622518539429e-07 ; diff weight =  0.0038264861796051264
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 3.748 min
==========
Testing lambda: 0.000681 starting at 2024-10-04 03:21:54 Max_iter: 1000
At iteration 242, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  243 ; minimum lost =  0.007946114987134933 ; diff loss =  9.741634130477905e-07 ; diff weight =  0.004537557251751423
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 3.794 min
==========
Testing lambda: 0.001 starting at 2024-10-04 03:25:41 Max_iter: 1000
At iteration 212, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  213 ; minimum lost =  0.009327948093414307 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.003455192781984806
lambda is : 0.0010000000000000002, cost : 3.326 min
==========
Testing lambda: 0.001468 starting at 2024-10-04 03:29:01 Max_iter: 1000
At iteration 225, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  226 ; minimum lost =  0.01070590503513813 ; diff loss =  9.667128324508667e-07 ; diff weight =  0.003709246404469013
lambda is : 0.0014677992676220694, cost : 3.52 min
==========
Testing lambda: 0.002154 starting at 2024-10-04 03:32:32 Max_iter: 1000
At iteration 168, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  169 ; minimum lost =  0.012352457270026207 ; diff loss =  8.326023817062378e-07 ; diff weight =  0.0028031347319483757
lambda is : 0.0021544346900318843, cost : 2.642 min
==========
Testing lambda: 0.003162 starting at 2024-10-04 03:35:11 Max_iter: 1000
At iteration 84, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  85 ; minimum lost =  0.014023976400494576 ; diff loss =  8.25151801109314e-07 ; diff weight =  0.000208058743737638
lambda is : 0.003162277660168382, cost : 1.346 min
==========
Testing lambda: 0.004642 starting at 2024-10-04 03:36:31 Max_iter: 1000
At iteration 83, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  84 ; minimum lost =  0.015768563374876976 ; diff loss =  5.979090929031372e-07 ; diff weight =  0.0009935209527611732
lambda is : 0.004641588833612781, cost : 1.332 min
==========
Testing lambda: 0.006813 starting at 2024-10-04 03:37:51 Max_iter: 1000
At iteration 98, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  99 ; minimum lost =  0.01798146404325962 ; diff loss =  2.1792948246002197e-07 ; diff weight =  0.0005780458450317383
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.006812920690579613, cost : 1.562 min
==========
Testing lambda: 0.01 starting at 2024-10-04 03:39:25 Max_iter: 1000
At iteration 109, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  110 ; minimum lost =  0.021284732967615128 ; diff loss =  5.029141902923584e-08 ; diff weight =  0.00024628639221191406
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.010000000000000004, cost : 1.732 min
==========
Testing lambda: 0.014678 starting at 2024-10-04 03:41:09 Max_iter: 1000
At iteration 116, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  117 ; minimum lost =  0.025942444801330566 ; diff loss =  4.246830940246582e-07 ; diff weight =  0.0005983710289001465
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.014677992676220709, cost : 1.843 min
==========
Testing lambda: 0.021544 starting at 2024-10-04 03:42:59 Max_iter: 1000
At iteration 110, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  111 ; minimum lost =  0.032454218715429306 ; diff loss =  1.601874828338623e-07 ; diff weight =  0.00036007165908813477
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.02154434690031885, cost : 1.748 min
==========
Testing lambda: 0.031623 starting at 2024-10-04 03:44:44 Max_iter: 1000
At iteration 133, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  134 ; minimum lost =  0.041483793407678604 ; diff loss =  7.450580596923828e-09 ; diff weight =  5.459785461425781e-05
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0316227766016838, cost : 2.104 min
==========
Testing lambda: 0.046416 starting at 2024-10-04 03:46:51 Max_iter: 1000
At iteration 132, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  132 ; minimum lost =  0.05390658974647522 ; diff loss =  -6.332993507385254e-07 ; diff weight =  0.009724797680974007
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.04641588833612786, cost : 2.101 min
==========
Testing lambda: 0.068129 starting at 2024-10-04 03:48:57 Max_iter: 1000
At iteration 135, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  136 ; minimum lost =  0.07081504911184311 ; diff loss =  9.313225746154785e-07 ; diff weight =  0.0006024837493896484
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.0681292069057962, cost : 2.132 min
==========
Testing lambda: 0.1 starting at 2024-10-04 03:51:05 Max_iter: 1000
At iteration 135, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  136 ; minimum lost =  0.09364486485719681 ; diff loss =  3.501772880554199e-07 ; diff weight =  0.00029903650283813477
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
lambda is : 0.10000000000000002, cost : 2.132 min
==========
          Percentage  Prevalence  Other_prevalence  Feature_number  ...  Precision  F1 score  loss_history  error_history
0.000010    0.396015    0.247191          0.127555           10892  ...        1.0       1.0      0.015857       0.005402
0.000015    0.382090    0.258427          0.134625           10509  ...        1.0       1.0      0.016016       0.006378
0.000022    0.364929    0.269663          0.142305           10037  ...        1.0       1.0      0.016242       0.007969
0.000032    0.033050    0.865169          0.582576             909  ...        1.0       1.0      0.002598       0.003160
0.000046    0.019234    0.932584          0.692770             529  ...        1.0       1.0      0.002904       0.002391

[5 rows x 11 columns]
Exporting resultDF
Exporting result Dict
CD8_Proliferating Time elapsed: 71.15179912646612 minutes.
Representative adata: (57515, 27504)
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for CD8_TCM
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
Testing lambda: 1e-05 starting at 2024-10-04 03:53:22 Max_iter: 1000
At iteration 523, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  524 ; minimum lost =  0.016671495512127876 ; diff loss =  9.201467037200928e-07 ; diff weight =  0.0006187953986227512
lambda is : 9.999999999999997e-06, cost : 8.573 min
==========
Testing lambda: 1.5e-05 starting at 2024-10-04 04:01:56 Max_iter: 1000
At iteration 538, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  538 ; minimum lost =  0.01963299885392189 ; diff loss =  -4.6566128730773926e-07 ; diff weight =  0.01475951261818409
lambda is : 1.4677992676220687e-05, cost : 8.81 min
==========
Testing lambda: 2.2e-05 starting at 2024-10-04 04:10:45 Max_iter: 1000
At iteration 492, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.022863546386361122 ; diff loss =  -6.016343832015991e-07 ; diff weight =  0.015355817973613739
lambda is : 2.1544346900318854e-05, cost : 8.005 min
==========
Testing lambda: 3.2e-05 starting at 2024-10-04 04:18:45 Max_iter: 1000
At iteration 554, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  555 ; minimum lost =  0.02489488013088703 ; diff loss =  5.140900611877441e-07 ; diff weight =  0.0016356654232367873
lambda is : 3.16227766016838e-05, cost : 8.902 min
==========
Testing lambda: 4.6e-05 starting at 2024-10-04 04:27:39 Max_iter: 1000
At iteration 550, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  551 ; minimum lost =  0.02867838554084301 ; diff loss =  6.407499313354492e-07 ; diff weight =  0.00012389846961013973
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 8.992 min
==========
Testing lambda: 6.8e-05 starting at 2024-10-04 04:36:39 Max_iter: 1000
At iteration 395, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  396 ; minimum lost =  0.03546594828367233 ; diff loss =  9.350478649139404e-07 ; diff weight =  0.00016305311874020845
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 6.542 min
==========
Testing lambda: 0.0001 starting at 2024-10-04 04:43:11 Max_iter: 1000
At iteration 430, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  431 ; minimum lost =  0.03784266859292984 ; diff loss =  9.57399606704712e-07 ; diff weight =  0.0003489161026664078
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 6.976 min
==========
Testing lambda: 0.000147 starting at 2024-10-04 04:50:10 Max_iter: 1000
At iteration 505, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  506 ; minimum lost =  0.040958061814308167 ; diff loss =  3.650784492492676e-07 ; diff weight =  0.0008419135701842606
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 8.119 min
==========
Testing lambda: 0.000215 starting at 2024-10-04 04:58:17 Max_iter: 1000
At iteration 456, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  457 ; minimum lost =  0.045777469873428345 ; diff loss =  6.48200511932373e-07 ; diff weight =  0.00028613509493879974
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 7.283 min
==========
Testing lambda: 0.000316 starting at 2024-10-04 05:05:34 Max_iter: 1000
At iteration 461, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  462 ; minimum lost =  0.050849273800849915 ; diff loss =  4.954636096954346e-07 ; diff weight =  0.004029730800539255
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 7.341 min
==========
Testing lambda: 0.000464 starting at 2024-10-04 05:12:54 Max_iter: 1000
At iteration 442, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  443 ; minimum lost =  0.05686383694410324 ; diff loss =  6.705522537231445e-07 ; diff weight =  0.00041470996802672744
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 7.071 min
==========
Testing lambda: 0.000681 starting at 2024-10-04 05:19:59 Max_iter: 1000
At iteration 463, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  464 ; minimum lost =  0.06315057724714279 ; diff loss =  6.92903995513916e-07 ; diff weight =  0.0021229092963039875
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 7.316 min
==========
Testing lambda: 0.001 starting at 2024-10-04 05:27:18 Max_iter: 1000
At iteration 491, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  492 ; minimum lost =  0.07009001821279526 ; diff loss =  3.725290298461914e-08 ; diff weight =  0.0015029379865154624
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 7.738 min
==========
Testing lambda: 0.001468 starting at 2024-10-04 05:35:02 Max_iter: 1000
At iteration 478, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  479 ; minimum lost =  0.07739374041557312 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0015434783417731524
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 7.567 min
==========
Testing lambda: 0.002154 starting at 2024-10-04 05:42:36 Max_iter: 1000
At iteration 480, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  481 ; minimum lost =  0.085175059735775 ; diff loss =  9.462237358093262e-07 ; diff weight =  0.0013693186920136213
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 7.584 min
==========
Testing lambda: 0.003162 starting at 2024-10-04 05:50:11 Max_iter: 1000
At iteration 464, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  465 ; minimum lost =  0.09354567527770996 ; diff loss =  8.717179298400879e-07 ; diff weight =  0.0013047861866652966
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 7.426 min
==========
Testing lambda: 0.004642 starting at 2024-10-04 05:57:36 Max_iter: 1000
At iteration 460, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  461 ; minimum lost =  0.10270503163337708 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.002295965561643243
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 7.241 min
==========
Testing lambda: 0.006813 starting at 2024-10-04 06:04:51 Max_iter: 1000
At iteration 456, Convergence with loss difference, Device: cuda
Convergence with loss difference, Device: cuda
minimum epoch =  456 ; minimum lost =  0.11188796162605286 ; diff loss =  -1.9371509552001953e-07 ; diff weight =  0.0028299379628151655
lambda is : 0.006812920690579613, cost : 7.152 min
==========
Testing lambda: 0.01 starting at 2024-10-04 06:12:00 Max_iter: 1000

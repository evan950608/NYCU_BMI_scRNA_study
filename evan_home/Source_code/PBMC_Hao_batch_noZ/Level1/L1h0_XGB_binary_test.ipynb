{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Path: c:\\Users\\evanlee\\Documents\\Bmi_NAS_evan\\evan_home\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory as a Path object\n",
    "current_path = Path.cwd()\n",
    "home_folder = 'evan_home'\n",
    "\n",
    "# Traverse up the directory tree until you find the target folder\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if parent.name == home_folder:\n",
    "        home_path = parent\n",
    "        break\n",
    "else:\n",
    "    raise ValueError(f\"Folder '{home_folder}' not found in the current working directory.\")\n",
    "\n",
    "print(\"Home Path:\", home_path)\n",
    "source_code_dir = home_path / 'Source_code'\n",
    "dataset_dir = home_path / 'Dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve, average_precision_score, matthews_corrcoef\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original adata: (161764, 33538)\n",
      "all cell types: ['B', 'CD4_T', 'CD8_T', 'DC', 'Mono', 'NK', 'other', 'other_T']\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# adata = sc.read_h5ad(r\"C:\\Users\\evanlee\\Documents\\Research_datasets\\PBMC_Hao\\GSE164378_Hao\\Harmony_noZ\\Hao_Harmony_test_no_scale.h5ad\")\n",
    "adata = sc.read_h5ad(dataset_dir / 'PBMC_Hao/GSE164378_Hao/Harmony_noZ/Hao_Harmony_test_no_scale.h5ad')\n",
    "print('Original adata:', adata.shape)\n",
    "adata.obs['celltype.l1'] = adata.obs['celltype.l1'].str.replace(' ', '_')\n",
    "label = adata.obs['celltype.l1'].tolist()\n",
    "types = np.unique(label).tolist()\n",
    "print('all cell types:', types)\n",
    "print('====================')\n",
    "# del adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celltype.l1</th>\n",
       "      <th>celltype.l2</th>\n",
       "      <th>celltype.l3</th>\n",
       "      <th>Batch</th>\n",
       "      <th>donor</th>\n",
       "      <th>time</th>\n",
       "      <th>lane</th>\n",
       "      <th>Phase</th>\n",
       "      <th>nCount_ADT</th>\n",
       "      <th>nFeature_ADT</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>leiden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_AAACCCAAGAAACTCA</th>\n",
       "      <td>Mono</td>\n",
       "      <td>CD14 Mono</td>\n",
       "      <td>CD14 Mono</td>\n",
       "      <td>Batch1</td>\n",
       "      <td>P2</td>\n",
       "      <td>7</td>\n",
       "      <td>L1</td>\n",
       "      <td>G1</td>\n",
       "      <td>7535</td>\n",
       "      <td>217</td>\n",
       "      <td>10823</td>\n",
       "      <td>2915</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_AAACCCAAGACATACA</th>\n",
       "      <td>CD4_T</td>\n",
       "      <td>CD4 TCM</td>\n",
       "      <td>CD4 TCM_1</td>\n",
       "      <td>Batch1</td>\n",
       "      <td>P1</td>\n",
       "      <td>7</td>\n",
       "      <td>L1</td>\n",
       "      <td>G1</td>\n",
       "      <td>6013</td>\n",
       "      <td>209</td>\n",
       "      <td>5864</td>\n",
       "      <td>1617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_AAACCCACAACTGGTT</th>\n",
       "      <td>CD8_T</td>\n",
       "      <td>CD8 Naive</td>\n",
       "      <td>CD8 Naive</td>\n",
       "      <td>Batch1</td>\n",
       "      <td>P4</td>\n",
       "      <td>2</td>\n",
       "      <td>L1</td>\n",
       "      <td>S</td>\n",
       "      <td>6620</td>\n",
       "      <td>213</td>\n",
       "      <td>5067</td>\n",
       "      <td>1381</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_AAACCCACACGTACTA</th>\n",
       "      <td>NK</td>\n",
       "      <td>NK</td>\n",
       "      <td>NK_2</td>\n",
       "      <td>Batch1</td>\n",
       "      <td>P3</td>\n",
       "      <td>7</td>\n",
       "      <td>L1</td>\n",
       "      <td>G1</td>\n",
       "      <td>3567</td>\n",
       "      <td>202</td>\n",
       "      <td>4786</td>\n",
       "      <td>1890</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_AAACCCACAGCATACT</th>\n",
       "      <td>CD8_T</td>\n",
       "      <td>CD8 Naive</td>\n",
       "      <td>CD8 Naive</td>\n",
       "      <td>Batch1</td>\n",
       "      <td>P4</td>\n",
       "      <td>7</td>\n",
       "      <td>L1</td>\n",
       "      <td>G1</td>\n",
       "      <td>6402</td>\n",
       "      <td>215</td>\n",
       "      <td>6505</td>\n",
       "      <td>1621</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    celltype.l1 celltype.l2 celltype.l3   Batch donor  time  \\\n",
       "L1_AAACCCAAGAAACTCA        Mono   CD14 Mono   CD14 Mono  Batch1    P2     7   \n",
       "L1_AAACCCAAGACATACA       CD4_T     CD4 TCM   CD4 TCM_1  Batch1    P1     7   \n",
       "L1_AAACCCACAACTGGTT       CD8_T   CD8 Naive   CD8 Naive  Batch1    P4     2   \n",
       "L1_AAACCCACACGTACTA          NK          NK        NK_2  Batch1    P3     7   \n",
       "L1_AAACCCACAGCATACT       CD8_T   CD8 Naive   CD8 Naive  Batch1    P4     7   \n",
       "\n",
       "                    lane Phase  nCount_ADT  nFeature_ADT  nCount_RNA  \\\n",
       "L1_AAACCCAAGAAACTCA   L1    G1        7535           217       10823   \n",
       "L1_AAACCCAAGACATACA   L1    G1        6013           209        5864   \n",
       "L1_AAACCCACAACTGGTT   L1     S        6620           213        5067   \n",
       "L1_AAACCCACACGTACTA   L1    G1        3567           202        4786   \n",
       "L1_AAACCCACAGCATACT   L1    G1        6402           215        6505   \n",
       "\n",
       "                     nFeature_RNA leiden  \n",
       "L1_AAACCCAAGAAACTCA          2915      4  \n",
       "L1_AAACCCAAGACATACA          1617      2  \n",
       "L1_AAACCCACAACTGGTT          1381      5  \n",
       "L1_AAACCCACACGTACTA          1890      3  \n",
       "L1_AAACCCACAGCATACT          1621      5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\evanlee\\Documents\\GitHub\\EvanPys\\Progress\\PBMC_Hao_batch_noZ\\Level1\\feature_selection_k3\")\n",
    "os.chdir(source_code_dir / 'PBMC_Hao_batch_noZ/Level1/feature_selection_k3')\n",
    "\n",
    "features_dict = {}\n",
    "# Read features for each celltype\n",
    "for celltype in types:\n",
    "    try:\n",
    "        feature_df = pd.read_csv(f'{celltype}_features.txt', names=['Gene', 'Weight', 'Tendency'], sep='\\t')\n",
    "        features_dict[celltype] = feature_df\n",
    "    except:\n",
    "        print('skipping:', celltype)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['B', 'CD4_T', 'CD8_T', 'DC', 'Mono', 'NK', 'other', 'other_T'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_count</th>\n",
       "      <th>Positive_feature_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD4_T</th>\n",
       "      <td>201</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8_T</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mono</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_T</th>\n",
       "      <td>247</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature_count  Positive_feature_count\n",
       "B                   19                      10\n",
       "CD4_T              201                      95\n",
       "CD8_T               23                       9\n",
       "DC                  50                      23\n",
       "Mono                50                      20\n",
       "NK                  33                      17\n",
       "other                5                       3\n",
       "other_T            247                     112"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(columns=['Feature_count', 'Positive_feature_count'])\n",
    "for celltype in features_dict.keys():\n",
    "    feature_df = features_dict[celltype]\n",
    "    feature_count = feature_df.shape[0]\n",
    "    positive_count = feature_df[feature_df['Tendency'] == 1].shape[0]\n",
    "    count_df.loc[celltype] = [feature_count, positive_count]\n",
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = 'B'\n",
    "\n",
    "# subset data to celltype features\n",
    "X = adata[:, features_dict[celltype]['Gene'].tolist()].X\n",
    "# Binary label\n",
    "y = [1 if i==celltype else 0 for i in adata.obs['celltype.l1'].tolist()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification matrices\n",
    "# dtrain_clf = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "# dtest_clf = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "dtrain_clf = xgb.DMatrix(X_train, y_train, enable_categorical=False)\n",
    "dtest_clf = xgb.DMatrix(X_test, y_test, enable_categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"objective\": \"binary:logistic\", \"tree_method\": \"gpu_hist\"}  # no need to set \"num_class\" because binary classification\n",
    "params = {\"objective\": \"binary:logistic\", \"device\": \"cuda\"}\n",
    "n = 1000\n",
    "model = xgb.train(\n",
    "    params=params, \n",
    "    dtrain=dtrain_clf, \n",
    "    num_boost_round=n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997836367570241\n",
      "Precision: 0.9985512495472655\n",
      "Recall: 0.9989130434782608\n",
      "F1 Score: 0.9987321137475094\n",
      "ROC AUC: 0.9999991429622261\n",
      "PR AUC: 0.9999908163381536\n",
      "MCC: 0.9986138601199674\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict(dtest_clf)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_prob]  # Threshold at 0.5\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "pr_auc = average_precision_score(y_test, y_prob)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"PR AUC:\", pr_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate: xgb.cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-logloss-mean  train-logloss-std  train-auc-mean  train-auc-std  \\\n",
      "0              0.166108       1.248221e-04        0.999056       0.000203   \n",
      "1              0.116896       8.079640e-05        0.999504       0.000157   \n",
      "2              0.084105       5.370915e-05        0.999600       0.000102   \n",
      "3              0.061219       4.490751e-05        0.999705       0.000044   \n",
      "4              0.044926       5.499863e-05        0.999776       0.000046   \n",
      "..                  ...                ...             ...            ...   \n",
      "995            0.000023       3.714273e-07        1.000000       0.000000   \n",
      "996            0.000023       3.719030e-07        1.000000       0.000000   \n",
      "997            0.000023       3.723933e-07        1.000000       0.000000   \n",
      "998            0.000023       3.728537e-07        1.000000       0.000000   \n",
      "999            0.000023       3.733349e-07        1.000000       0.000000   \n",
      "\n",
      "     test-logloss-mean  test-logloss-std  test-auc-mean  test-auc-std  \n",
      "0             0.166369          0.000192       0.998819      0.000621  \n",
      "1             0.117301          0.000164       0.999280      0.000617  \n",
      "2             0.084608          0.000177       0.999431      0.000538  \n",
      "3             0.061802          0.000220       0.999540      0.000424  \n",
      "4             0.045581          0.000229       0.999592      0.000406  \n",
      "..                 ...               ...            ...           ...  \n",
      "995           0.001355          0.000717       0.999990      0.000013  \n",
      "996           0.001355          0.000717       0.999990      0.000013  \n",
      "997           0.001355          0.000717       0.999990      0.000013  \n",
      "998           0.001355          0.000717       0.999990      0.000013  \n",
      "999           0.001355          0.000717       0.999990      0.000013  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "n = 1000\n",
    "\n",
    "# cross validation\n",
    "cv_results = xgb.cv(\n",
    "   params=params, \n",
    "   dtrain=dtrain_clf, \n",
    "   num_boost_round=n,\n",
    "   nfold=5,\n",
    "   metrics=[\"logloss\", \"auc\"],\n",
    "   as_pandas=True, \n",
    "   seed=42\n",
    ")\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC across folds: 0.9999901886855384\n"
     ]
    }
   ],
   "source": [
    "# Display mean AUC of cross-validation folds\n",
    "mean_auc = cv_results['test-auc-mean'].iloc[-1]\n",
    "print(\"Mean AUC across folds:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation: Stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 161761 161762 161763] [     3      8     16 ... 161744 161747 161751]\n",
      "[     0      2      3 ... 161761 161762 161763] [     1      4      6 ... 161730 161750 161756]\n",
      "[     0      1      3 ... 161760 161762 161763] [     2      5     12 ... 161749 161754 161761]\n",
      "[     0      1      2 ... 161761 161762 161763] [    11     22     33 ... 161753 161757 161759]\n",
      "[     1      2      3 ... 161757 161759 161761] [     0      9     10 ... 161760 161762 161763]\n",
      "Mean Accuracy: 0.9996476345202616 Std Dev: 4.626306295287637e-05\n",
      "Mean Precision: 0.9982607629439691 Std Dev: 0.0008376342262167467\n",
      "Mean Recall: 0.9976086956521739 Std Dev: 0.0004914731871830017\n",
      "Mean F1 Score: 0.9979342237366859 Std Dev: 0.00027036383628093065\n",
      "Mean ROC AUC: 0.9999937313727452 Std Dev: 8.436315644889128e-06\n",
      "Mean PR AUC: 0.9999127347210308 Std Dev: 0.000129920145510554\n",
      "Mean MCC: 0.9977419160995993 Std Dev: 0.0002958599206462882\n"
     ]
    }
   ],
   "source": [
    "# Stratified cross validation\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"eval_metric\": \"logloss\", \n",
    "    'lambda': 1  # L2 regularization term on weights\n",
    "}\n",
    "n = 1000\n",
    "\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to collect metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "roc_aucs = []\n",
    "pr_aucs = []\n",
    "mccs = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(train_index, test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    \n",
    "    # Create DMatrix objects for train and test sets\n",
    "    dtrain_clf = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest_clf = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    # Train the XGBoost model\n",
    "    model = xgb.train(params=params, dtrain=dtrain_clf, num_boost_round=n)\n",
    "    \n",
    "    # Predict probabilities and classify with a 0.5 threshold\n",
    "    y_prob = model.predict(dtest_clf)\n",
    "    y_pred = [1 if prob > 0.5 else 0 for prob in y_prob]\n",
    "    \n",
    "    # Calculate and collect metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_test, y_prob))\n",
    "    pr_aucs.append(average_precision_score(y_test, y_prob))\n",
    "    mccs.append(matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "print(\"Mean Accuracy:\", np.mean(accuracies), \"Std Dev:\", np.std(accuracies))\n",
    "print(\"Mean Precision:\", np.mean(precisions), \"Std Dev:\", np.std(precisions))\n",
    "print(\"Mean Recall:\", np.mean(recalls), \"Std Dev:\", np.std(recalls))\n",
    "print(\"Mean F1 Score:\", np.mean(f1_scores), \"Std Dev:\", np.std(f1_scores))\n",
    "print(\"Mean ROC AUC:\", np.mean(roc_aucs), \"Std Dev:\", np.std(roc_aucs))\n",
    "print(\"Mean PR AUC:\", np.mean(pr_aucs), \"Std Dev:\", np.std(pr_aucs))\n",
    "print(\"Mean MCC:\", np.mean(mccs), \"Std Dev:\", np.std(mccs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation: XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratCV_results = xgb.cv(\n",
    "#    params=params, \n",
    "#    dtrain=dtrain_clf, \n",
    "#    num_boost_round=n,\n",
    "#    folds=skf,\n",
    "#    metrics=\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = 'B'\n",
    "\n",
    "# subset data to celltype features\n",
    "X = adata[:, features_dict[celltype]['Gene'].tolist()].X\n",
    "# Binary label\n",
    "y = [1 if i==celltype else 0 for i in adata.obs['celltype.l1'].tolist()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', eval_metric='logloss', reg_lambda=1)\n",
    "\n",
    "# Train the classifier\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997218186876023\n",
      "Precision: 0.9981890619340819\n",
      "Recall: 0.9985507246376811\n",
      "F1 Score: 0.9983698605325122\n",
      "ROC AUC: 0.9999989837980682\n",
      "PR AUC: 0.9999890641157058\n",
      "MCC: 0.9982178145523835\n"
     ]
    }
   ],
   "source": [
    "# y_prob = model.predict(dtest_clf)\n",
    "# y_pred = [1 if prob > 0.5 else 0 for prob in y_prob]  # Threshold at 0.5\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "y_prob = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "pr_auc = average_precision_score(y_test, y_prob)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"PR AUC:\", pr_auc)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation...\n"
     ]
    }
   ],
   "source": [
    "# Kfold cross validation\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1_score': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'average_precision': 'average_precision',  # PR AUC\n",
    "    'mcc': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "k = 5\n",
    "print('Cross validation...')\n",
    "cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "# cv_results = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=32)\n",
    "## Use training set in cross_validate()\n",
    "cv_results = cross_validate(xgb_clf, X_train, y_train, cv=cv, scoring=scoring, n_jobs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.62881517, 4.57806063, 4.64584613, 4.52797961, 4.60318828]),\n",
       " 'score_time': array([0.59358358, 0.59966397, 0.57604027, 0.58403134, 0.58455491]),\n",
       " 'test_accuracy': array([0.99957501, 0.99957499, 0.99961363, 0.99976818, 0.99972954]),\n",
       " 'test_precision': array([0.99909132, 0.99863822, 0.99773551, 0.9977396 , 0.99818923]),\n",
       " 'test_recall': array([0.99592391, 0.99637681, 0.99773551, 0.9995471 , 0.9986413 ]),\n",
       " 'test_f1_score': array([0.9975051 , 0.99750623, 0.99773551, 0.99864253, 0.99841521]),\n",
       " 'test_roc_auc': array([0.99999874, 0.99999904, 0.99999799, 0.99999049, 0.99999297]),\n",
       " 'test_average_precision': array([0.99998651, 0.99998975, 0.99997839, 0.99989188, 0.99991975]),\n",
       " 'test_mcc': array([0.99727433, 0.9972747 , 0.99752431, 0.99851629, 0.9982674 ])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

nohup: ignoring input
Shape: (71915, 25712) <class 'scipy.sparse._csc.csc_matrix'>
Celltypes: ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
====================
                        celltype  res_3_clus  sample   site patient stage virus    leiden
HCC01T_AAACCTGAGGGCATGT     T_NK          13  HCC01T  Tumor   HCC01     I   HBV  Leiden_5
HCC01T_AAACCTGAGTCGCCGT  Myeloid          16  HCC01T  Tumor   HCC01     I   HBV  Leiden_3
HCC01T_AAACCTGCATTACCTT     T_NK          25  HCC01T  Tumor   HCC01     I   HBV  Leiden_5
HCC01T_AAACCTGGTCACACGC     T_NK           2  HCC01T  Tumor   HCC01     I   HBV  Leiden_1
HCC01T_AAACCTGTCCAGTATG     T_NK           2  HCC01T  Tumor   HCC01     I   HBV  Leiden_1
celltype
T_NK           25591
Hepatocyte     20782
Myeloid        15947
B               3685
Endothelial     3644
Fibroblast      2266
Name: count, dtype: int64
======
***** Starting tuning
Shape: (71915, 25712)
['T_NK', 'Myeloid', 'Endothelial', 'Hepatocyte', 'Fibroblast', 'B']
Categories (6, object): ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for B
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
*** Start parallel lambda tuning ***
Lambda:Lambda:Lambda:Lambda:Lambda: Lambda:Lambda: Lambda:Lambda: Lambda: Lambda:Lambda: Lambda:Lambda:2.2e-05 Lambda: Lambda: Lambda:1e-05 Lambda: Lambda: Lambda:4.6e-05Lambda: Lambda:1.5e-05 Lambda: Lambda: Lambda:  0.000147   starting at  3.2e-05  0.001  starting at  0.003162  6.8e-05   starting at 0.0001  starting at  0.000215 0.068129 0.1 0.046416 starting at 0.000316 0.000464 2024-11-25 12:08:20 0.000681 starting at 0.001468 starting at 0.002154 2024-11-25 12:08:20 0.004642 starting at 0.006813 starting at 0.01  2024-11-25 12:08:200.014678 starting at 0.021544 2024-11-25 12:08:20 0.031623 starting at starting at starting at starting at 2024-11-25 12:08:20 starting at starting at Max_iter: starting at 2024-11-25 12:08:20 starting at 2024-11-25 12:08:20 starting at Max_iter: starting at 2024-11-25 12:08:20 starting at 2024-11-25 12:08:20 starting at  Max_iter:starting at 2024-11-25 12:08:20 starting at Max_iter: starting at 2024-11-25 12:08:20 2024-11-25 12:08:20 2024-11-25 12:08:20 2024-11-25 12:08:20 Max_iter: 2024-11-25 12:08:20 2024-11-25 12:08:20 10002024-11-25 12:08:20 Max_iter: 2024-11-25 12:08:20 Max_iter: 2024-11-25 12:08:20 10002024-11-25 12:08:20 Max_iter: 2024-11-25 12:08:20 Max_iter: 2024-11-25 12:08:20  10002024-11-25 12:08:20 Max_iter: 2024-11-25 12:08:20 1000
2024-11-25 12:08:20 Max_iter: Max_iter: Max_iter: Max_iter: 1000Max_iter: Max_iter: 
Max_iter: 1000
Max_iter: 1000Max_iter: 
Max_iter: 1000Max_iter: 1000Max_iter: 
Max_iter: 1000Max_iter:Max_iter:10001000
10001000
10001000
1000
1000

10001000
1000
10001000
  








10001000

At iteration 196, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  197 ; minimum lost =  0.22426146268844604 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0003217702324036509
lambda is : 0.0681292069057962, cost : 47.548 min
==========
At iteration 249, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  250 ; minimum lost =  0.17304039001464844 ; diff loss =  6.109476089477539e-07 ; diff weight =  0.00018664241360966116
lambda is : 0.0316227766016838, cost : 59.709 min
==========
At iteration 285, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  286 ; minimum lost =  0.2528448700904846 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0004561158420983702
lambda is : 0.10000000000000002, cost : 68.691 min
==========
At iteration 296, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  297 ; minimum lost =  0.19634926319122314 ; diff loss =  5.364418029785156e-07 ; diff weight =  0.00027366794529370964
lambda is : 0.04641588833612786, cost : 70.439 min
==========
At iteration 298, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  299 ; minimum lost =  0.15180817246437073 ; diff loss =  7.450580596923828e-07 ; diff weight =  0.0006741896504536271
lambda is : 0.02154434690031885, cost : 71.603 min
==========
At iteration 345, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  346 ; minimum lost =  0.13009357452392578 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0010822665644809604
lambda is : 0.014677992676220709, cost : 82.635 min
==========
At iteration 399, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  400 ; minimum lost =  0.11118800938129425 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0012095392448827624
lambda is : 0.010000000000000004, cost : 94.332 min
==========
At iteration 406, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  407 ; minimum lost =  0.09570266306400299 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0010433171410113573
lambda is : 0.006812920690579613, cost : 95.135 min
==========
At iteration 418, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  419 ; minimum lost =  0.07300945371389389 ; diff loss =  7.003545761108398e-07 ; diff weight =  0.0011750534176826477
lambda is : 0.003162277660168382, cost : 98.352 min
==========
At iteration 428, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  429 ; minimum lost =  0.0645168349146843 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0010533391032367945
At iteration 427, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  428 ; minimum lost =  0.08323146402835846 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0016584154218435287
lambda is : 0.004641588833612781, cost : 102.09 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 102.099 min
==========
At iteration 435, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  436 ; minimum lost =  0.057536378502845764 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.001383631257340312
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 102.444 min
==========
At iteration 441, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  442 ; minimum lost =  0.05179235339164734 ; diff loss =  9.015202522277832e-07 ; diff weight =  0.001415679114870727
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 103.063 min
==========
At iteration 467, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  468 ; minimum lost =  0.04333716630935669 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.002911919029429555
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 110.139 min
==========
At iteration 474, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  475 ; minimum lost =  0.037134092301130295 ; diff loss =  5.476176738739014e-07 ; diff weight =  0.001353211933746934
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 111.574 min
==========
At iteration 469, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  470 ; minimum lost =  0.024304863065481186 ; diff loss =  6.854534149169922e-07 ; diff weight =  0.011727814562618732
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 2.1544346900318854e-05, cost : 112.445 min
==========
At iteration 477, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  478 ; minimum lost =  0.03470440208911896 ; diff loss =  5.997717380523682e-07 ; diff weight =  0.0029062549583613873
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 113.605 min
==========
At iteration 479, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  480 ; minimum lost =  0.04710143432021141 ; diff loss =  8.828938007354736e-07 ; diff weight =  0.0018332634354010224
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 114.887 min
==========
At iteration 487, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  488 ; minimum lost =  0.03237995505332947 ; diff loss =  6.407499313354492e-07 ; diff weight =  0.0004936850746162236
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 116.055 min
==========
At iteration 489, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  490 ; minimum lost =  0.02814214862883091 ; diff loss =  5.792826414108276e-07 ; diff weight =  0.0010521902004256845
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 116.449 min
==========
At iteration 495, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  496 ; minimum lost =  0.030174871906638145 ; diff loss =  7.35744833946228e-07 ; diff weight =  0.005235104355961084
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 117.468 min
==========
At iteration 512, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  513 ; minimum lost =  0.021850228309631348 ; diff loss =  8.307397365570068e-07 ; diff weight =  0.0006267536664381623
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 1.4677992676220687e-05, cost : 118.483 min
==========
At iteration 533, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  534 ; minimum lost =  0.01948101632297039 ; diff loss =  7.469207048416138e-07 ; diff weight =  0.0004232654464431107
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999997e-06, cost : 124.077 min
==========
At iteration 541, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  542 ; minimum lost =  0.0399128720164299 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.0024530012160539627
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 125.143 min
==========
At iteration 541, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  542 ; minimum lost =  0.025920502841472626 ; diff loss =  4.805624485015869e-07 ; diff weight =  0.0002806475094985217
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 126.607 min
==========
*** Collecting results ***
Exporting result Dict
B Time elapsed: 126.68416050275167 minutes.
Shape: (71915, 25712)
['T_NK', 'Myeloid', 'Endothelial', 'Hepatocyte', 'Fibroblast', 'B']
Categories (6, object): ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for Endothelial
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
*** Start parallel lambda tuning ***
Lambda:Lambda:Lambda: Lambda:Lambda: Lambda: Lambda:1e-05Lambda: Lambda: Lambda:Lambda: Lambda: 1.5e-05 Lambda:Lambda: Lambda:Lambda:2.2e-05 Lambda: Lambda:  starting atLambda:Lambda:Lambda:0.000147 Lambda: Lambda:3.2e-05 Lambda:Lambda: 4.6e-05 0.000464 starting at   6.8e-05   starting at  0.0001 0.004642  2024-11-25 14:15:09   starting at  0.000215   starting at0.046416   0.000316starting at starting at 2024-11-25 14:15:09 0.001 0.000681 starting at 0.001468 0.002154 2024-11-25 14:15:09 0.003162 starting at starting at  Max_iter:0.006813 0.01 0.014678 2024-11-25 14:15:09 0.021544 starting at 0.031623  2024-11-25 14:15:09starting at 0.0681290.1  starting at2024-11-25 14:15:09 2024-11-25 14:15:09 Max_iter: starting at starting at 2024-11-25 14:15:09 starting at starting at Max_iter: starting at 2024-11-25 14:15:09 2024-11-25 14:15:09  1000starting at starting at starting at Max_iter: starting at 2024-11-25 14:15:09 starting at  Max_iter:2024-11-25 14:15:09  starting atstarting at  2024-11-25 14:15:09Max_iter: Max_iter: 10002024-11-25 14:15:09 2024-11-25 14:15:09 Max_iter: 2024-11-25 14:15:09 2024-11-25 14:15:09 1000
2024-11-25 14:15:09 Max_iter: Max_iter:
2024-11-25 14:15:092024-11-25 14:15:09 2024-11-25 14:15:09 10002024-11-25 14:15:09 Max_iter: 2024-11-25 14:15:09  1000Max_iter:  2024-11-25 14:15:092024-11-25 14:15:09  Max_iter:10001000
Max_iter:Max_iter:1000Max_iter:Max_iter: Max_iter:1000  Max_iter:Max_iter:Max_iter: 
Max_iter:1000Max_iter:
1000
 Max_iter:Max_iter:  1000

 1000 1000
 10001000
 1000
1000 1000 1000
 
  1000






10001000
10001000



At iteration 206, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  207 ; minimum lost =  0.2634146511554718 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0002496874949429184
lambda is : 0.10000000000000002, cost : 50.169 min
==========
At iteration 218, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  219 ; minimum lost =  0.23335114121437073 ; diff loss =  7.152557373046875e-07 ; diff weight =  0.0003283775004092604
lambda is : 0.0681292069057962, cost : 53.416 min
==========
At iteration 299, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  300 ; minimum lost =  0.08578293025493622 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0011134754167869687
lambda is : 0.010000000000000004, cost : 71.564 min
==========
At iteration 296, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  297 ; minimum lost =  0.19696810841560364 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0003676886553876102
lambda is : 0.04641588833612786, cost : 72.7 min
==========
At iteration 326, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  327 ; minimum lost =  0.10624310374259949 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0006730062304995954
lambda is : 0.014677992676220709, cost : 78.468 min
==========
At iteration 343, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  344 ; minimum lost =  0.1619385927915573 ; diff loss =  9.08970832824707e-07 ; diff weight =  0.00047076516784727573
lambda is : 0.0316227766016838, cost : 82.794 min
==========
At iteration 376, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  377 ; minimum lost =  0.03311041742563248 ; diff loss =  9.94652509689331e-07 ; diff weight =  0.0027525017503648996
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 88.178 min
==========
At iteration 374, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  375 ; minimum lost =  0.03909674286842346 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0021058362908661366
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 89.877 min
==========
At iteration 400, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  401 ; minimum lost =  0.04683556407690048 ; diff loss =  9.015202522277832e-07 ; diff weight =  0.0015001497231423855
lambda is : 0.003162277660168382, cost : 93.986 min
==========
At iteration 396, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  397 ; minimum lost =  0.05677913874387741 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.001604612683877349
lambda is : 0.004641588833612781, cost : 94.858 min
==========
At iteration 412, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  413 ; minimum lost =  0.06929461658000946 ; diff loss =  9.462237358093262e-07 ; diff weight =  0.0012273626634851098
lambda is : 0.006812920690579613, cost : 98.289 min
==========
At iteration 424, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  425 ; minimum lost =  0.028479065746068954 ; diff loss =  8.922070264816284e-07 ; diff weight =  0.0021672435104846954
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 101.586 min
==========
At iteration 432, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  433 ; minimum lost =  0.13148654997348785 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0012528112856671214
lambda is : 0.02154434690031885, cost : 103.817 min
==========
At iteration 450, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  451 ; minimum lost =  0.024872109293937683 ; diff loss =  9.629875421524048e-07 ; diff weight =  0.002347939182072878
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 106.103 min
==========
At iteration 481, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  482 ; minimum lost =  0.021989621222019196 ; diff loss =  9.462237358093262e-07 ; diff weight =  0.004009280353784561
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 113.646 min
==========
At iteration 493, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  494 ; minimum lost =  0.019684448838233948 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.00336605217307806
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 117.349 min
==========
At iteration 512, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  513 ; minimum lost =  0.017779087647795677 ; diff loss =  9.611248970031738e-07 ; diff weight =  0.0031317162793129683
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 119.636 min
==========
At iteration 521, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  522 ; minimum lost =  0.014682868495583534 ; diff loss =  9.164214134216309e-07 ; diff weight =  0.001773249707184732
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 121.787 min
==========
At iteration 551, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  552 ; minimum lost =  0.013326452113687992 ; diff loss =  5.466863512992859e-07 ; diff weight =  0.0012865735916420817
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 129.16 min
==========
At iteration 556, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  557 ; minimum lost =  0.01607886143028736 ; diff loss =  9.57399606704712e-07 ; diff weight =  0.0036223961506038904
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 129.54 min
==========
At iteration 566, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  567 ; minimum lost =  0.0076402174308896065 ; diff loss =  9.583309292793274e-07 ; diff weight =  0.0006627414841204882
At iteration 569, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  570 ; minimum lost =  0.009747088886797428 ; diff loss =  4.833564162254333e-07 ; diff weight =  0.00042774484609253705
lambda is : 9.999999999999997e-06, cost : 132.416 min
==========
lambda is : 2.1544346900318854e-05, cost : 132.597 min
==========
At iteration 576, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  577 ; minimum lost =  0.010862816125154495 ; diff loss =  7.934868335723877e-07 ; diff weight =  0.0012241620570421219
At iteration 566, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  567 ; minimum lost =  0.012024793773889542 ; diff loss =  4.3213367462158203e-07 ; diff weight =  0.0011787922121584415
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 133.508 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 133.512 min
==========
At iteration 589, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  590 ; minimum lost =  0.00843743234872818 ; diff loss =  4.12575900554657e-07 ; diff weight =  0.0010755619732663035
lambda is : 1.4677992676220687e-05, cost : 136.844 min
==========
*** Collecting results ***
Exporting result Dict
Endothelial Time elapsed: 136.92216847340265 minutes.
Shape: (71915, 25712)
['T_NK', 'Myeloid', 'Endothelial', 'Hepatocyte', 'Fibroblast', 'B']
Categories (6, object): ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for Fibroblast
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
*** Start parallel lambda tuning ***
Lambda: Lambda: Lambda:Lambda:1e-05 Lambda: Lambda:Lambda:Lambda:Lambda:Lambda: 1.5e-05 Lambda: Lambda:Lambda: Lambda: Lambda:starting at Lambda: Lambda:Lambda: Lambda: Lambda:4.6e-05 Lambda: Lambda:  Lambda: Lambda: Lambda:  0.000147 starting at  2.2e-05   3.2e-05 0.000681  2024-11-25 16:32:11 0.001468  0.003162 0.004642  starting at  6.8e-05 0.021544 0.014678  0.0001 0.068129 0.1 0.046416 starting at 2024-11-25 16:32:11 0.000215 starting at 0.000316 0.000464 starting at starting at 0.001 Max_iter: starting at 0.002154 starting at starting at 0.006813 2024-11-25 16:32:11 0.01 starting at starting at starting at 0.031623 starting at starting at starting at starting at 2024-11-25 16:32:11 Max_iter: starting at 2024-11-25 16:32:11 starting at starting at 2024-11-25 16:32:11 2024-11-25 16:32:11 starting at 10002024-11-25 16:32:11 starting at 2024-11-25 16:32:11 2024-11-25 16:32:11 starting at Max_iter: starting at 2024-11-25 16:32:11 2024-11-25 16:32:11 2024-11-25 16:32:11 starting at 2024-11-25 16:32:11 2024-11-25 16:32:11 2024-11-25 16:32:11 2024-11-25 16:32:11 Max_iter: 10002024-11-25 16:32:11 Max_iter: 2024-11-25 16:32:11 2024-11-25 16:32:11 Max_iter: Max_iter: 2024-11-25 16:32:11 
Max_iter: 2024-11-25 16:32:11 Max_iter: Max_iter: 2024-11-25 16:32:11 10002024-11-25 16:32:11 Max_iter: Max_iter: Max_iter: 2024-11-25 16:32:11 Max_iter: Max_iter: Max_iter: Max_iter: 1000
Max_iter: 1000Max_iter: Max_iter: 10001000Max_iter: 1000Max_iter: 10001000Max_iter: 
Max_iter: 100010001000
Max_iter:1000100010001000
1000
10001000

1000
1000

10001000

 










1000
At iteration 248, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  249 ; minimum lost =  0.1910102367401123 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.00020189271890558302
lambda is : 0.0681292069057962, cost : 61.315 min
==========
At iteration 256, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  257 ; minimum lost =  0.21709024906158447 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0004114565090276301
lambda is : 0.10000000000000002, cost : 63.052 min
==========
At iteration 257, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  258 ; minimum lost =  0.16292200982570648 ; diff loss =  8.493661880493164e-07 ; diff weight =  0.0006066388450562954
lambda is : 0.04641588833612786, cost : 63.377 min
==========
At iteration 276, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  277 ; minimum lost =  0.1357795149087906 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.00036311332951299846
lambda is : 0.0316227766016838, cost : 68.482 min
==========
At iteration 318, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  319 ; minimum lost =  0.11064273118972778 ; diff loss =  6.556510925292969e-07 ; diff weight =  0.0005873751360923052
lambda is : 0.02154434690031885, cost : 77.04 min
==========
At iteration 325, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  326 ; minimum lost =  0.07081020623445511 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0016000081086531281
lambda is : 0.010000000000000004, cost : 79.0 min
==========
At iteration 360, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  361 ; minimum lost =  0.04501592740416527 ; diff loss =  6.966292858123779e-07 ; diff weight =  0.0013307976769283414
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 87.132 min
==========
At iteration 368, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  369 ; minimum lost =  0.03616312891244888 ; diff loss =  7.972121238708496e-07 ; diff weight =  0.0017486887518316507
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 90.042 min
==========
At iteration 390, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  391 ; minimum lost =  0.02936367318034172 ; diff loss =  8.065253496170044e-07 ; diff weight =  0.0018626197706907988
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 93.567 min
==========
At iteration 396, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  397 ; minimum lost =  0.08871950209140778 ; diff loss =  8.791685104370117e-07 ; diff weight =  0.0011261526960879564
lambda is : 0.014677992676220709, cost : 94.087 min
==========
At iteration 393, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  394 ; minimum lost =  0.05635978654026985 ; diff loss =  9.872019290924072e-07 ; diff weight =  0.001826873398385942
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 94.196 min
==========
At iteration 400, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  401 ; minimum lost =  0.024153269827365875 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.001942205592058599
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 96.409 min
==========
At iteration 428, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  429 ; minimum lost =  0.01725384220480919 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.002830374985933304
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 102.266 min
==========
At iteration 435, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  436 ; minimum lost =  0.020212870091199875 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.00507238507270813
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 104.212 min
==========
At iteration 462, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  463 ; minimum lost =  0.014986268244683743 ; diff loss =  9.825453162193298e-07 ; diff weight =  0.0026609196793287992
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 109.998 min
==========
At iteration 485, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  486 ; minimum lost =  0.013211396522819996 ; diff loss =  9.862706065177917e-07 ; diff weight =  0.007671603932976723
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 114.322 min
==========
At iteration 507, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  508 ; minimum lost =  0.011696984991431236 ; diff loss =  9.55536961555481e-07 ; diff weight =  0.004120588302612305
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 119.571 min
==========
At iteration 513, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  514 ; minimum lost =  0.0065626706928014755 ; diff loss =  6.94766640663147e-07 ; diff weight =  0.006656472571194172
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 120.089 min
==========
At iteration 516, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  517 ; minimum lost =  0.00517469085752964 ; diff loss =  9.522773325443268e-07 ; diff weight =  0.014122952707111835
lambda is : 1.4677992676220687e-05, cost : 122.281 min
==========
At iteration 525, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  526 ; minimum lost =  0.005776260048151016 ; diff loss =  8.405186235904694e-07 ; diff weight =  0.001352032762952149
lambda is : 2.1544346900318854e-05, cost : 123.24 min
==========
At iteration 520, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  521 ; minimum lost =  0.007333109155297279 ; diff loss =  8.493661880493164e-07 ; diff weight =  0.009822101332247257
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 123.557 min
==========
At iteration 524, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  525 ; minimum lost =  0.010377384722232819 ; diff loss =  8.66129994392395e-07 ; diff weight =  0.0037250134628266096
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 124.24 min
==========
At iteration 568, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  569 ; minimum lost =  0.008146082051098347 ; diff loss =  7.981434464454651e-07 ; diff weight =  0.0013041156344115734
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 131.852 min
==========
At iteration 572, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  572 ; minimum lost =  0.004149321466684341 ; diff loss =  -7.897615432739258e-07 ; diff weight =  0.01797124370932579
lambda is : 9.999999999999997e-06, cost : 133.051 min
==========
At iteration 584, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  585 ; minimum lost =  0.009181935340166092 ; diff loss =  8.642673492431641e-07 ; diff weight =  0.004752458073198795
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 135.788 min
==========
*** Collecting results ***
Exporting result Dict
/home/jovyan/work/GitHub/EvanPys/Progress/ADlasso2/AD2_w_utils_lossdiff_noZ.py:929: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax1 = plt.subplots(figsize = (fig_width,fig_height))
Fibroblast Time elapsed: 135.86319758494696 minutes.
Shape: (71915, 25712)
['T_NK', 'Myeloid', 'Endothelial', 'Hepatocyte', 'Fibroblast', 'B']
Categories (6, object): ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for Hepatocyte
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
*** Start parallel lambda tuning ***
Lambda:Lambda:Lambda:Lambda:  Lambda:Lambda:Lambda: Lambda:Lambda:Lambda:Lambda: Lambda:Lambda:3.2e-05 1e-05 Lambda:Lambda:  Lambda: Lambda:Lambda: Lambda:1.5e-05 Lambda: Lambda: Lambda: Lambda: Lambda:2.2e-05 Lambda:   starting at starting at  0.000215 0.000464  4.6e-05   6.8e-05  starting at  0.004642  0.0001  0.000147  0.021544  starting at 0.1 0.068129 0.000316 2024-11-25 18:48:09 2024-11-25 18:48:09 0.000681 starting at starting at 0.001 starting at 0.001468 0.002154 starting at 0.003162 2024-11-25 18:48:090.006813 starting at 0.01 starting at 0.014678 starting at 0.031623 starting at 0.046416 2024-11-25 18:48:09 starting at starting at starting at Max_iter: Max_iter: starting at 2024-11-25 18:48:09 2024-11-25 18:48:09 starting at 2024-11-25 18:48:09 starting at starting at 2024-11-25 18:48:09 starting at  Max_iter:starting at 2024-11-25 18:48:09 starting at 2024-11-25 18:48:09 starting at 2024-11-25 18:48:09 starting at 2024-11-25 18:48:09 starting at Max_iter:2024-11-25 18:48:09 2024-11-25 18:48:09 2024-11-25 18:48:09 100010002024-11-25 18:48:09 Max_iter: Max_iter: 2024-11-25 18:48:09 Max_iter:2024-11-25 18:48:09 2024-11-25 18:48:09 Max_iter: 2024-11-25 18:48:09  10002024-11-25 18:48:09 Max_iter: 2024-11-25 18:48:09 Max_iter: 2024-11-25 18:48:09 Max_iter: 2024-11-25 18:48:09 Max_iter: 2024-11-25 18:48:09  1000Max_iter: Max_iter: Max_iter: 

Max_iter:10001000Max_iter:  1000Max_iter: Max_iter: 1000Max_iter: 
Max_iter: 1000Max_iter: 1000Max_iter: 1000Max_iter: 1000Max_iter: 
100010001000 

1000
10001000
10001000
1000

1000

1000
1000


1000







At iteration 355, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  356 ; minimum lost =  0.26052767038345337 ; diff loss =  4.172325134277344e-07 ; diff weight =  0.000220716668991372
lambda is : 0.04641588833612786, cost : 89.341 min
==========
At iteration 398, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  399 ; minimum lost =  0.1938610076904297 ; diff loss =  5.364418029785156e-07 ; diff weight =  0.0002552180958446115
lambda is : 0.02154434690031885, cost : 101.066 min
==========
At iteration 429, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  430 ; minimum lost =  0.22346240282058716 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0008910868782550097
lambda is : 0.0316227766016838, cost : 107.948 min
==========
At iteration 455, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  456 ; minimum lost =  0.15117527544498444 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0009904014877974987
lambda is : 0.010000000000000004, cost : 114.162 min
==========
At iteration 457, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  458 ; minimum lost =  0.1700558364391327 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0007708553457632661
lambda is : 0.014677992676220709, cost : 114.602 min
==========
At iteration 465, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  466 ; minimum lost =  0.3069595992565155 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.00038194956141524017
lambda is : 0.0681292069057962, cost : 115.689 min
==========
At iteration 478, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  479 ; minimum lost =  0.3635590076446533 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.00041105717536993325
lambda is : 0.10000000000000002, cost : 118.711 min
==========
At iteration 485, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  486 ; minimum lost =  0.13642889261245728 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0011335288872942328
lambda is : 0.006812920690579613, cost : 121.54 min
==========
At iteration 492, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  493 ; minimum lost =  0.12495116889476776 ; diff loss =  7.152557373046875e-07 ; diff weight =  0.0008179420256055892
lambda is : 0.004641588833612781, cost : 122.504 min
==========
At iteration 548, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  549 ; minimum lost =  0.1158067137002945 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0011934813810512424
lambda is : 0.003162277660168382, cost : 134.73 min
==========
At iteration 584, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  585 ; minimum lost =  0.08125026524066925 ; diff loss =  7.599592208862305e-07 ; diff weight =  0.00027500675059854984
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 141.634 min
==========
At iteration 582, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  583 ; minimum lost =  0.08409789204597473 ; diff loss =  6.780028343200684e-07 ; diff weight =  0.004540444817394018
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 143.371 min
==========
At iteration 593, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  594 ; minimum lost =  0.07790128886699677 ; diff loss =  8.419156074523926e-07 ; diff weight =  0.000517725246027112
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 145.923 min
==========
At iteration 598, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  599 ; minimum lost =  0.08701493591070175 ; diff loss =  6.556510925292969e-07 ; diff weight =  0.00033569970401003957
At iteration 600, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  601 ; minimum lost =  0.1084539070725441 ; diff loss =  9.313225746154785e-07 ; diff weight =  0.0011498926905915141
At iteration 598, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  599 ; minimum lost =  0.10248246043920517 ; diff loss =  9.611248970031738e-07 ; diff weight =  0.0015267699491232634
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 146.965 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 147.019 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 147.023 min
==========
At iteration 602, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  603 ; minimum lost =  0.07515530288219452 ; diff loss =  9.760260581970215e-07 ; diff weight =  0.00036087498301640153
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 148.788 min
==========
At iteration 617, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  618 ; minimum lost =  0.06865442544221878 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0002569349599070847
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 151.398 min
==========
At iteration 635, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  636 ; minimum lost =  0.09760823845863342 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.0018897212576121092
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 154.05 min
==========
At iteration 643, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  644 ; minimum lost =  0.07110999524593353 ; diff loss =  8.642673492431641e-07 ; diff weight =  0.0001954974140971899
At iteration 636, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  637 ; minimum lost =  0.09352575987577438 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0017178894486278296
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 155.337 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 155.523 min
==========
At iteration 649, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  650 ; minimum lost =  0.09004294872283936 ; diff loss =  6.109476089477539e-07 ; diff weight =  0.0016674459911882877
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 156.703 min
==========
At iteration 682, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  683 ; minimum lost =  0.0560113899409771 ; diff loss =  9.126961231231689e-07 ; diff weight =  0.0004746310005430132
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999997e-06, cost : 163.766 min
==========
At iteration 735, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  736 ; minimum lost =  0.0594823993742466 ; diff loss =  9.94652509689331e-07 ; diff weight =  0.0005884619895368814
At iteration 737, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  737 ; minimum lost =  0.0631556510925293 ; diff loss =  -1.043081283569336e-07 ; diff weight =  0.01161313895136118
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 1.4677992676220687e-05, cost : 173.697 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 2.1544346900318854e-05, cost : 173.973 min
==========
*** Collecting results ***
Exporting result Dict
Hepatocyte Time elapsed: 174.0491713444392 minutes.
Shape: (71915, 25712)
['T_NK', 'Myeloid', 'Endothelial', 'Hepatocyte', 'Fibroblast', 'B']
Categories (6, object): ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for Myeloid
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
*** Start parallel lambda tuning ***
Lambda:Lambda: Lambda: Lambda: Lambda:Lambda:1.5e-05Lambda:Lambda:Lambda:Lambda:Lambda: Lambda:Lambda:1e-05 Lambda:Lambda:3.2e-05 Lambda:  Lambda: starting at Lambda: Lambda:  Lambda: 2.2e-05 Lambda: Lambda: Lambda:Lambda:Lambda:starting at   starting at  4.6e-05 0.000681   2024-11-25 21:42:190.001468  6.8e-05  0.003162 starting at0.0001  0.006813 starting at  0.014678  0.000147    2024-11-25 21:42:19 0.000215 0.000316 2024-11-25 21:42:19 0.000464 starting at starting at 0.001  Max_iter:starting at 0.002154 starting at 0.004642  2024-11-25 21:42:19starting at 0.01 starting at 2024-11-25 21:42:19 0.021544 starting at 0.031623 starting at 0.046416 0.068129 0.1 Max_iter: starting at starting at Max_iter: starting at 2024-11-25 21:42:192024-11-25 21:42:19 2024-11-25 21:42:19 starting at  10002024-11-25 21:42:19 starting at 2024-11-25 21:42:19 starting at  Max_iter:2024-11-25 21:42:19 starting at 2024-11-25 21:42:19 Max_iter: starting at 2024-11-25 21:42:19 starting at 2024-11-25 21:42:19 starting at starting at starting at 10002024-11-25 21:42:19 2024-11-25 21:42:19 1000 Max_iter:Max_iter: Max_iter: 2024-11-25 21:42:19 
Max_iter: 2024-11-25 21:42:19 Max_iter: 2024-11-25 21:42:19  1000Max_iter: 2024-11-25 21:42:19 Max_iter: 10002024-11-25 21:42:19 Max_iter: 2024-11-25 21:42:19 Max_iter: 2024-11-25 21:42:19 2024-11-25 21:42:19 2024-11-25 21:42:19 
Max_iter: Max_iter: 
 10001000Max_iter: 1000Max_iter:1000Max_iter: 
1000Max_iter:1000
Max_iter:1000Max_iter:1000Max_iter:Max_iter:Max_iter:100010001000

1000
 1000
1000

 1000
 
 
   





10001000
1000
1000
1000

At iteration 332, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  333 ; minimum lost =  0.4044204354286194 ; diff loss =  5.960464477539062e-07 ; diff weight =  0.0003509455418679863
lambda is : 0.10000000000000002, cost : 80.55 min
==========
At iteration 372, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  373 ; minimum lost =  0.27157285809516907 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0004247166798450053
lambda is : 0.04641588833612786, cost : 89.628 min
==========
At iteration 387, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  388 ; minimum lost =  0.3329331576824188 ; diff loss =  5.662441253662109e-07 ; diff weight =  0.0001938711357070133
lambda is : 0.0681292069057962, cost : 94.045 min
==========
At iteration 435, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  436 ; minimum lost =  0.1225653737783432 ; diff loss =  7.897615432739258e-07 ; diff weight =  0.0009717587963677943
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.010000000000000004, cost : 104.66 min
==========
At iteration 438, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  439 ; minimum lost =  0.22066782414913177 ; diff loss =  7.599592208862305e-07 ; diff weight =  0.001074186759069562
lambda is : 0.0316227766016838, cost : 105.033 min
==========
At iteration 493, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  494 ; minimum lost =  0.10330236703157425 ; diff loss =  9.08970832824707e-07 ; diff weight =  0.0017102593556046486
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.006812920690579613, cost : 116.854 min
==========
At iteration 496, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  497 ; minimum lost =  0.1475306898355484 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0010780919110402465
lambda is : 0.014677992676220709, cost : 118.294 min
==========
At iteration 522, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  523 ; minimum lost =  0.17976686358451843 ; diff loss =  4.3213367462158203e-07 ; diff weight =  3.594457302824594e-05
lambda is : 0.02154434690031885, cost : 123.093 min
==========
At iteration 537, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  538 ; minimum lost =  0.07750165462493896 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0014839422656223178
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.003162277660168382, cost : 128.017 min
==========
At iteration 550, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  551 ; minimum lost =  0.08869780600070953 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.0012744307750836015
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.004641588833612781, cost : 129.082 min
==========
At iteration 556, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  557 ; minimum lost =  0.06878446042537689 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0015753705520182848
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 131.763 min
==========
At iteration 560, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  561 ; minimum lost =  0.06199914962053299 ; diff loss =  8.717179298400879e-07 ; diff weight =  0.0018673875601962209
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 134.189 min
==========
At iteration 570, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  571 ; minimum lost =  0.056685589253902435 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.002096440875902772
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 134.587 min
==========
At iteration 579, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  580 ; minimum lost =  0.03262137621641159 ; diff loss =  9.387731552124023e-07 ; diff weight =  0.0005580169963650405
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 138.448 min
==========
At iteration 610, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  611 ; minimum lost =  0.045756954699754715 ; diff loss =  9.350478649139404e-07 ; diff weight =  0.0021742370445281267
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 143.205 min
==========
At iteration 616, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  617 ; minimum lost =  0.036263514310121536 ; diff loss =  1.564621925354004e-07 ; diff weight =  0.006136045325547457
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 144.007 min
==========
At iteration 613, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  614 ; minimum lost =  0.038507506251335144 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0007874234579503536
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 145.832 min
==========
At iteration 624, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  625 ; minimum lost =  0.02548779919743538 ; diff loss =  9.313225746154785e-07 ; diff weight =  0.0006482957978732884
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999997e-06, cost : 146.992 min
==========
At iteration 626, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  627 ; minimum lost =  0.05238022282719612 ; diff loss =  9.797513484954834e-07 ; diff weight =  0.0022135304752737284
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 147.863 min
==========
At iteration 632, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  633 ; minimum lost =  0.048772625625133514 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.002161137294024229
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 148.476 min
==========
At iteration 625, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  626 ; minimum lost =  0.04307342320680618 ; diff loss =  7.7858567237854e-07 ; diff weight =  0.0008772671571932733
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 148.627 min
==========
At iteration 628, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  629 ; minimum lost =  0.03401293605566025 ; diff loss =  6.221234798431396e-07 ; diff weight =  0.00043611321598291397
At iteration 625, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  626 ; minimum lost =  0.029645049944519997 ; diff loss =  9.331852197647095e-07 ; diff weight =  0.002671573543921113
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 149.329 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 2.1544346900318854e-05, cost : 149.548 min
==========
At iteration 630, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  631 ; minimum lost =  0.04057948663830757 ; diff loss =  3.6135315895080566e-07 ; diff weight =  0.0038710476364940405
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 150.524 min
==========
At iteration 648, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  649 ; minimum lost =  0.02719218283891678 ; diff loss =  8.139759302139282e-07 ; diff weight =  0.0005778376944363117
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 1.4677992676220687e-05, cost : 152.129 min
==========
*** Collecting results ***
Exporting result Dict
Myeloid Time elapsed: 152.20817863941193 minutes.
Shape: (71915, 25712)
['T_NK', 'Myeloid', 'Endothelial', 'Hepatocyte', 'Fibroblast', 'B']
Categories (6, object): ['B', 'Endothelial', 'Fibroblast', 'Hepatocyte', 'Myeloid', 'T_NK']
TYPE <class 'scipy.sparse._csr.csr_matrix'>
====================
Starting job for T_NK
[-11.51292546 -11.12916128 -10.7453971  -10.36163292  -9.97786874
  -9.59410455  -9.21034037  -8.82657619  -8.44281201  -8.05904783
  -7.67528364  -7.29151946  -6.90775528  -6.5239911   -6.14022691
  -5.75646273  -5.37269855  -4.98893437  -4.60517019  -4.221406
  -3.83764182  -3.45387764  -3.07011346  -2.68634928  -2.30258509]
[1.00000000e-05 1.46779927e-05 2.15443469e-05 3.16227766e-05
 4.64158883e-05 6.81292069e-05 1.00000000e-04 1.46779927e-04
 2.15443469e-04 3.16227766e-04 4.64158883e-04 6.81292069e-04
 1.00000000e-03 1.46779927e-03 2.15443469e-03 3.16227766e-03
 4.64158883e-03 6.81292069e-03 1.00000000e-02 1.46779927e-02
 2.15443469e-02 3.16227766e-02 4.64158883e-02 6.81292069e-02
 1.00000000e-01]
Alpha: 0.01
Loss tolerance: 1e-06
*** Start parallel lambda tuning ***
Lambda:Lambda: Lambda: Lambda:Lambda: Lambda:1.5e-05 Lambda: Lambda:1e-05 Lambda: Lambda:Lambda: Lambda: Lambda:4.6e-05 Lambda: Lambda:Lambda:starting at Lambda: Lambda:2.2e-05 Lambda: Lambda:Lambda: Lambda:starting at Lambda: Lambda:3.2e-05 Lambda: 0.000316 0.000464  starting at  6.8e-05   2024-11-26 00:14:38  0.0001  starting at  0.006813 0.000147  0.014678  2024-11-26 00:14:38  0.000215  starting at  0.068129 starting at starting at 0.000681 2024-11-26 00:14:38 0.001 starting at 0.001468 0.002154 Max_iter: 0.003162 starting at 0.004642 2024-11-26 00:14:38 starting at starting at 0.01 starting at 0.021544 Max_iter: 0.031623 starting at 0.046416 2024-11-26 00:14:38 0.1 starting at 2024-11-26 00:14:38 2024-11-26 00:14:38 starting at Max_iter: starting at 2024-11-26 00:14:38 starting at starting at 1000starting at 2024-11-26 00:14:38 starting at Max_iter: 2024-11-26 00:14:38 2024-11-26 00:14:38 starting at 2024-11-26 00:14:38 starting at 1000
starting at 2024-11-26 00:14:38 starting at Max_iter: starting at 2024-11-26 00:14:38 Max_iter: Max_iter: 2024-11-26 00:14:38 10002024-11-26 00:14:38 Max_iter: 2024-11-26 00:14:38 2024-11-26 00:14:38 
2024-11-26 00:14:38 Max_iter: 2024-11-26 00:14:38 1000Max_iter: Max_iter: 2024-11-26 00:14:38 Max_iter:2024-11-26 00:14:382024-11-26 00:14:38Max_iter: 2024-11-26 00:14:3810002024-11-26 00:14:38 Max_iter:10001000Max_iter:
Max_iter:1000Max_iter:Max_iter: Max_iter:1000Max_iter: 
10001000Max_iter:   1000 
Max_iter: 

  1000
 10001000 
1000

 1000Max_iter:Max_iter:
Max_iter: 10001000


1000
1000

 1000  10001000



1000


At iteration 322, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  323 ; minimum lost =  0.3989800810813904 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.00033534489921294153
lambda is : 0.0681292069057962, cost : 77.543 min
==========
At iteration 406, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  407 ; minimum lost =  0.4586685001850128 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.000378547003492713
lambda is : 0.10000000000000002, cost : 97.431 min
==========
At iteration 444, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  445 ; minimum lost =  0.34482747316360474 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.00067662273067981
lambda is : 0.04641588833612786, cost : 105.833 min
==========
At iteration 450, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  451 ; minimum lost =  0.2974507808685303 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0006216097390279174
lambda is : 0.0316227766016838, cost : 107.113 min
==========
At iteration 465, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  466 ; minimum lost =  0.25674957036972046 ; diff loss =  9.834766387939453e-07 ; diff weight =  0.0005968260229565203
lambda is : 0.02154434690031885, cost : 111.186 min
==========
At iteration 489, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  490 ; minimum lost =  0.16930034756660461 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0016363918548449874
lambda is : 0.006812920690579613, cost : 115.44 min
==========
At iteration 504, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  505 ; minimum lost =  0.1500716507434845 ; diff loss =  9.5367431640625e-07 ; diff weight =  0.0011134009109809995
lambda is : 0.004641588833612781, cost : 120.126 min
==========
At iteration 507, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  508 ; minimum lost =  0.22206321358680725 ; diff loss =  8.940696716308594e-07 ; diff weight =  0.0005543019506148994
lambda is : 0.014677992676220709, cost : 120.659 min
==========
At iteration 520, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  521 ; minimum lost =  0.19310584664344788 ; diff loss =  2.384185791015625e-07 ; diff weight =  0.00042258898611180484
lambda is : 0.010000000000000004, cost : 122.571 min
==========
At iteration 555, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  556 ; minimum lost =  0.13454945385456085 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0010247051250189543
lambda is : 0.003162277660168382, cost : 130.932 min
==========
At iteration 578, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  579 ; minimum lost =  0.12203356623649597 ; diff loss =  9.238719940185547e-07 ; diff weight =  0.0009652563603594899
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0021544346900318843, cost : 134.431 min
==========
At iteration 577, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  578 ; minimum lost =  0.11210742592811584 ; diff loss =  9.98377799987793e-07 ; diff weight =  0.0013566892594099045
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0014677992676220694, cost : 135.388 min
==========
At iteration 578, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  579 ; minimum lost =  0.07756979763507843 ; diff loss =  8.046627044677734e-07 ; diff weight =  0.00027079679421149194
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999991e-05, cost : 136.753 min
==========
At iteration 591, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  592 ; minimum lost =  0.072337806224823 ; diff loss =  9.611248970031738e-07 ; diff weight =  0.00023237447021529078
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 4.6415888336127784e-05, cost : 138.39 min
==========
At iteration 590, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  591 ; minimum lost =  0.09221379458904266 ; diff loss =  7.37607479095459e-07 ; diff weight =  0.0005031510954722762
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00046415888336127795, cost : 138.916 min
==========
At iteration 593, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  594 ; minimum lost =  0.1040450856089592 ; diff loss =  9.685754776000977e-07 ; diff weight =  0.001339624635875225
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0010000000000000002, cost : 139.189 min
==========
At iteration 596, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  597 ; minimum lost =  0.07465716451406479 ; diff loss =  9.015202522277832e-07 ; diff weight =  0.00041059014620259404
At iteration 587, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  588 ; minimum lost =  0.08049578964710236 ; diff loss =  5.736947059631348e-07 ; diff weight =  0.003028969280421734
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 6.81292069057961e-05, cost : 140.06 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00014677992676220703, cost : 140.119 min
==========
At iteration 604, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  605 ; minimum lost =  0.08389154821634293 ; diff loss =  2.905726432800293e-07 ; diff weight =  0.00014311395352706313
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0002154434690031884, cost : 142.147 min
==========
At iteration 612, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  613 ; minimum lost =  0.069257453083992 ; diff loss =  4.76837158203125e-07 ; diff weight =  0.006498394533991814
At iteration 614, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  615 ; minimum lost =  0.09751100838184357 ; diff loss =  9.909272193908691e-07 ; diff weight =  0.0021189930848777294
At iteration 613, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  613 ; minimum lost =  0.06408239901065826 ; diff loss =  -3.2782554626464844e-07 ; diff weight =  0.012716027908027172
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.0006812920690579617, cost : 143.7 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 3.16227766016838e-05, cost : 143.751 min
==========
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 1.4677992676220687e-05, cost : 144.208 min
==========
At iteration 614, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  615 ; minimum lost =  0.08767272531986237 ; diff loss =  7.599592208862305e-07 ; diff weight =  0.00022171517775859684
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 0.00031622776601683783, cost : 144.894 min
==========
At iteration 635, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  636 ; minimum lost =  0.0665384978055954 ; diff loss =  8.419156074523926e-07 ; diff weight =  0.0002322735672350973
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 2.1544346900318854e-05, cost : 148.204 min
==========
At iteration 673, Convergence with loss difference, Device: cpu
Convergence with loss difference, Device: cpu
minimum epoch =  674 ; minimum lost =  0.05979636684060097 ; diff loss =  8.158385753631592e-07 ; diff weight =  0.0003530520189087838
/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
lambda is : 9.999999999999997e-06, cost : 156.617 min
==========
*** Collecting results ***
Exporting result Dict
T_NK Time elapsed: 156.69866495132447 minutes.
***** Finished lambda tuning
====================
